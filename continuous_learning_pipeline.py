#!/usr/bin/env python3
"""
24ì‹œê°„ ìë™ í•™ìŠµ íŒŒì´í”„ë¼ì¸
ìƒìš©í™” ìˆ˜ì¤€ì˜ AIì™€ C# ì „ë¬¸ê°€ ì§€ì‹ì„ ì§€ì†ì ìœ¼ë¡œ í•™ìŠµ
"""

import os
import sys
import json
import sqlite3
import logging
import asyncio
import schedule
import threading
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
import subprocess
import requests
from collections import defaultdict
import numpy as np

# AutoCI ëª¨ë“ˆ ì„í¬íŠ¸
sys.path.append(str(Path(__file__).parent))

from commercial_ai_engine import CommercialDialogueEngine
from csharp_expert_learner import CSharpExpertLearner
from real_learning_system import RealLearningSystem
from ai_learning_monitor import AILearningMonitor

logger = logging.getLogger(__name__)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler('continuous_learning.log'),
        logging.StreamHandler()
    ]
)


class ContinuousLearningPipeline:
    """24ì‹œê°„ ìë™ í•™ìŠµ íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self):
        self.base_path = Path(__file__).parent
        self.data_path = self.base_path / "learning_pipeline_data"
        self.data_path.mkdir(exist_ok=True)
        
        # í•™ìŠµ ì»´í¬ë„ŒíŠ¸
        self.components = {
            'dialogue_engine': CommercialDialogueEngine(),
            'csharp_learner': CSharpExpertLearner(),
            'base_learner': RealLearningSystem(),
            'monitor': AILearningMonitor()
        }
        
        # í•™ìŠµ ìŠ¤ì¼€ì¤„
        self.learning_schedule = {
            'documentation_crawl': '02:00',  # ìƒˆë²½ 2ì‹œ ë¬¸ì„œ í¬ë¡¤ë§
            'code_analysis': '06:00',        # ì˜¤ì „ 6ì‹œ ì½”ë“œ ë¶„ì„
            'pattern_synthesis': '10:00',    # ì˜¤ì „ 10ì‹œ íŒ¨í„´ ì¢…í•©
            'knowledge_update': '14:00',     # ì˜¤í›„ 2ì‹œ ì§€ì‹ ì—…ë°ì´íŠ¸
            'quality_review': '18:00',       # ì˜¤í›„ 6ì‹œ í’ˆì§ˆ ê²€í† 
            'optimization': '22:00'          # ì˜¤í›„ 10ì‹œ ìµœì í™”
        }
        
        # í•™ìŠµ ì†ŒìŠ¤
        self.learning_sources = {
            'github': GitHubLearner(),
            'stackoverflow': StackOverflowLearner(),
            'documentation': DocumentationLearner(),
            'community': CommunityLearner(),
            'feedback': FeedbackLearner()
        }
        
        # í•™ìŠµ ìƒíƒœ
        self.learning_state = {
            'is_running': False,
            'current_task': None,
            'tasks_completed': 0,
            'last_learning_time': datetime.now(),
            'learning_history': deque(maxlen=1000)
        }
        
        # í’ˆì§ˆ ë©”íŠ¸ë¦­
        self.quality_metrics = {
            'dialogue_quality': 0.0,
            'knowledge_accuracy': 0.0,
            'response_time': 0.0,
            'user_satisfaction': 0.0
        }
        
        # ì´ˆê¸°í™”
        self._init_database()
        self._setup_schedulers()
        
    def _init_database(self):
        """í•™ìŠµ íŒŒì´í”„ë¼ì¸ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        conn = sqlite3.connect(str(self.data_path / "pipeline.db"))
        cursor = conn.cursor()
        
        # í•™ìŠµ ì‘ì—… í…Œì´ë¸”
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS learning_tasks (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                task_type TEXT,
                start_time DATETIME,
                end_time DATETIME,
                status TEXT,
                results TEXT,
                quality_score REAL,
                errors TEXT
            )
        ''')
        
        # í•™ìŠµ ì†ŒìŠ¤ í…Œì´ë¸”
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS learning_sources (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                source_type TEXT,
                source_url TEXT,
                last_accessed DATETIME,
                content_hash TEXT,
                learning_value REAL,
                metadata TEXT
            )
        ''')
        
        # í’ˆì§ˆ ë©”íŠ¸ë¦­ í…Œì´ë¸”
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS quality_metrics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                metric_type TEXT,
                metric_value REAL,
                details TEXT
            )
        ''')
        
        # í•™ìŠµ ê²°ê³¼ í…Œì´ë¸”
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS learning_results (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                component TEXT,
                improvement_type TEXT,
                before_value REAL,
                after_value REAL,
                description TEXT
            )
        ''')
        
        conn.commit()
        conn.close()
    
    def _setup_schedulers(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •"""
        # ë¬¸ì„œ í¬ë¡¤ë§
        schedule.every().day.at(self.learning_schedule['documentation_crawl']).do(
            self._run_async_task, self.learn_from_documentation
        )
        
        # ì½”ë“œ ë¶„ì„
        schedule.every().day.at(self.learning_schedule['code_analysis']).do(
            self._run_async_task, self.analyze_code_repositories
        )
        
        # íŒ¨í„´ ì¢…í•©
        schedule.every().day.at(self.learning_schedule['pattern_synthesis']).do(
            self._run_async_task, self.synthesize_patterns
        )
        
        # ì§€ì‹ ì—…ë°ì´íŠ¸
        schedule.every().day.at(self.learning_schedule['knowledge_update']).do(
            self._run_async_task, self.update_knowledge_base
        )
        
        # í’ˆì§ˆ ê²€í† 
        schedule.every().day.at(self.learning_schedule['quality_review']).do(
            self._run_async_task, self.review_quality
        )
        
        # ìµœì í™”
        schedule.every().day.at(self.learning_schedule['optimization']).do(
            self._run_async_task, self.optimize_systems
        )
        
        # 1ì‹œê°„ë§ˆë‹¤ ì‹¤í–‰ë˜ëŠ” ì‘ì—…
        schedule.every().hour.do(self._hourly_learning)
        
        # 10ë¶„ë§ˆë‹¤ ì‹¤í–‰ë˜ëŠ” ì‘ì—…
        schedule.every(10).minutes.do(self._quick_learning)
    
    def _run_async_task(self, async_func):
        """ë¹„ë™ê¸° ì‘ì—… ì‹¤í–‰"""
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            loop.run_until_complete(async_func())
        finally:
            loop.close()
    
    def start(self):
        """24ì‹œê°„ í•™ìŠµ ì‹œì‘"""
        self.learning_state['is_running'] = True
        
        # ëª¨ë‹ˆí„°ë§ ì‹œì‘
        self.components['monitor'].start()
        
        # ë°±ê·¸ë¼ìš´ë“œ í•™ìŠµ ìŠ¤ë ˆë“œ ì‹œì‘
        self.learning_thread = threading.Thread(
            target=self._learning_loop,
            daemon=True
        )
        self.learning_thread.start()
        
        # ìŠ¤ì¼€ì¤„ëŸ¬ ìŠ¤ë ˆë“œ ì‹œì‘
        self.scheduler_thread = threading.Thread(
            target=self._scheduler_loop,
            daemon=True
        )
        self.scheduler_thread.start()
        
        logger.info("ğŸš€ 24ì‹œê°„ ìë™ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹œì‘!")
    
    def stop(self):
        """í•™ìŠµ ì¤‘ì§€"""
        self.learning_state['is_running'] = False
        
        # ì»´í¬ë„ŒíŠ¸ ì¤‘ì§€
        self.components['monitor'].stop()
        
        logger.info("ğŸ›‘ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì¤‘ì§€")
    
    def _learning_loop(self):
        """ë©”ì¸ í•™ìŠµ ë£¨í”„"""
        while self.learning_state['is_running']:
            try:
                # ì‹¤ì‹œê°„ í•™ìŠµ ì‘ì—…
                self._perform_realtime_learning()
                
                # 30ì´ˆ ëŒ€ê¸°
                time.sleep(30)
                
            except Exception as e:
                logger.error(f"í•™ìŠµ ë£¨í”„ ì˜¤ë¥˜: {e}")
                time.sleep(60)  # ì˜¤ë¥˜ ì‹œ 1ë¶„ ëŒ€ê¸°
    
    def _scheduler_loop(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ë£¨í”„"""
        while self.learning_state['is_running']:
            schedule.run_pending()
            time.sleep(60)  # 1ë¶„ë§ˆë‹¤ ì²´í¬
    
    def _perform_realtime_learning(self):
        """ì‹¤ì‹œê°„ í•™ìŠµ ìˆ˜í–‰"""
        # í˜„ì¬ ì‹œìŠ¤í…œ ìƒíƒœ ì²´í¬
        system_status = self._check_system_status()
        
        # CPU ì‚¬ìš©ë¥ ì´ ë‚®ì„ ë•Œ í•™ìŠµ ìˆ˜í–‰
        if system_status['cpu_usage'] < 50:
            # ëŒ€ê¸° ì¤‘ì¸ í•™ìŠµ ì‘ì—… ì‹¤í–‰
            self._execute_pending_tasks()
    
    def _check_system_status(self) -> Dict[str, float]:
        """ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸"""
        try:
            import psutil
            return {
                'cpu_usage': psutil.cpu_percent(interval=1),
                'memory_usage': psutil.virtual_memory().percent,
                'disk_usage': psutil.disk_usage('/').percent
            }
        except:
            return {
                'cpu_usage': 0,
                'memory_usage': 0,
                'disk_usage': 0
            }
    
    def _execute_pending_tasks(self):
        """ëŒ€ê¸° ì¤‘ì¸ í•™ìŠµ ì‘ì—… ì‹¤í–‰"""
        # í•™ìŠµ ìš°ì„ ìˆœìœ„ íì—ì„œ ì‘ì—… ê°€ì ¸ì˜¤ê¸°
        pass
    
    async def learn_from_documentation(self):
        """ë¬¸ì„œì—ì„œ í•™ìŠµ"""
        logger.info("ğŸ“š ë¬¸ì„œ í•™ìŠµ ì‹œì‘...")
        
        task_id = self._start_task('documentation_crawl')
        
        try:
            # C# ë¬¸ì„œ í•™ìŠµ
            await self.components['csharp_learner'].learn_from_documentation()
            
            # Unity ë¬¸ì„œ í•™ìŠµ
            unity_docs = await self.learning_sources['documentation'].fetch_unity_docs()
            
            # í•™ìŠµ ê²°ê³¼ ì €ì¥
            self._record_learning_result(
                'documentation',
                'knowledge_expansion',
                before=self.quality_metrics['knowledge_accuracy'],
                after=self.quality_metrics['knowledge_accuracy'] + 0.01
            )
            
            self._complete_task(task_id, 'success')
            
        except Exception as e:
            logger.error(f"ë¬¸ì„œ í•™ìŠµ ì˜¤ë¥˜: {e}")
            self._complete_task(task_id, 'failed', str(e))
    
    async def analyze_code_repositories(self):
        """ì½”ë“œ ì €ì¥ì†Œ ë¶„ì„"""
        logger.info("ğŸ” ì½”ë“œ ì €ì¥ì†Œ ë¶„ì„ ì‹œì‘...")
        
        task_id = self._start_task('code_analysis')
        
        try:
            # GitHub ì¸ê¸° C# í”„ë¡œì íŠ¸ ë¶„ì„
            repos = await self.learning_sources['github'].get_trending_csharp_repos()
            
            for repo in repos[:5]:  # ìƒìœ„ 5ê°œ
                # ì½”ë“œ ë‹¤ìš´ë¡œë“œ ë° ë¶„ì„
                code_path = await self._download_repo(repo)
                
                if code_path:
                    # íŒ¨í„´ í•™ìŠµ
                    patterns = self.components['csharp_learner'].analyze_code_patterns(code_path)
                    
                    # ëª¨ë²” ì‚¬ë¡€ ì¶”ì¶œ
                    best_practices = self._extract_best_practices(patterns)
                    
                    # ì €ì¥
                    self._store_code_insights(repo, patterns, best_practices)
            
            self._complete_task(task_id, 'success')
            
        except Exception as e:
            logger.error(f"ì½”ë“œ ë¶„ì„ ì˜¤ë¥˜: {e}")
            self._complete_task(task_id, 'failed', str(e))
    
    async def synthesize_patterns(self):
        """íŒ¨í„´ ì¢…í•© ë° ì¼ë°˜í™”"""
        logger.info("ğŸ§© íŒ¨í„´ ì¢…í•© ì‹œì‘...")
        
        task_id = self._start_task('pattern_synthesis')
        
        try:
            # ìˆ˜ì§‘ëœ íŒ¨í„´ ë¡œë“œ
            patterns = self._load_collected_patterns()
            
            # íŒ¨í„´ í´ëŸ¬ìŠ¤í„°ë§
            clustered_patterns = self._cluster_patterns(patterns)
            
            # ì¼ë°˜í™”ëœ íŒ¨í„´ ìƒì„±
            generalized_patterns = self._generalize_patterns(clustered_patterns)
            
            # íŒ¨í„´ í’ˆì§ˆ í‰ê°€
            for pattern in generalized_patterns:
                pattern['quality_score'] = self._evaluate_pattern_quality(pattern)
            
            # ê³ í’ˆì§ˆ íŒ¨í„´ë§Œ ì €ì¥
            high_quality_patterns = [
                p for p in generalized_patterns 
                if p['quality_score'] > 0.8
            ]
            
            self._store_generalized_patterns(high_quality_patterns)
            
            self._complete_task(task_id, 'success')
            
        except Exception as e:
            logger.error(f"íŒ¨í„´ ì¢…í•© ì˜¤ë¥˜: {e}")
            self._complete_task(task_id, 'failed', str(e))
    
    async def update_knowledge_base(self):
        """ì§€ì‹ ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸"""
        logger.info("ğŸ§  ì§€ì‹ ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸...")
        
        task_id = self._start_task('knowledge_update')
        
        try:
            # ê° ì»´í¬ë„ŒíŠ¸ì˜ ì§€ì‹ í†µí•©
            dialogue_knowledge = self.components['dialogue_engine'].conversation_patterns
            csharp_knowledge = self.components['csharp_learner'].synthesize_knowledge()
            base_knowledge = self.components['base_learner'].get_learning_stats()
            
            # ì§€ì‹ ìœµí•©
            integrated_knowledge = self._integrate_knowledge(
                dialogue_knowledge,
                csharp_knowledge,
                base_knowledge
            )
            
            # ì§€ì‹ ê²€ì¦
            validated_knowledge = self._validate_knowledge(integrated_knowledge)
            
            # ì—…ë°ì´íŠ¸ ì ìš©
            self._apply_knowledge_updates(validated_knowledge)
            
            # í’ˆì§ˆ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            self.quality_metrics['knowledge_accuracy'] = self._calculate_knowledge_accuracy()
            
            self._complete_task(task_id, 'success')
            
        except Exception as e:
            logger.error(f"ì§€ì‹ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}")
            self._complete_task(task_id, 'failed', str(e))
    
    async def review_quality(self):
        """í’ˆì§ˆ ê²€í†  ë° ê°œì„ """
        logger.info("ğŸ” í’ˆì§ˆ ê²€í†  ì‹œì‘...")
        
        task_id = self._start_task('quality_review')
        
        try:
            # ëŒ€í™” í’ˆì§ˆ í‰ê°€
            dialogue_quality = await self._evaluate_dialogue_quality()
            
            # ì§€ì‹ ì •í™•ë„ í‰ê°€
            knowledge_accuracy = await self._evaluate_knowledge_accuracy()
            
            # ì‘ë‹µ ì†ë„ í‰ê°€
            response_speed = await self._evaluate_response_speed()
            
            # ì‚¬ìš©ì ë§Œì¡±ë„ í‰ê°€
            user_satisfaction = await self._evaluate_user_satisfaction()
            
            # ì¢…í•© í’ˆì§ˆ ì ìˆ˜
            overall_quality = (
                dialogue_quality * 0.3 +
                knowledge_accuracy * 0.3 +
                response_speed * 0.2 +
                user_satisfaction * 0.2
            )
            
            # í’ˆì§ˆ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            self.quality_metrics.update({
                'dialogue_quality': dialogue_quality,
                'knowledge_accuracy': knowledge_accuracy,
                'response_time': response_speed,
                'user_satisfaction': user_satisfaction
            })
            
            # ê°œì„  í•„ìš” ì˜ì—­ ì‹ë³„
            improvements_needed = self._identify_improvements(self.quality_metrics)
            
            # ê°œì„  ê³„íš ìˆ˜ë¦½
            improvement_plan = self._create_improvement_plan(improvements_needed)
            
            # í’ˆì§ˆ ë¦¬í¬íŠ¸ ìƒì„±
            self._generate_quality_report(overall_quality, improvements_needed)
            
            self._complete_task(task_id, 'success')
            
        except Exception as e:
            logger.error(f"í’ˆì§ˆ ê²€í†  ì˜¤ë¥˜: {e}")
            self._complete_task(task_id, 'failed', str(e))
    
    async def optimize_systems(self):
        """ì‹œìŠ¤í…œ ìµœì í™”"""
        logger.info("âš¡ ì‹œìŠ¤í…œ ìµœì í™” ì‹œì‘...")
        
        task_id = self._start_task('optimization')
        
        try:
            # ë©”ëª¨ë¦¬ ìµœì í™”
            self._optimize_memory()
            
            # ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”
            self._optimize_databases()
            
            # ëª¨ë¸ ìµœì í™”
            self._optimize_models()
            
            # ìºì‹œ ìµœì í™”
            self._optimize_caches()
            
            # ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
            performance = self._run_performance_benchmark()
            
            # ìµœì í™” ê²°ê³¼ ê¸°ë¡
            self._record_optimization_results(performance)
            
            self._complete_task(task_id, 'success')
            
        except Exception as e:
            logger.error(f"ìµœì í™” ì˜¤ë¥˜: {e}")
            self._complete_task(task_id, 'failed', str(e))
    
    def _hourly_learning(self):
        """ì‹œê°„ë³„ í•™ìŠµ ì‘ì—…"""
        logger.info("â° ì‹œê°„ë³„ í•™ìŠµ ì‘ì—… ì‹¤í–‰")
        
        try:
            # Stack Overflow ìµœì‹  ì§ˆë¬¸ í•™ìŠµ
            self._learn_from_stackoverflow()
            
            # ì‚¬ìš©ì í”¼ë“œë°± í•™ìŠµ
            self._learn_from_feedback()
            
            # ì‹¤ì‹œê°„ íŠ¸ë Œë“œ í•™ìŠµ
            self._learn_from_trends()
            
        except Exception as e:
            logger.error(f"ì‹œê°„ë³„ í•™ìŠµ ì˜¤ë¥˜: {e}")
    
    def _quick_learning(self):
        """ë¹ ë¥¸ í•™ìŠµ ì‘ì—… (10ë¶„ë§ˆë‹¤)"""
        try:
            # ìµœê·¼ ëŒ€í™” ë¶„ì„
            self._analyze_recent_conversations()
            
            # ì—ëŸ¬ íŒ¨í„´ í•™ìŠµ
            self._learn_from_errors()
            
            # ìºì‹œ ì—…ë°ì´íŠ¸
            self._update_caches()
            
        except Exception as e:
            logger.error(f"ë¹ ë¥¸ í•™ìŠµ ì˜¤ë¥˜: {e}")
    
    def _learn_from_stackoverflow(self):
        """Stack Overflowì—ì„œ í•™ìŠµ"""
        try:
            questions = self.learning_sources['stackoverflow'].get_recent_questions(
                tags=['c#', 'unity3d'],
                limit=20
            )
            
            for question in questions:
                # ì§ˆë¬¸ ë¶„ì„
                analysis = self._analyze_question(question)
                
                # ë‹µë³€ì´ ìˆìœ¼ë©´ í•™ìŠµ
                if question.get('accepted_answer'):
                    self._learn_from_qa_pair(
                        question['title'] + ' ' + question['body'],
                        question['accepted_answer']
                    )
            
        except Exception as e:
            logger.error(f"Stack Overflow í•™ìŠµ ì˜¤ë¥˜: {e}")
    
    def _learn_from_feedback(self):
        """ì‚¬ìš©ì í”¼ë“œë°±ì—ì„œ í•™ìŠµ"""
        try:
            # ìµœê·¼ í”¼ë“œë°± ë¡œë“œ
            feedbacks = self.learning_sources['feedback'].get_recent_feedbacks()
            
            for feedback in feedbacks:
                if feedback['rating'] < 3:
                    # ë¶€ì •ì  í”¼ë“œë°± ë¶„ì„
                    self._analyze_negative_feedback(feedback)
                else:
                    # ê¸ì •ì  í”¼ë“œë°±ì—ì„œ ì„±ê³µ íŒ¨í„´ í•™ìŠµ
                    self._learn_success_pattern(feedback)
            
        except Exception as e:
            logger.error(f"í”¼ë“œë°± í•™ìŠµ ì˜¤ë¥˜: {e}")
    
    def _learn_from_trends(self):
        """ìµœì‹  íŠ¸ë Œë“œ í•™ìŠµ"""
        try:
            # GitHub íŠ¸ë Œë”©
            github_trends = self.learning_sources['github'].get_trending_topics()
            
            # ì»¤ë®¤ë‹ˆí‹° íŠ¸ë Œë“œ
            community_trends = self.learning_sources['community'].get_hot_topics()
            
            # íŠ¸ë Œë“œ ë¶„ì„ ë° í•™ìŠµ
            all_trends = github_trends + community_trends
            
            for trend in all_trends:
                self._incorporate_trend(trend)
            
        except Exception as e:
            logger.error(f"íŠ¸ë Œë“œ í•™ìŠµ ì˜¤ë¥˜: {e}")
    
    def _analyze_recent_conversations(self):
        """ìµœê·¼ ëŒ€í™” ë¶„ì„"""
        # ìµœê·¼ 10ë¶„ê°„ì˜ ëŒ€í™” ë¶„ì„
        recent_convs = self.components['base_learner'].short_term_memory
        
        if recent_convs:
            # ì£¼ìš” ì£¼ì œ ì¶”ì¶œ
            topics = self._extract_topics(recent_convs)
            
            # ê°ì • íŒ¨í„´ ë¶„ì„
            emotion_patterns = self._analyze_emotion_patterns(recent_convs)
            
            # ì„±ê³µ/ì‹¤íŒ¨ íŒ¨í„´ ë¶„ì„
            success_patterns = self._analyze_success_patterns(recent_convs)
            
            # í•™ìŠµ ì ìš©
            self._apply_conversation_insights(topics, emotion_patterns, success_patterns)
    
    def _learn_from_errors(self):
        """ì—ëŸ¬ì—ì„œ í•™ìŠµ"""
        # ìµœê·¼ ì—ëŸ¬ ë¡œê·¸ ë¶„ì„
        error_logs = self._get_recent_error_logs()
        
        if error_logs:
            self.components['csharp_learner'].learn_from_errors(error_logs)
    
    def _update_caches(self):
        """ìºì‹œ ì—…ë°ì´íŠ¸"""
        # ìì£¼ ì‚¬ìš©ë˜ëŠ” ì‘ë‹µ ìºì‹±
        self._update_response_cache()
        
        # ì§€ì‹ ìºì‹œ ì—…ë°ì´íŠ¸
        self._update_knowledge_cache()
    
    def _start_task(self, task_type: str) -> int:
        """í•™ìŠµ ì‘ì—… ì‹œì‘"""
        conn = sqlite3.connect(str(self.data_path / "pipeline.db"))
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO learning_tasks (task_type, start_time, status)
            VALUES (?, ?, 'running')
        ''', (task_type, datetime.now()))
        
        task_id = cursor.lastrowid
        conn.commit()
        conn.close()
        
        self.learning_state['current_task'] = task_type
        
        return task_id
    
    def _complete_task(self, task_id: int, status: str, error: str = None):
        """í•™ìŠµ ì‘ì—… ì™„ë£Œ"""
        conn = sqlite3.connect(str(self.data_path / "pipeline.db"))
        cursor = conn.cursor()
        
        cursor.execute('''
            UPDATE learning_tasks 
            SET end_time = ?, status = ?, errors = ?
            WHERE id = ?
        ''', (datetime.now(), status, error, task_id))
        
        conn.commit()
        conn.close()
        
        self.learning_state['tasks_completed'] += 1
        self.learning_state['current_task'] = None
    
    def _record_learning_result(self, component: str, improvement_type: str,
                              before: float, after: float, description: str = ""):
        """í•™ìŠµ ê²°ê³¼ ê¸°ë¡"""
        conn = sqlite3.connect(str(self.data_path / "pipeline.db"))
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO learning_results 
            (component, improvement_type, before_value, after_value, description)
            VALUES (?, ?, ?, ?, ?)
        ''', (component, improvement_type, before, after, description))
        
        conn.commit()
        conn.close()
    
    async def _download_repo(self, repo: Dict) -> Optional[str]:
        """GitHub ì €ì¥ì†Œ ë‹¤ìš´ë¡œë“œ"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” git clone ì‚¬ìš©
        # ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜
        return f"/tmp/repos/{repo['name']}"
    
    def _extract_best_practices(self, patterns: List[Dict]) -> List[Dict]:
        """ëª¨ë²” ì‚¬ë¡€ ì¶”ì¶œ"""
        best_practices = []
        
        for pattern in patterns:
            if pattern.get('quality_score', 0) > 0.8:
                best_practices.append({
                    'type': pattern['type'],
                    'description': f"High quality {pattern['type']} pattern",
                    'example': pattern.get('implementation', '')
                })
        
        return best_practices
    
    def _store_code_insights(self, repo: Dict, patterns: List[Dict], 
                           best_practices: List[Dict]):
        """ì½”ë“œ ì¸ì‚¬ì´íŠ¸ ì €ì¥"""
        conn = sqlite3.connect(str(self.data_path / "pipeline.db"))
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO learning_sources 
            (source_type, source_url, content_hash, learning_value, metadata)
            VALUES (?, ?, ?, ?, ?)
        ''', (
            'github',
            repo['url'],
            repo.get('commit_hash', ''),
            len(patterns) * 0.1 + len(best_practices) * 0.2,
            json.dumps({
                'patterns': len(patterns),
                'best_practices': len(best_practices)
            })
        ))
        
        conn.commit()
        conn.close()
    
    def _load_collected_patterns(self) -> List[Dict]:
        """ìˆ˜ì§‘ëœ íŒ¨í„´ ë¡œë“œ"""
        # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ íŒ¨í„´ ë¡œë“œ
        return []
    
    def _cluster_patterns(self, patterns: List[Dict]) -> Dict[str, List[Dict]]:
        """íŒ¨í„´ í´ëŸ¬ìŠ¤í„°ë§"""
        clustered = defaultdict(list)
        
        for pattern in patterns:
            pattern_type = pattern.get('type', 'unknown')
            clustered[pattern_type].append(pattern)
        
        return dict(clustered)
    
    def _generalize_patterns(self, clustered_patterns: Dict[str, List[Dict]]) -> List[Dict]:
        """íŒ¨í„´ ì¼ë°˜í™”"""
        generalized = []
        
        for pattern_type, patterns in clustered_patterns.items():
            if len(patterns) >= 3:  # 3ê°œ ì´ìƒì˜ ìœ ì‚¬ íŒ¨í„´ì´ ìˆì„ ë•Œë§Œ
                generalized.append({
                    'type': pattern_type,
                    'instances': len(patterns),
                    'common_features': self._extract_common_features(patterns),
                    'variations': self._extract_variations(patterns)
                })
        
        return generalized
    
    def _extract_common_features(self, patterns: List[Dict]) -> List[str]:
        """ê³µí†µ íŠ¹ì§• ì¶”ì¶œ"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë” ì •êµí•œ ë¶„ì„
        return ['common_feature_1', 'common_feature_2']
    
    def _extract_variations(self, patterns: List[Dict]) -> List[Dict]:
        """ë³€í˜• ì¶”ì¶œ"""
        return [{'variation': 'type_1'}, {'variation': 'type_2'}]
    
    def _evaluate_pattern_quality(self, pattern: Dict) -> float:
        """íŒ¨í„´ í’ˆì§ˆ í‰ê°€"""
        score = 0.5
        
        # ì¸ìŠ¤í„´ìŠ¤ ìˆ˜
        if pattern['instances'] > 10:
            score += 0.2
        elif pattern['instances'] > 5:
            score += 0.1
        
        # ê³µí†µ íŠ¹ì§• ìˆ˜
        if len(pattern['common_features']) > 5:
            score += 0.2
        
        # ë³€í˜• ë‹¤ì–‘ì„±
        if len(pattern['variations']) > 3:
            score += 0.1
        
        return min(1.0, score)
    
    def _store_generalized_patterns(self, patterns: List[Dict]):
        """ì¼ë°˜í™”ëœ íŒ¨í„´ ì €ì¥"""
        for pattern in patterns:
            logger.info(f"ê³ í’ˆì§ˆ íŒ¨í„´ ì €ì¥: {pattern['type']} (í’ˆì§ˆ: {pattern['quality_score']:.2f})")
    
    def _integrate_knowledge(self, dialogue: Dict, csharp: Dict, base: Dict) -> Dict:
        """ì§€ì‹ í†µí•©"""
        return {
            'dialogue_patterns': dialogue,
            'csharp_expertise': csharp,
            'base_learning': base,
            'integrated_at': datetime.now()
        }
    
    def _validate_knowledge(self, knowledge: Dict) -> Dict:
        """ì§€ì‹ ê²€ì¦"""
        # ëª¨ìˆœ ì²´í¬, ì •í™•ì„± ê²€ì¦ ë“±
        return knowledge
    
    def _apply_knowledge_updates(self, knowledge: Dict):
        """ì§€ì‹ ì—…ë°ì´íŠ¸ ì ìš©"""
        # ê° ì»´í¬ë„ŒíŠ¸ì— ì—…ë°ì´íŠ¸ ì ìš©
        pass
    
    def _calculate_knowledge_accuracy(self) -> float:
        """ì§€ì‹ ì •í™•ë„ ê³„ì‚°"""
        return 0.85  # ì˜ˆì‹œ ê°’
    
    async def _evaluate_dialogue_quality(self) -> float:
        """ëŒ€í™” í’ˆì§ˆ í‰ê°€"""
        # ìµœê·¼ ëŒ€í™” ìƒ˜í”Œë§ ë° í‰ê°€
        return 0.9
    
    async def _evaluate_knowledge_accuracy(self) -> float:
        """ì§€ì‹ ì •í™•ë„ í‰ê°€"""
        # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ìœ¼ë¡œ í‰ê°€
        return 0.85
    
    async def _evaluate_response_speed(self) -> float:
        """ì‘ë‹µ ì†ë„ í‰ê°€"""
        # í‰ê·  ì‘ë‹µ ì‹œê°„ ì¸¡ì •
        return 0.95
    
    async def _evaluate_user_satisfaction(self) -> float:
        """ì‚¬ìš©ì ë§Œì¡±ë„ í‰ê°€"""
        # í”¼ë“œë°± ë¶„ì„
        return 0.88
    
    def _identify_improvements(self, metrics: Dict[str, float]) -> List[str]:
        """ê°œì„  í•„ìš” ì˜ì—­ ì‹ë³„"""
        improvements = []
        
        for metric, value in metrics.items():
            if value < 0.8:
                improvements.append(metric)
        
        return improvements
    
    def _create_improvement_plan(self, improvements: List[str]) -> Dict:
        """ê°œì„  ê³„íš ìˆ˜ë¦½"""
        plan = {}
        
        for area in improvements:
            if area == 'dialogue_quality':
                plan[area] = 'Increase training on conversation patterns'
            elif area == 'knowledge_accuracy':
                plan[area] = 'Update documentation learning'
        
        return plan
    
    def _generate_quality_report(self, overall_quality: float, improvements: List[str]):
        """í’ˆì§ˆ ë¦¬í¬íŠ¸ ìƒì„±"""
        report = f"""
ğŸ“Š í’ˆì§ˆ ë¦¬í¬íŠ¸
================
ì „ì²´ í’ˆì§ˆ ì ìˆ˜: {overall_quality:.2%}

ê°œì„  í•„ìš” ì˜ì—­:
{chr(10).join(f'- {imp}' for imp in improvements)}

ìƒì„± ì‹œê°„: {datetime.now()}
        """
        
        logger.info(report)
    
    def _optimize_memory(self):
        """ë©”ëª¨ë¦¬ ìµœì í™”"""
        # ë¶ˆí•„ìš”í•œ ë°ì´í„° ì •ë¦¬
        for component in self.components.values():
            if hasattr(component, 'cleanup_memory'):
                component.cleanup_memory()
    
    def _optimize_databases(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”"""
        # VACUUM, ì¸ë±ìŠ¤ ì¬êµ¬ì„± ë“±
        databases = [
            self.data_path / "pipeline.db",
            self.base_path / "autoci_brain.db",
            self.base_path / "csharp_knowledge" / "expert_knowledge.db"
        ]
        
        for db_path in databases:
            if db_path.exists():
                conn = sqlite3.connect(str(db_path))
                conn.execute("VACUUM")
                conn.close()
    
    def _optimize_models(self):
        """ëª¨ë¸ ìµœì í™”"""
        # ëª¨ë¸ ê°€ì¤‘ì¹˜ ì •ë¦¬, ì–‘ìí™” ë“±
        pass
    
    def _optimize_caches(self):
        """ìºì‹œ ìµœì í™”"""
        # ì˜¤ë˜ëœ ìºì‹œ í•­ëª© ì œê±°
        pass
    
    def _run_performance_benchmark(self) -> Dict[str, float]:
        """ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
        return {
            'response_time': 0.1,
            'throughput': 100,
            'memory_usage': 500
        }
    
    def _record_optimization_results(self, performance: Dict):
        """ìµœì í™” ê²°ê³¼ ê¸°ë¡"""
        logger.info(f"ìµœì í™” ì™„ë£Œ: {performance}")
    
    def _analyze_question(self, question: Dict) -> Dict:
        """ì§ˆë¬¸ ë¶„ì„"""
        return {
            'topic': 'c#',
            'difficulty': 'medium',
            'tags': question.get('tags', [])
        }
    
    def _learn_from_qa_pair(self, question: str, answer: str):
        """Q&A ìŒì—ì„œ í•™ìŠµ"""
        self.components['base_learner'].learn_from_conversation(
            question, answer, {'source': 'stackoverflow'}
        )
    
    def _analyze_negative_feedback(self, feedback: Dict):
        """ë¶€ì •ì  í”¼ë“œë°± ë¶„ì„"""
        # ì‹¤íŒ¨ ì›ì¸ ë¶„ì„
        pass
    
    def _learn_success_pattern(self, feedback: Dict):
        """ì„±ê³µ íŒ¨í„´ í•™ìŠµ"""
        # ì„±ê³µ ìš”ì¸ ë¶„ì„
        pass
    
    def _incorporate_trend(self, trend: Dict):
        """íŠ¸ë Œë“œ ë°˜ì˜"""
        # ìƒˆë¡œìš´ ê¸°ìˆ , íŒ¨í„´ í•™ìŠµ
        pass
    
    def _extract_topics(self, conversations: list) -> List[str]:
        """ì£¼ì œ ì¶”ì¶œ"""
        topics = []
        for conv in conversations:
            if 'topic' in conv:
                topics.append(conv['topic'])
        return list(set(topics))
    
    def _analyze_emotion_patterns(self, conversations: list) -> Dict:
        """ê°ì • íŒ¨í„´ ë¶„ì„"""
        emotions = defaultdict(int)
        for conv in conversations:
            if 'emotion' in conv:
                emotions[conv['emotion']] += 1
        return dict(emotions)
    
    def _analyze_success_patterns(self, conversations: list) -> List[Dict]:
        """ì„±ê³µ íŒ¨í„´ ë¶„ì„"""
        success_patterns = []
        for conv in conversations:
            if conv.get('quality_score', 0) > 0.8:
                success_patterns.append({
                    'pattern': conv.get('pattern', ''),
                    'score': conv['quality_score']
                })
        return success_patterns
    
    def _apply_conversation_insights(self, topics: List[str], 
                                   emotions: Dict, patterns: List[Dict]):
        """ëŒ€í™” ì¸ì‚¬ì´íŠ¸ ì ìš©"""
        # í•™ìŠµëœ ë‚´ìš©ì„ ì‹œìŠ¤í…œì— ë°˜ì˜
        pass
    
    def _get_recent_error_logs(self) -> str:
        """ìµœê·¼ ì—ëŸ¬ ë¡œê·¸ ê°€ì ¸ì˜¤ê¸°"""
        # ì‹¤ì œë¡œëŠ” ë¡œê·¸ íŒŒì¼ì—ì„œ ì½ê¸°
        return ""
    
    def _update_response_cache(self):
        """ì‘ë‹µ ìºì‹œ ì—…ë°ì´íŠ¸"""
        # ìì£¼ ì‚¬ìš©ë˜ëŠ” ì‘ë‹µ ìºì‹±
        pass
    
    def _update_knowledge_cache(self):
        """ì§€ì‹ ìºì‹œ ì—…ë°ì´íŠ¸"""
        # ìì£¼ ì¡°íšŒë˜ëŠ” ì§€ì‹ ìºì‹±
        pass
    
    def get_status(self) -> Dict[str, Any]:
        """íŒŒì´í”„ë¼ì¸ ìƒíƒœ"""
        return {
            'is_running': self.learning_state['is_running'],
            'current_task': self.learning_state['current_task'],
            'tasks_completed': self.learning_state['tasks_completed'],
            'quality_metrics': self.quality_metrics,
            'last_learning': self.learning_state['last_learning_time']
        }


class GitHubLearner:
    """GitHubì—ì„œ í•™ìŠµ"""
    
    async def get_trending_csharp_repos(self) -> List[Dict]:
        """C# ì¸ê¸° ì €ì¥ì†Œ ê°€ì ¸ì˜¤ê¸°"""
        # GitHub API ì‚¬ìš©
        return [
            {'name': 'dotnet/runtime', 'url': 'https://github.com/dotnet/runtime'},
            {'name': 'Unity-Technologies/ml-agents', 'url': 'https://github.com/Unity-Technologies/ml-agents'}
        ]
    
    def get_trending_topics(self) -> List[Dict]:
        """íŠ¸ë Œë”© í† í”½"""
        return [
            {'topic': 'blazor', 'trend_score': 0.9},
            {'topic': 'minimal-apis', 'trend_score': 0.85}
        ]


class StackOverflowLearner:
    """Stack Overflowì—ì„œ í•™ìŠµ"""
    
    def get_recent_questions(self, tags: List[str], limit: int = 10) -> List[Dict]:
        """ìµœê·¼ ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸°"""
        # Stack Exchange API ì‚¬ìš©
        return []


class DocumentationLearner:
    """ê³µì‹ ë¬¸ì„œì—ì„œ í•™ìŠµ"""
    
    async def fetch_unity_docs(self) -> Dict:
        """Unity ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°"""
        return {'topics': ['scripting', 'physics', 'ui']}


class CommunityLearner:
    """ì»¤ë®¤ë‹ˆí‹°ì—ì„œ í•™ìŠµ"""
    
    def get_hot_topics(self) -> List[Dict]:
        """ì¸ê¸° ì£¼ì œ"""
        return [
            {'topic': 'ecs', 'source': 'unity-forum'},
            {'topic': 'async-await', 'source': 'reddit'}
        ]


class FeedbackLearner:
    """í”¼ë“œë°±ì—ì„œ í•™ìŠµ"""
    
    def get_recent_feedbacks(self) -> List[Dict]:
        """ìµœê·¼ í”¼ë“œë°±"""
        return []


# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
if __name__ == "__main__":
    print("ğŸš€ 24ì‹œê°„ ìë™ í•™ìŠµ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    pipeline = ContinuousLearningPipeline()
    
    # íŒŒì´í”„ë¼ì¸ ì‹œì‘
    pipeline.start()
    
    print("\nâœ… íŒŒì´í”„ë¼ì¸ ì‹œì‘ë¨!")
    print(f"ìƒíƒœ: {pipeline.get_status()}")
    
    # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì ì‹œ ì‹¤í–‰
    time.sleep(5)
    
    # ì¤‘ì§€
    pipeline.stop()
    
    print("\nğŸ›‘ íŒŒì´í”„ë¼ì¸ ì¤‘ì§€ë¨")