#!/usr/bin/env python3
"""
C# ì „ë¬¸ê°€ í•™ìŠµ ì‹œìŠ¤í…œ ì‹œì‘ ìŠ¤í¬ë¦½íŠ¸
24ì‹œê°„ ìë™ í•™ìŠµ ë° ì½”ë“œ ê°œì„  ì„œë¹„ìŠ¤ ì‹¤í–‰
"""

import os
import sys
import json
import asyncio
import logging
from pathlib import Path
from datetime import datetime
import subprocess

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('expert_learning_startup.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class ExpertLearningStartup:
    """ì „ë¬¸ê°€ í•™ìŠµ ì‹œìŠ¤í…œ ì‹œì‘ ê´€ë¦¬ì"""
    
    def __init__(self):
        self.base_dir = Path(".")
        self.models_dir = self.base_dir / "MyAIWebApp" / "Models"
        self.venv_path = self.models_dir / "llm_venv"
        self.requirements = [
            "torch>=2.0.0",
            "transformers>=4.30.0",
            "fastapi>=0.100.0",
            "uvicorn>=0.22.0",
            "aiohttp>=3.8.0",
            "beautifulsoup4>=4.12.0",
            "requests>=2.31.0",
            "watchdog>=3.0.0",
            "accelerate>=0.20.0",
            "sentencepiece>=0.1.99",
            "protobuf>=4.23.0",
            "datasets>=2.14.0",
            "peft>=0.4.0",  # Parameter-Efficient Fine-Tuning
            "bitsandbytes>=0.40.0",  # 8-bit quantization
            "scipy>=1.11.0",
            "scikit-learn>=1.3.0",
            "pandas>=2.0.0",
            "numpy>=1.24.0",
            "matplotlib>=3.7.0",
            "seaborn>=0.12.0",
            "tqdm>=4.65.0",
            "colorama>=0.4.6",
            "python-dotenv>=1.0.0"
        ]
        
    def check_system_requirements(self):
        """ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸"""
        logger.info("ğŸ” ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸ ì¤‘...")
        
        # Python ë²„ì „ í™•ì¸
        python_version = sys.version_info
        if python_version.major < 3 or (python_version.major == 3 and python_version.minor < 8):
            logger.error("âŒ Python 3.8 ì´ìƒì´ í•„ìš”í•©ë‹ˆë‹¤!")
            return False
        logger.info(f"âœ… Python {python_version.major}.{python_version.minor} í™•ì¸")
        
        # Git í™•ì¸
        try:
            subprocess.run(["git", "--version"], capture_output=True, check=True)
            logger.info("âœ… Git ì„¤ì¹˜ í™•ì¸")
        except:
            logger.error("âŒ Gitì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
            return False
        
        # ë©”ëª¨ë¦¬ í™•ì¸
        try:
            import psutil
            mem = psutil.virtual_memory()
            total_gb = mem.total / (1024**3)
            if total_gb < 16:
                logger.warning(f"âš ï¸  ë©”ëª¨ë¦¬ê°€ {total_gb:.1f}GBì…ë‹ˆë‹¤. 16GB ì´ìƒ ê¶Œì¥!")
            else:
                logger.info(f"âœ… ë©”ëª¨ë¦¬ {total_gb:.1f}GB í™•ì¸")
        except:
            logger.warning("âš ï¸  psutilì´ ì—†ì–´ ë©”ëª¨ë¦¬ë¥¼ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        return True
    
    def setup_environment(self):
        """í™˜ê²½ ì„¤ì •"""
        logger.info("ğŸ› ï¸  ê°œë°œ í™˜ê²½ ì„¤ì • ì¤‘...")
        
        # í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±
        directories = [
            self.base_dir / "expert_training_data",
            self.base_dir / "expert_training_data" / "github_projects",
            self.base_dir / "expert_training_data" / "stackoverflow",
            self.base_dir / "expert_training_data" / "microsoft_docs",
            self.base_dir / "expert_training_data" / "improvements",
            self.base_dir / "expert_training_data" / "models",
            self.base_dir / "expert_training_data" / "checkpoints",
            self.base_dir / "expert_training_data" / "logs"
        ]
        
        for dir_path in directories:
            dir_path.mkdir(parents=True, exist_ok=True)
            logger.info(f"ğŸ“ ë””ë ‰í† ë¦¬ ìƒì„±: {dir_path}")
        
        # ì„¤ì • íŒŒì¼ ìƒì„±
        config = {
            "github_token": os.getenv("GITHUB_TOKEN", ""),
            "stackoverflow_key": os.getenv("STACKOVERFLOW_KEY", ""),
            "model_name": "codellama/CodeLlama-7b-Instruct-hf",
            "learning_config": {
                "batch_size": 4,
                "learning_rate": 1e-5,
                "epochs": 3,
                "max_length": 2048,
                "warmup_steps": 500,
                "save_steps": 1000,
                "evaluation_steps": 500,
                "gradient_checkpointing": True,
                "fp16": True,  # Mixed precision training
                "load_in_8bit": True  # 8-bit quantization
            },
            "crawler_config": {
                "github_stars_threshold": 1000,
                "stackoverflow_score_threshold": 50,
                "code_quality_threshold": 0.7,
                "max_files_per_repo": 100,
                "crawl_interval_hours": 4
            },
            "improvement_config": {
                "scan_interval_minutes": 5,
                "max_files_per_scan": 10,
                "min_quality_for_improvement": 0.7,
                "auto_fix": False  # ìë™ ìˆ˜ì • ë¹„í™œì„±í™” (ì•ˆì „ì„ ìœ„í•´)
            }
        }
        
        config_path = self.base_dir / "expert_learning_config.json"
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        logger.info(f"âš™ï¸  ì„¤ì • íŒŒì¼ ìƒì„±: {config_path}")
        
        # .env íŒŒì¼ ìƒì„± (ì—†ëŠ” ê²½ìš°)
        env_path = self.base_dir / ".env"
        if not env_path.exists():
            with open(env_path, 'w') as f:
                f.write("# GitHub API Token (ì„ íƒì‚¬í•­ - Rate limit ì¦ê°€)\n")
                f.write("# https://github.com/settings/tokens ì—ì„œ ìƒì„±\n")
                f.write("GITHUB_TOKEN=\n\n")
                f.write("# Stack Exchange API Key (ì„ íƒì‚¬í•­)\n")
                f.write("# https://stackapps.com/apps/oauth/register ì—ì„œ ìƒì„±\n")
                f.write("STACKOVERFLOW_KEY=\n")
            logger.info("ğŸ“ .env íŒŒì¼ ìƒì„± - API í‚¤ë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš” (ì„ íƒì‚¬í•­)")
    
    def install_dependencies(self):
        """ì˜ì¡´ì„± ì„¤ì¹˜"""
        logger.info("ğŸ“¦ í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘...")
        
        # requirements.txt ìƒì„±
        req_path = self.base_dir / "requirements_expert.txt"
        with open(req_path, 'w') as f:
            for req in self.requirements:
                f.write(f"{req}\n")
        
        # pip ì—…ê·¸ë ˆì´ë“œ
        logger.info("ğŸ”„ pip ì—…ê·¸ë ˆì´ë“œ...")
        subprocess.run([sys.executable, "-m", "pip", "install", "--upgrade", "pip"])
        
        # íŒ¨í‚¤ì§€ ì„¤ì¹˜
        logger.info("ğŸ“¥ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
        result = subprocess.run(
            [sys.executable, "-m", "pip", "install", "-r", str(req_path)],
            capture_output=True,
            text=True
        )
        
        if result.returncode != 0:
            logger.error(f"âŒ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì‹¤íŒ¨: {result.stderr}")
            return False
        
        logger.info("âœ… ëª¨ë“  íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ!")
        return True
    
    def download_model(self):
        """Code Llama ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"""
        logger.info("ğŸ¤– Code Llama 7B-Instruct ëª¨ë¸ í™•ì¸ ì¤‘...")
        
        model_path = self.base_dir / "CodeLlama-7b-Instruct-hf"
        
        if model_path.exists() and any(model_path.iterdir()):
            logger.info("âœ… ëª¨ë¸ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤!")
            return True
        
        logger.info("ğŸ“¥ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘... (ì•½ 13GB)")
        
        # ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸
        download_script = """
import os
from huggingface_hub import snapshot_download
import torch

model_id = "codellama/CodeLlama-7b-Instruct-hf"
local_dir = "./CodeLlama-7b-Instruct-hf"

print(f"ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘: {model_id}")
snapshot_download(
    repo_id=model_id,
    local_dir=local_dir,
    local_dir_use_symlinks=False,
    resume_download=True
)
print("âœ… ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")

# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
if torch.cuda.is_available():
    print(f"âœ… GPU ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.get_device_name(0)}")
    print(f"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")
else:
    print("âš ï¸  GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPUë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤ (ëŠë¦¼)")
"""
        
        # ì„ì‹œ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ìƒì„±
        temp_script = self.base_dir / "temp_download_model.py"
        with open(temp_script, 'w') as f:
            f.write(download_script)
        
        # ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
        result = subprocess.run([sys.executable, str(temp_script)], capture_output=True, text=True)
        
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        temp_script.unlink()
        
        if result.returncode != 0:
            logger.error(f"âŒ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {result.stderr}")
            return False
        
        print(result.stdout)
        return True
    
    def create_startup_scripts(self):
        """ì‹œì‘ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"""
        logger.info("ğŸ“ ì‹œì‘ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì¤‘...")
        
        # Windows ë°°ì¹˜ íŒŒì¼
        bat_content = r"""@echo off
echo ğŸš€ C# Expert Learning System ì‹œì‘...
echo.

REM Python ê°€ìƒí™˜ê²½ í™œì„±í™” (ìˆëŠ” ê²½ìš°)
if exist "MyAIWebApp\Models\llm_venv\Scripts\activate.bat" (
    call MyAIWebApp\Models\llm_venv\Scripts\activate.bat
)

REM ì „ë¬¸ê°€ í•™ìŠµ ì‹œìŠ¤í…œ ì‹œì‘
echo ğŸ§  24ì‹œê°„ ì „ë¬¸ê°€ í•™ìŠµ ì‹œìŠ¤í…œ ì‹œì‘...
start "Expert Learning" python csharp_expert_crawler.py

REM 5ì´ˆ ëŒ€ê¸°
timeout /t 5 /nobreak > nul

REM í–¥ìƒëœ ì„œë²„ ì‹œì‘ (ìˆëŠ” ê²½ìš°)
if exist "MyAIWebApp\\Models\\enhanced_server.py" (
    echo ğŸŒ AI ì„œë²„ ì‹œì‘...
    cd MyAIWebApp\\Models
    start "AI Server" python -m uvicorn enhanced_server:app --host 0.0.0.0 --port 8000 --reload
    cd ..\..
)

echo.
echo âœ… ëª¨ë“  ì„œë¹„ìŠ¤ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤!
echo.
echo ğŸ“Š í•™ìŠµ ì§„í–‰ ìƒí™© í™•ì¸: learning_stats.json
echo ğŸ“ ë¡œê·¸ í™•ì¸: csharp_expert_learning.log
echo.
echo ì¢…ë£Œí•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”...
pause
"""
        
        with open(self.base_dir / "start_expert_learning.bat", 'w') as f:
            f.write(bat_content)
        
        # Linux/Mac ì‰˜ ìŠ¤í¬ë¦½íŠ¸
        sh_content = """#!/bin/bash
echo "ğŸš€ C# Expert Learning System ì‹œì‘..."
echo

# Python ê°€ìƒí™˜ê²½ í™œì„±í™” (ìˆëŠ” ê²½ìš°)
if [ -f "MyAIWebApp/Models/llm_venv/bin/activate" ]; then
    source MyAIWebApp/Models/llm_venv/bin/activate
fi

# ì „ë¬¸ê°€ í•™ìŠµ ì‹œìŠ¤í…œ ì‹œì‘
echo "ğŸ§  24ì‹œê°„ ì „ë¬¸ê°€ í•™ìŠµ ì‹œìŠ¤í…œ ì‹œì‘..."
python csharp_expert_crawler.py &
LEARNING_PID=$!

# 5ì´ˆ ëŒ€ê¸°
sleep 5

# í–¥ìƒëœ ì„œë²„ ì‹œì‘ (ìˆëŠ” ê²½ìš°)
if [ -f "MyAIWebApp/Models/enhanced_server.py" ]; then
    echo "ğŸŒ AI ì„œë²„ ì‹œì‘..."
    cd MyAIWebApp/Models
    uvicorn enhanced_server:app --host 0.0.0.0 --port 8000 --reload &
    SERVER_PID=$!
    cd ../..
fi

echo
echo "âœ… ëª¨ë“  ì„œë¹„ìŠ¤ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤!"
echo
echo "ğŸ“Š í•™ìŠµ ì§„í–‰ ìƒí™© í™•ì¸: learning_stats.json"
echo "ğŸ“ ë¡œê·¸ í™•ì¸: csharp_expert_learning.log"
echo
echo "ì¢…ë£Œí•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”..."

# ì¢…ë£Œ ì‹œê·¸ë„ ëŒ€ê¸°
trap "kill $LEARNING_PID $SERVER_PID 2>/dev/null; exit" INT TERM
wait
"""
        
        sh_path = self.base_dir / "start_expert_learning.sh"
        with open(sh_path, 'w') as f:
            f.write(sh_content)
        
        # ì‹¤í–‰ ê¶Œí•œ ë¶€ì—¬ (Linux/Mac)
        if os.name != 'nt':
            os.chmod(sh_path, 0o755)
        
        logger.info("âœ… ì‹œì‘ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì™„ë£Œ!")
    
    def create_monitoring_dashboard(self):
        """ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ ìƒì„±"""
        logger.info("ğŸ“Š ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ ìƒì„± ì¤‘...")
        
        dashboard_html = """<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>C# Expert Learning Dashboard</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background-color: #f5f5f5;
            margin: 0;
            padding: 20px;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
        }
        h1 {
            color: #333;
            text-align: center;
            margin-bottom: 30px;
        }
        .stats-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin-bottom: 30px;
        }
        .stat-card {
            background: white;
            border-radius: 10px;
            padding: 20px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        .stat-card h3 {
            margin: 0 0 10px 0;
            color: #666;
            font-size: 16px;
        }
        .stat-value {
            font-size: 32px;
            font-weight: bold;
            color: #007bff;
        }
        .chart-container {
            background: white;
            border-radius: 10px;
            padding: 20px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            margin-bottom: 20px;
        }
        .log-container {
            background: #1e1e1e;
            color: #d4d4d4;
            border-radius: 10px;
            padding: 20px;
            font-family: 'Consolas', 'Monaco', monospace;
            font-size: 14px;
            max-height: 400px;
            overflow-y: auto;
        }
        .refresh-btn {
            background: #28a745;
            color: white;
            border: none;
            padding: 10px 20px;
            border-radius: 5px;
            cursor: pointer;
            font-size: 16px;
            margin-bottom: 20px;
        }
        .refresh-btn:hover {
            background: #218838;
        }
        .progress-bar {
            background: #e0e0e0;
            border-radius: 10px;
            height: 20px;
            overflow: hidden;
            margin: 10px 0;
        }
        .progress-fill {
            background: linear-gradient(90deg, #007bff, #0056b3);
            height: 100%;
            transition: width 0.3s ease;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ§  C# Expert Learning Dashboard</h1>
        
        <button class="refresh-btn" onclick="refreshData()">ğŸ”„ ìƒˆë¡œê³ ì¹¨</button>
        
        <div class="stats-grid">
            <div class="stat-card">
                <h3>ğŸ“š ìˆ˜ì§‘ëœ ë°ì´í„°</h3>
                <div class="stat-value" id="total-data">0</div>
            </div>
            <div class="stat-card">
                <h3>â±ï¸ ì´ í•™ìŠµ ì‹œê°„</h3>
                <div class="stat-value" id="training-hours">0h</div>
            </div>
            <div class="stat-card">
                <h3>ğŸ“ˆ ëª¨ë¸ ì„±ëŠ¥</h3>
                <div class="stat-value" id="model-score">0.00</div>
            </div>
            <div class="stat-card">
                <h3>ğŸ”§ ì½”ë“œ ê°œì„ </h3>
                <div class="stat-value" id="improvements">0</div>
            </div>
        </div>
        
        <div class="chart-container">
            <h3>í•™ìŠµ ì§„í–‰ë¥ </h3>
            <div class="progress-bar">
                <div class="progress-fill" id="progress" style="width: 0%"></div>
            </div>
            <p id="progress-text">ëŒ€ê¸° ì¤‘...</p>
        </div>
        
        <div class="chart-container">
            <h3>ìµœê·¼ í™œë™</h3>
            <div id="recent-activities">
                <p>í™œë™ ë‚´ì—­ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...</p>
            </div>
        </div>
        
        <div class="log-container" id="log-output">
            ë¡œê·¸ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...
        </div>
    </div>
    
    <script>
        async function refreshData() {
            try {
                // í†µê³„ íŒŒì¼ ì½ê¸°
                const statsResponse = await fetch('learning_stats.json');
                if (statsResponse.ok) {
                    const stats = await statsResponse.json();
                    
                    document.getElementById('total-data').textContent = 
                        (stats.total_data_collected || 0).toLocaleString();
                    
                    document.getElementById('training-hours').textContent = 
                        (stats.total_training_hours || 0).toFixed(1) + 'h';
                    
                    const latestScore = stats.model_improvements && stats.model_improvements.length > 0
                        ? stats.model_improvements[stats.model_improvements.length - 1].score_change
                        : 0;
                    document.getElementById('model-score').textContent = latestScore.toFixed(2);
                    
                    document.getElementById('improvements').textContent = 
                        (stats.code_improvements_count || 0).toLocaleString();
                }
                
                // ë¡œê·¸ íŒŒì¼ ì½ê¸° (ìµœê·¼ 50ì¤„)
                const logResponse = await fetch('csharp_expert_learning.log');
                if (logResponse.ok) {
                    const logText = await logResponse.text();
                    const lines = logText.split('\\n').slice(-50).reverse();
                    document.getElementById('log-output').innerHTML = lines.join('<br>');
                }
                
                // ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                const now = new Date();
                const hours = now.getHours();
                const progress = (hours / 24) * 100;
                document.getElementById('progress').style.width = progress + '%';
                document.getElementById('progress-text').textContent = 
                    `ì˜¤ëŠ˜ ì§„í–‰ë¥ : ${progress.toFixed(1)}% (${hours}/24ì‹œê°„)`;
                
            } catch (error) {
                console.error('ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜:', error);
            }
        }
        
        // ì´ˆê¸° ë¡œë“œ ë° ìë™ ìƒˆë¡œê³ ì¹¨
        refreshData();
        setInterval(refreshData, 30000); // 30ì´ˆë§ˆë‹¤ ìƒˆë¡œê³ ì¹¨
    </script>
</body>
</html>"""
        
        with open(self.base_dir / "expert_learning_dashboard.html", 'w', encoding='utf-8') as f:
            f.write(dashboard_html)
        
        logger.info("âœ… ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ ìƒì„± ì™„ë£Œ!")
    
    async def start_learning_system(self):
        """í•™ìŠµ ì‹œìŠ¤í…œ ì‹œì‘"""
        logger.info("ğŸš€ C# ì „ë¬¸ê°€ í•™ìŠµ ì‹œìŠ¤í…œì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        # ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸
        if not self.check_system_requirements():
            logger.error("âŒ ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ì„ ì¶©ì¡±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return
        
        # í™˜ê²½ ì„¤ì •
        self.setup_environment()
        
        # ì˜ì¡´ì„± ì„¤ì¹˜
        if not self.install_dependencies():
            logger.error("âŒ ì˜ì¡´ì„± ì„¤ì¹˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return
        
        # ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
        if not self.download_model():
            logger.error("âŒ ëª¨ë¸ ë‹¤ìš´ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return
        
        # ì‹œì‘ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
        self.create_startup_scripts()
        
        # ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ ìƒì„±
        self.create_monitoring_dashboard()
        
        logger.info("\n" + "="*60)
        logger.info("âœ… C# ì „ë¬¸ê°€ í•™ìŠµ ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ!")
        logger.info("="*60)
        logger.info("\nğŸ¯ ì‹œì‘ ë°©ë²•:")
        logger.info("  Windows: start_expert_learning.bat ì‹¤í–‰")
        logger.info("  Linux/Mac: ./start_expert_learning.sh ì‹¤í–‰")
        logger.info("\nğŸ“Š ëª¨ë‹ˆí„°ë§:")
        logger.info("  ë¸Œë¼ìš°ì €ì—ì„œ expert_learning_dashboard.html ì—´ê¸°")
        logger.info("\nğŸ“ ì„¤ì •:")
        logger.info("  expert_learning_config.json í¸ì§‘")
        logger.info("  .env íŒŒì¼ì— API í‚¤ ì¶”ê°€ (ì„ íƒì‚¬í•­)")
        logger.info("\nğŸ’¡ íŒ:")
        logger.info("  - GitHub API í† í°ì„ ì¶”ê°€í•˜ë©´ ë” ë§ì€ ë°ì´í„° ìˆ˜ì§‘ ê°€ëŠ¥")
        logger.info("  - GPUê°€ ìˆìœ¼ë©´ í•™ìŠµ ì†ë„ê°€ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤")
        logger.info("  - 24ì‹œê°„ ë™ì•ˆ ì§€ì†ì ìœ¼ë¡œ í•™ìŠµí•˜ë©° ë°œì „í•©ë‹ˆë‹¤")
        logger.info("="*60)

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    startup = ExpertLearningStartup()
    asyncio.run(startup.start_learning_system())

if __name__ == "__main__":
    main()