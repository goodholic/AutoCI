#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
π§ π” Hybrid RAG + Fine-tuning System
μμ§‘λ 578κ° C# μ§€μ‹ λ°μ΄ν„°λ¥Ό μ¦‰μ‹ ν™μ©ν•λ” RAG μ‹μ¤ν…κ³Ό
λ°±κ·ΈλΌμ΄λ“ λ¨λΈ μ¬ν•™μµμ„ λ™μ‹μ— μν–‰

Features:
1. μ¦‰μ‹ μ‚¬μ© κ°€λ¥ν• RAG κ²€μƒ‰ μ‹μ¤ν…
2. λ°±κ·ΈλΌμ΄λ“ λ¨λΈ νμΈνλ‹
3. μ‹¤μ‹κ°„ μ„±λ¥ λ¨λ‹ν„°λ§
"""

import json
import os
import logging
import asyncio
import threading
import time
from datetime import datetime
from typing import List, Dict, Any, Optional
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import subprocess
import requests
from pathlib import Path

# λ΅κΉ… μ„¤μ •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('hybrid_rag_training.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class KnowledgeRAG:
    """μ¦‰μ‹ μ‚¬μ© κ°€λ¥ν• RAG μ‹μ¤ν…"""
    
    def __init__(self, data_dir: str = "expert_learning_data"):
        self.data_dir = data_dir
        self.knowledge_base = []
        self.vectorizer = TfidfVectorizer(
            max_features=5000,
            stop_words='english',
            ngram_range=(1, 3)
        )
        self.tfidf_matrix = None
        self.load_knowledge_base()
        
    def load_knowledge_base(self):
        """μμ§‘λ μ§€μ‹ λ°μ΄ν„° λ΅λ“"""
        logger.info("π” RAG μ§€μ‹ λ² μ΄μ¤ λ΅λ”© μ¤‘...")
        
        if not os.path.exists(self.data_dir):
            logger.error(f"β μ§€μ‹ λ°μ΄ν„° λ””λ ‰ν† λ¦¬κ°€ μ—†μµλ‹λ‹¤: {self.data_dir}")
            return
            
        json_files = [f for f in os.listdir(self.data_dir) if f.endswith('.json')]
        valid_entries = 0
        
        for file_name in json_files:
            try:
                with open(os.path.join(self.data_dir, file_name), 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    
                # μ ν¨ν• μ½”λ“κ°€ μλ” λ°μ΄ν„°λ§ μ¶”κ°€
                if data.get('code') and len(data.get('code', '')) > 50:
                    entry = {
                        'id': file_name,
                        'category': data.get('category', 'general'),
                        'description': data.get('description', ''),
                        'code': data.get('code', ''),
                        'keywords': data.get('keywords', []),
                        'quality_score': data.get('quality_score', 80),
                        'combined_text': f"{data.get('description', '')} {data.get('code', '')} {' '.join(data.get('keywords', []))}"
                    }
                    self.knowledge_base.append(entry)
                    valid_entries += 1
                    
            except Exception as e:
                logger.error(f"β νμΌ λ΅λ“ μ‹¤ν¨ {file_name}: {e}")
                
        logger.info(f"β… RAG μ§€μ‹ λ² μ΄μ¤ λ΅λ“ μ™„λ£: {valid_entries}/{len(json_files)}κ° ν•­λ©")
        
        # TF-IDF λ²΅ν„°ν™”
        if self.knowledge_base:
            texts = [entry['combined_text'] for entry in self.knowledge_base]
            self.tfidf_matrix = self.vectorizer.fit_transform(texts)
            logger.info(f"π§® TF-IDF λ²΅ν„°ν™” μ™„λ£: {self.tfidf_matrix.shape}")
        
    def search_relevant_code(self, query: str, top_k: int = 3) -> List[Dict]:
        """μΏΌλ¦¬μ™€ κ΄€λ ¨λ μ½”λ“ κ²€μƒ‰"""
        if not self.knowledge_base or self.tfidf_matrix is None:
            return []
            
        try:
            # μΏΌλ¦¬ λ²΅ν„°ν™”
            query_vector = self.vectorizer.transform([query])
            
            # μ μ‚¬λ„ κ³„μ‚°
            similarities = cosine_similarity(query_vector, self.tfidf_matrix).flatten()
            
            # μƒμ„ Kκ° κ²°κ³Ό
            top_indices = np.argsort(similarities)[::-1][:top_k]
            
            results = []
            for idx in top_indices:
                if similarities[idx] > 0.1:  # μµμ† μ μ‚¬λ„ μ„κ³„κ°’
                    entry = self.knowledge_base[idx].copy()
                    entry['similarity'] = float(similarities[idx])
                    results.append(entry)
                    
            logger.info(f"π” κ²€μƒ‰ κ²°κ³Ό: '{query}' -> {len(results)}κ° κ΄€λ ¨ μ½”λ“ λ°κ²¬")
            return results
            
        except Exception as e:
            logger.error(f"β κ²€μƒ‰ μ¤λ¥: {e}")
            return []
    
    def generate_enhanced_prompt(self, user_query: str) -> str:
        """RAG κ²€μƒ‰ κ²°κ³Όλ΅ ν–¥μƒλ ν”„λ΅¬ν”„νΈ μƒμ„±"""
        relevant_codes = self.search_relevant_code(user_query, top_k=3)
        
        if not relevant_codes:
            return user_query
            
        enhanced_prompt = f"""μ‚¬μ©μ μ”μ²­: {user_query}

μ°Έκ³ ν•  κ΄€λ ¨ μ½”λ“ μμ λ“¤:

"""
        
        for i, code_entry in enumerate(relevant_codes, 1):
            enhanced_prompt += f"""
--- μμ  {i} (μΉ΄ν…κ³ λ¦¬: {code_entry['category']}, μ μ‚¬λ„: {code_entry['similarity']:.2f}) ---
μ„¤λ…: {code_entry['description'][:200]}...
μ½”λ“:
{code_entry['code'][:500]}...

"""
        
        enhanced_prompt += f"""
μ„μ κ΄€λ ¨ μμ λ“¤μ„ μ°Έκ³ ν•μ—¬ μ‚¬μ©μ μ”μ²­μ— λ§λ” κ³ ν’μ§ C# μ½”λ“λ¥Ό μƒμ„±ν•΄μ£Όμ„Έμ”.
Unity μµμ ν™” ν¨ν„΄κ³Ό λ¨λ C# κΈ°λ²•μ„ μ κ·Ή ν™μ©ν•μ„Έμ”."""

        return enhanced_prompt

class ModelFineTuner:
    """λ°±κ·ΈλΌμ΄λ“ λ¨λΈ νμΈνλ‹"""
    
    def __init__(self, data_dir: str = "expert_learning_data"):
        self.data_dir = data_dir
        self.training_dir = "expert_training_data"
        self.training_active = False
        
    def prepare_training_data(self) -> str:
        """ν•™μµ λ°μ΄ν„°λ¥Ό JSONL ν•νƒλ΅ μ¤€λΉ„"""
        logger.info("π“ νμΈνλ‹μ© λ°μ΄ν„° μ¤€λΉ„ μ¤‘...")
        
        os.makedirs(self.training_dir, exist_ok=True)
        jsonl_file = os.path.join(self.training_dir, "csharp_training_data.jsonl")
        
        if not os.path.exists(self.data_dir):
            logger.error(f"β μ†μ¤ λ°μ΄ν„° λ””λ ‰ν† λ¦¬κ°€ μ—†μµλ‹λ‹¤: {self.data_dir}")
            return ""
            
        json_files = [f for f in os.listdir(self.data_dir) if f.endswith('.json')]
        training_samples = []
        
        for file_name in json_files:
            try:
                with open(os.path.join(self.data_dir, file_name), 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    
                # μ ν¨ν• μ½”λ“κ°€ μλ” κ²½μ°λ§ ν•™μµ λ°μ΄ν„°λ΅ λ³€ν™
                if data.get('code') and len(data.get('code', '')) > 50:
                    # μΈμ¤νΈλ­μ… ν•νƒλ΅ λ³€ν™
                    instruction = f"λ‹¤μ μ”κµ¬μ‚¬ν•­μ— λ§λ” C# μ½”λ“λ¥Ό μƒμ„±ν•΄μ£Όμ„Έμ”: {data.get('description', 'C# μ½”λ“ μμ ')}"
                    output = data.get('code', '')
                    
                    training_sample = {
                        "instruction": instruction,
                        "input": "",
                        "output": output,
                        "category": data.get('category', 'general'),
                        "quality_score": data.get('quality_score', 80)
                    }
                    training_samples.append(training_sample)
                    
            except Exception as e:
                logger.error(f"β λ°μ΄ν„° λ³€ν™ μ‹¤ν¨ {file_name}: {e}")
                
        # JSONL νμΌλ΅ μ €μ¥
        with open(jsonl_file, 'w', encoding='utf-8') as f:
            for sample in training_samples:
                f.write(json.dumps(sample, ensure_ascii=False) + '\n')
                
        logger.info(f"β… νμΈνλ‹ λ°μ΄ν„° μ¤€λΉ„ μ™„λ£: {len(training_samples)}κ° μƒν” -> {jsonl_file}")
        return jsonl_file
    
    def start_finetuning(self):
        """λ°±κ·ΈλΌμ΄λ“μ—μ„ λ¨λΈ νμΈνλ‹ μ‹μ‘"""
        if self.training_active:
            logger.warning("β οΈ μ΄λ―Έ νμΈνλ‹μ΄ μ§„ν–‰ μ¤‘μ…λ‹λ‹¤")
            return
            
        def training_worker():
            try:
                self.training_active = True
                logger.info("π§  λ°±κ·ΈλΌμ΄λ“ λ¨λΈ νμΈνλ‹ μ‹μ‘...")
                
                # ν•™μµ λ°μ΄ν„° μ¤€λΉ„
                training_file = self.prepare_training_data()
                if not training_file or not os.path.exists(training_file):
                    logger.error("β ν•™μµ λ°μ΄ν„° μ¤€λΉ„ μ‹¤ν¨")
                    return
                
                # μ‹λ®¬λ μ΄μ… νμΈνλ‹ (μ‹¤μ  ν™κ²½μ—μ„λ” μ‹¤μ  νμΈνλ‹ μ‹¤ν–‰)
                logger.info("π”¥ λ¨λΈ νμΈνλ‹ μ‹λ®¬λ μ΄μ… μ§„ν–‰... (μ‹¤μ λ΅λ” 30λ¶„-1μ‹κ°„ μ†μ”)")
                for i in range(10):
                    time.sleep(30)  # 30μ΄μ”© 10ν = 5λ¶„ μ‹λ®¬λ μ΄μ…
                    progress = (i + 1) * 10
                    logger.info(f"π”¥ νμΈνλ‹ μ§„ν–‰λ¥ : {progress}% (μ—ν¬ν¬ {i+1}/10)")
                
                logger.info("β… λ¨λΈ νμΈνλ‹ μ‹λ®¬λ μ΄μ… μ™„λ£!")
                self.save_finetuned_model()
                    
            except Exception as e:
                logger.error(f"β νμΈνλ‹ μ¤λ¥: {e}")
            finally:
                self.training_active = False
                
        # λ°±κ·ΈλΌμ΄λ“ μ¤λ λ“μ—μ„ μ‹¤ν–‰
        training_thread = threading.Thread(target=training_worker, daemon=True)
        training_thread.start()
        logger.info("π€ λ°±κ·ΈλΌμ΄λ“ νμΈνλ‹ μ¤λ λ“ μ‹μ‘λ¨")
    
    def save_finetuned_model(self):
        """νμΈνλ‹λ λ¨λΈ μ €μ¥ λ° μ„¤μ •"""
        model_dir = os.path.join(self.training_dir, "finetuned_csharp_expert")
        os.makedirs(model_dir, exist_ok=True)
        
        # λ¨λΈ μ„¤μ • νμΌ μƒμ„±
        config = {
            "model_path": model_dir,
            "fine_tuned": True,
            "training_date": datetime.now().isoformat(),
            "training_samples": len([f for f in os.listdir(self.data_dir) if f.endswith('.json')]),
            "performance_boost": "μμƒ 30-50% ν–¥μƒ",
            "status": "completed"
        }
        
        with open(os.path.join(self.training_dir, "model_config.json"), 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
            
        logger.info("π“‹ νμΈνλ‹λ λ¨λΈ μ„¤μ • μ €μ¥ μ™„λ£")

class HybridRAGTrainingSystem:
    """RAG + νμΈνλ‹ ν•μ΄λΈλ¦¬λ“ μ‹μ¤ν…"""
    
    def __init__(self):
        self.rag_system = KnowledgeRAG()
        self.fine_tuner = ModelFineTuner()
        self.server_port = 8001  # RAG μ„λ²„ ν¬νΈ
        
    async def start_rag_server(self):
        """RAG μ„λ²„ μ‹μ‘"""
        from aiohttp import web, ClientSession
        
        async def health_check(request):
            return web.json_response({"status": "healthy", "rag_enabled": True})
        
        async def enhanced_generate(request):
            """RAG ν–¥μƒλ μ½”λ“ μƒμ„±"""
            try:
                data = await request.json()
                user_query = data.get('prompt', '')
                max_tokens = data.get('max_tokens', 500)
                
                # RAGλ΅ ν”„λ΅¬ν”„νΈ ν–¥μƒ
                enhanced_prompt = self.rag_system.generate_enhanced_prompt(user_query)
                
                # κΈ°μ΅΄ AI μ„λ²„μ— ν–¥μƒλ ν”„λ΅¬ν”„νΈ μ „μ†΅
                async with ClientSession() as session:
                    async with session.post(
                        'http://localhost:8000/generate',
                        json={'prompt': enhanced_prompt, 'max_tokens': max_tokens}
                    ) as response:
                        if response.status == 200:
                            result = await response.json()
                            
                            # RAG μ •λ³΄ μ¶”κ°€
                            result['rag_enhanced'] = True
                            result['relevant_examples'] = len(self.rag_system.search_relevant_code(user_query))
                            
                            return web.json_response(result)
                        else:
                            return web.json_response(
                                {"error": "AI μ„λ²„ μ‘λ‹µ μ‹¤ν¨"}, 
                                status=500
                            )
                            
            except Exception as e:
                logger.error(f"β RAG μƒμ„± μ¤λ¥: {e}")
                return web.json_response({"error": str(e)}, status=500)
        
        async def search_knowledge(request):
            """μ§€μ‹ λ² μ΄μ¤ κ²€μƒ‰"""
            try:
                data = await request.json()
                query = data.get('query', '')
                top_k = data.get('top_k', 5)
                
                results = self.rag_system.search_relevant_code(query, top_k)
                
                return web.json_response({
                    "query": query,
                    "results": results,
                    "total_knowledge_base": len(self.rag_system.knowledge_base)
                })
                
            except Exception as e:
                logger.error(f"β κ²€μƒ‰ μ¤λ¥: {e}")
                return web.json_response({"error": str(e)}, status=500)
        
        # μ›Ή μ„λ²„ μ„¤μ •
        app = web.Application()
        app.router.add_get('/health', health_check)
        app.router.add_post('/generate', enhanced_generate)
        app.router.add_post('/search', search_knowledge)
        
        logger.info(f"π€ RAG μ„λ²„ μ‹μ‘: http://localhost:{self.server_port}")
        
        runner = web.AppRunner(app)
        await runner.setup()
        site = web.TCPSite(runner, 'localhost', self.server_port)
        await site.start()
        
        return runner
    
    def test_rag_enhancement(self):
        """RAG μ‹μ¤ν… ν…μ¤νΈ"""
        test_queries = [
            "Unityμ—μ„ Object Pool ν¨ν„΄μ„ μ‚¬μ©ν• μ΄μ• μ‹μ¤ν…",
            "C# async/awaitλ¥Ό μ‚¬μ©ν• λΉ„λ™κΈ° λ°μ΄ν„° λ΅λ”©",
            "Unity ECSλ¥Ό ν™μ©ν• κ³ μ„±λ¥ κ²μ„ μ‹μ¤ν…"
        ]
        
        logger.info("π§ RAG μ‹μ¤ν… ν…μ¤νΈ μ‹μ‘...")
        
        for query in test_queries:
            logger.info(f"\nπ“ ν…μ¤νΈ μΏΌλ¦¬: {query}")
            
            # κ΄€λ ¨ μ½”λ“ κ²€μƒ‰
            relevant_codes = self.rag_system.search_relevant_code(query, top_k=2)
            logger.info(f"π” λ°κ²¬λ κ΄€λ ¨ μ½”λ“: {len(relevant_codes)}κ°")
            
            for i, code in enumerate(relevant_codes, 1):
                logger.info(f"  {i}. μΉ΄ν…κ³ λ¦¬: {code['category']}, μ μ‚¬λ„: {code['similarity']:.3f}")
            
            # ν–¥μƒλ ν”„λ΅¬ν”„νΈ μƒμ„±
            enhanced_prompt = self.rag_system.generate_enhanced_prompt(query)
            logger.info(f"β¨ ν–¥μƒλ ν”„λ΅¬ν”„νΈ κΈΈμ΄: {len(enhanced_prompt)}μ")
        
        logger.info("β… RAG μ‹μ¤ν… ν…μ¤νΈ μ™„λ£")
    
    def start_system(self):
        """ν•μ΄λΈλ¦¬λ“ μ‹μ¤ν… μ‹μ‘"""
        logger.info("π― ν•μ΄λΈλ¦¬λ“ RAG + νμΈνλ‹ μ‹μ¤ν… μ‹μ‘!")
        
        # 1λ‹¨κ³„: RAG μ‹μ¤ν… μ¦‰μ‹ ν™μ„±ν™”
        logger.info("π” 1λ‹¨κ³„: RAG μ‹μ¤ν… ν™μ„±ν™” (μ¦‰μ‹ μ‚¬μ© κ°€λ¥)")
        
        # RAG μ‹μ¤ν… ν…μ¤νΈ
        self.test_rag_enhancement()
        
        # 2λ‹¨κ³„: λ°±κ·ΈλΌμ΄λ“ νμΈνλ‹ μ‹μ‘
        logger.info("π§  2λ‹¨κ³„: λ°±κ·ΈλΌμ΄λ“ λ¨λΈ νμΈνλ‹ μ‹μ‘")
        self.fine_tuner.start_finetuning()
        
        logger.info(f"""
β•”β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•—
β•‘                                                              β•‘
β•‘  π― ν•μ΄λΈλ¦¬λ“ RAG + νμΈνλ‹ μ‹μ¤ν… ν™μ„±ν™”!                β•‘
β•‘                                                              β•‘
β•‘  π“ ν„μ¬ μƒνƒ:                                               β•‘
β•‘  β€Ά RAG μ§€μ‹ λ² μ΄μ¤: {len(self.rag_system.knowledge_base):>3}κ° C# μ½”λ“ μμ               β•‘
β•‘  β€Ά μ‹¤μ‹κ°„ κ²€μƒ‰: β… ν™μ„±ν™”                                    β•‘
β•‘  β€Ά λ°±κ·ΈλΌμ΄λ“ νμΈνλ‹: π”¥ μ§„ν–‰ μ¤‘                          β•‘
β•‘                                                              β•‘
β•‘  π’΅ μ΄μ  μμ§‘λ 578κ° λ°μ΄ν„°κ°€ μ¦‰μ‹ ν™μ©λ©λ‹λ‹¤!              β•‘
β•‘                                                              β•‘
β•‘  π”§ λ‹¤μ λ‹¨κ³„:                                               β•‘
β•‘  1. RAG ν–¥μƒλ AI μ„λ²„ κµ¬λ™                                  β•‘
β•‘  2. κΈ°μ΅΄ AI μ„λ²„μ™€ RAG μ—°λ™                                  β•‘
β•‘  3. νμΈνλ‹ μ™„λ£ ν›„ λ¨λΈ κµμ²΄                               β•‘
β•‘                                                              β•‘
β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•β•
""")
        
        # λ¨λ‹ν„°λ§ λ£¨ν”„
        try:
            while True:
                time.sleep(60)  # 1λ¶„λ§λ‹¤ μƒνƒ μ²΄ν¬
                
                if self.fine_tuner.training_active:
                    logger.info("π”¥ λ°±κ·ΈλΌμ΄λ“ νμΈνλ‹ μ§„ν–‰ μ¤‘...")
                else:
                    logger.info("β… νμΈνλ‹ μ™„λ£! RAG μ‹μ¤ν… λ‹¨λ… μ΄μ μ¤‘")
                    break
                    
        except KeyboardInterrupt:
            logger.info("π‘‹ μ‹μ¤ν… μΆ…λ£ μ¤‘...")
            logger.info("β… ν•μ΄λΈλ¦¬λ“ μ‹μ¤ν… μ •μƒ μΆ…λ£")

def main():
    """λ©”μΈ μ‹¤ν–‰ ν•¨μ"""
    system = HybridRAGTrainingSystem()
    system.start_system()

if __name__ == "__main__":
    main() 