#!/usr/bin/env python3
"""
ìˆœìˆ˜ Python ì‹ ê²½ë§ í•™ìŠµ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ (ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ì´)
"""

import sys
import os
import time
import math
import json
from datetime import datetime
from typing import Dict, List, Optional, Tuple

# dataclass ìˆ˜ë™ êµ¬í˜„ (decorator ì—†ì´)
class ConversationData:
    def __init__(self, user_input: str, ai_response: str, feedback_score: float, timestamp: str):
        self.user_input = user_input
        self.ai_response = ai_response
        self.feedback_score = feedback_score
        self.timestamp = timestamp

class PurePythonMatrix:
    """ìˆœìˆ˜ Python í–‰ë ¬ ì—°ì‚°"""
    
    @staticmethod
    def zeros(rows: int, cols: int) -> List[List[float]]:
        """ì˜í–‰ë ¬ ìƒì„±"""
        return [[0.0 for _ in range(cols)] for _ in range(rows)]
    
    @staticmethod
    def random_matrix(rows: int, cols: int, scale: float = 1.0) -> List[List[float]]:
        """ëœë¤ í–‰ë ¬ ìƒì„±"""
        import random
        return [[random.gauss(0, scale) for _ in range(cols)] for _ in range(rows)]
    
    @staticmethod
    def multiply(A: List[List[float]], B: List[List[float]]) -> List[List[float]]:
        """í–‰ë ¬ ê³±ì…ˆ"""
        rows_A, cols_A = len(A), len(A[0])
        rows_B, cols_B = len(B), len(B[0])
        
        if cols_A != rows_B:
            raise ValueError("í–‰ë ¬ í¬ê¸°ê°€ ë§ì§€ ì•ŠìŠµë‹ˆë‹¤")
        
        result = PurePythonMatrix.zeros(rows_A, cols_B)
        
        for i in range(rows_A):
            for j in range(cols_B):
                for k in range(cols_A):
                    result[i][j] += A[i][k] * B[k][j]
        
        return result
    
    @staticmethod
    def add(A: List[List[float]], B: List[List[float]]) -> List[List[float]]:
        """í–‰ë ¬ ë§ì…ˆ"""
        rows, cols = len(A), len(A[0])
        result = PurePythonMatrix.zeros(rows, cols)
        
        for i in range(rows):
            for j in range(cols):
                result[i][j] = A[i][j] + B[i][j]
        
        return result
    
    @staticmethod
    def subtract(A: List[List[float]], B: List[List[float]]) -> List[List[float]]:
        """í–‰ë ¬ ëº„ì…ˆ"""
        rows, cols = len(A), len(A[0])
        result = PurePythonMatrix.zeros(rows, cols)
        
        for i in range(rows):
            for j in range(cols):
                result[i][j] = A[i][j] - B[i][j]
        
        return result
    
    @staticmethod
    def transpose(A: List[List[float]]) -> List[List[float]]:
        """í–‰ë ¬ ì „ì¹˜"""
        rows, cols = len(A), len(A[0])
        result = PurePythonMatrix.zeros(cols, rows)
        
        for i in range(rows):
            for j in range(cols):
                result[j][i] = A[i][j]
        
        return result
    
    @staticmethod
    def scalar_multiply(A: List[List[float]], scalar: float) -> List[List[float]]:
        """ìŠ¤ì¹¼ë¼ ê³±ì…ˆ"""
        rows, cols = len(A), len(A[0])
        result = PurePythonMatrix.zeros(rows, cols)
        
        for i in range(rows):
            for j in range(cols):
                result[i][j] = A[i][j] * scalar
        
        return result

class PurePythonNeuralNetwork:
    """ìˆœìˆ˜ Python ì‹ ê²½ë§"""
    
    def __init__(self, input_size: int = 10, hidden_size: int = 5, output_size: int = 1):
        # ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”
        scale = math.sqrt(2.0 / input_size)
        self.W1 = PurePythonMatrix.random_matrix(input_size, hidden_size, scale)
        self.b1 = PurePythonMatrix.zeros(1, hidden_size)
        
        scale = math.sqrt(2.0 / hidden_size)
        self.W2 = PurePythonMatrix.random_matrix(hidden_size, output_size, scale)
        self.b2 = PurePythonMatrix.zeros(1, output_size)
        
        self.learning_rate = 0.01
    
    def sigmoid(self, x: float) -> float:
        """ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜"""
        try:
            return 1.0 / (1.0 + math.exp(-max(-250, min(250, x))))
        except OverflowError:
            return 0.0 if x < 0 else 1.0
    
    def sigmoid_matrix(self, matrix: List[List[float]]) -> List[List[float]]:
        """í–‰ë ¬ì— ì‹œê·¸ëª¨ì´ë“œ ì ìš©"""
        rows, cols = len(matrix), len(matrix[0])
        result = PurePythonMatrix.zeros(rows, cols)
        
        for i in range(rows):
            for j in range(cols):
                result[i][j] = self.sigmoid(matrix[i][j])
        
        return result
    
    def forward(self, X: List[List[float]]) -> Tuple[List[List[float]], List[List[float]], List[List[float]]]:
        """ìˆœì „íŒŒ"""
        # z1 = X * W1 + b1
        z1 = PurePythonMatrix.multiply(X, self.W1)
        z1 = PurePythonMatrix.add(z1, self.b1)
        
        # a1 = sigmoid(z1)
        a1 = self.sigmoid_matrix(z1)
        
        # z2 = a1 * W2 + b2
        z2 = PurePythonMatrix.multiply(a1, self.W2)
        z2 = PurePythonMatrix.add(z2, self.b2)
        
        # a2 = sigmoid(z2)
        a2 = self.sigmoid_matrix(z2)
        
        return a1, z2, a2
    
    def calculate_loss(self, predictions: List[List[float]], targets: List[List[float]]) -> float:
        """ì†ì‹¤ ê³„ì‚° (MSE)"""
        total_loss = 0.0
        count = 0
        
        rows, cols = len(predictions), len(predictions[0])
        
        for i in range(rows):
            for j in range(cols):
                diff = predictions[i][j] - targets[i][j]
                total_loss += diff * diff
                count += 1
        
        return total_loss / count if count > 0 else 0.0
    
    def train_step(self, X: List[List[float]], y: List[List[float]]) -> float:
        """í•œ ë²ˆì˜ í•™ìŠµ ë‹¨ê³„"""
        batch_size = len(X)
        
        # ìˆœì „íŒŒ
        a1, z2, a2 = self.forward(X)
        
        # ì†ì‹¤ ê³„ì‚°
        loss = self.calculate_loss(a2, y)
        
        # ì—­ì „íŒŒ
        # ì¶œë ¥ì¸µ ì˜¤ì°¨
        dz2 = PurePythonMatrix.subtract(a2, y)
        
        # W2, b2 ê·¸ë˜ë””ì–¸íŠ¸
        a1_t = PurePythonMatrix.transpose(a1)
        dW2 = PurePythonMatrix.multiply(a1_t, dz2)
        dW2 = PurePythonMatrix.scalar_multiply(dW2, 1.0 / batch_size)
        
        # db2 ê³„ì‚° (ì—´ í•©)
        db2 = PurePythonMatrix.zeros(1, len(dz2[0]))
        for i in range(len(dz2)):
            for j in range(len(dz2[0])):
                db2[0][j] += dz2[i][j]
        db2 = PurePythonMatrix.scalar_multiply(db2, 1.0 / batch_size)
        
        # ì€ë‹‰ì¸µ ì˜¤ì°¨
        W2_t = PurePythonMatrix.transpose(self.W2)
        dz1 = PurePythonMatrix.multiply(dz2, W2_t)
        
        # a1ì— ëŒ€í•œ ì‹œê·¸ëª¨ì´ë“œ ë¯¸ë¶„ ì ìš©
        for i in range(len(dz1)):
            for j in range(len(dz1[0])):
                sigmoid_derivative = a1[i][j] * (1 - a1[i][j])
                dz1[i][j] *= sigmoid_derivative
        
        # W1, b1 ê·¸ë˜ë””ì–¸íŠ¸
        X_t = PurePythonMatrix.transpose(X)
        dW1 = PurePythonMatrix.multiply(X_t, dz1)
        dW1 = PurePythonMatrix.scalar_multiply(dW1, 1.0 / batch_size)
        
        # db1 ê³„ì‚°
        db1 = PurePythonMatrix.zeros(1, len(dz1[0]))
        for i in range(len(dz1)):
            for j in range(len(dz1[0])):
                db1[0][j] += dz1[i][j]
        db1 = PurePythonMatrix.scalar_multiply(db1, 1.0 / batch_size)
        
        # ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
        dW2_scaled = PurePythonMatrix.scalar_multiply(dW2, self.learning_rate)
        self.W2 = PurePythonMatrix.subtract(self.W2, dW2_scaled)
        
        db2_scaled = PurePythonMatrix.scalar_multiply(db2, self.learning_rate)
        self.b2 = PurePythonMatrix.subtract(self.b2, db2_scaled)
        
        dW1_scaled = PurePythonMatrix.scalar_multiply(dW1, self.learning_rate)
        self.W1 = PurePythonMatrix.subtract(self.W1, dW1_scaled)
        
        db1_scaled = PurePythonMatrix.scalar_multiply(db1, self.learning_rate)
        self.b1 = PurePythonMatrix.subtract(self.b1, db1_scaled)
        
        return loss
    
    def predict(self, X: List[List[float]]) -> List[List[float]]:
        """ì˜ˆì¸¡"""
        _, _, a2 = self.forward(X)
        return a2

class PurePythonLearningAutoCI:
    """ìˆœìˆ˜ Python í•™ìŠµ AutoCI ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.neural_network = PurePythonNeuralNetwork()
        self.conversations: List[ConversationData] = []
        self.learning_enabled = True
        
        # í†µê³„
        self.stats = {
            "total_conversations": 0,
            "total_training_epochs": 0,
            "average_loss": 0.0,
            "last_learning_time": None
        }
        
        print("ğŸ§  ìˆœìˆ˜ Python í•™ìŠµ AI ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def text_to_vector(self, text: str, vector_size: int = 10) -> List[float]:
        """í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜"""
        words = text.lower().split()
        vector = [0.0] * vector_size
        
        for i, word in enumerate(words[:vector_size]):
            # ë‹¨ì–´ì˜ í•´ì‹œë¥¼ ë²¡í„° ì¸ë±ìŠ¤ë¡œ ì‚¬ìš©
            word_hash = hash(word) % vector_size
            vector[word_hash] = 1.0
            
            # ë‹¨ì–´ ê¸¸ì´ì™€ ìœ„ì¹˜ ì •ë³´ ì¶”ê°€
            vector[word_hash] += len(word) * 0.1
            vector[word_hash] += (i + 1) * 0.01
        
        # ê°„ë‹¨í•œ ì •ê·œí™”
        vector_sum = sum(x * x for x in vector)
        if vector_sum > 0:
            norm = math.sqrt(vector_sum)
            vector = [x / norm for x in vector]
        
        return vector
    
    def estimate_feedback_score(self, user_input: str, ai_response: str) -> float:
        """í”¼ë“œë°± ì ìˆ˜ ìë™ ì¶”ì •"""
        score = 0.0
        
        # ê¸ì •ì /ë¶€ì •ì  í‚¤ì›Œë“œ
        positive_keywords = ["ì¢‹ì•„", "ë§ì•„", "ì •í™•", "ë„ì›€", "ê³ ë§ˆì›Œ", "ì˜í–ˆì–´"]
        negative_keywords = ["í‹€ë ¤", "ì•„ë‹ˆì•¼", "ì´ìƒí•´", "ë³„ë¡œ", "ë‹¤ì‹œ", "ì˜ëª»"]
        
        user_lower = user_input.lower()
        response_lower = ai_response.lower()
        
        for keyword in positive_keywords:
            if keyword in user_lower:
                score += 0.2
        
        for keyword in negative_keywords:
            if keyword in user_lower:
                score -= 0.2
        
        # ì‘ë‹µ ê¸¸ì´ ì²´í¬
        response_length = len(ai_response)
        if 10 <= response_length <= 100:
            score += 0.1
        elif response_length < 5 or response_length > 200:
            score -= 0.1
        
        return max(-1.0, min(1.0, score))
    
    def process_conversation(self, user_input: str, ai_response: str, 
                           feedback_score: Optional[float] = None) -> Dict:
        """ëŒ€í™” ì²˜ë¦¬"""
        if feedback_score is None:
            feedback_score = self.estimate_feedback_score(user_input, ai_response)
        
        conversation = ConversationData(
            user_input=user_input,
            ai_response=ai_response,
            feedback_score=feedback_score,
            timestamp=datetime.now().isoformat()
        )
        
        self.conversations.append(conversation)
        self.stats["total_conversations"] += 1
        
        # í•™ìŠµ íŠ¸ë¦¬ê±°
        if self.learning_enabled and abs(feedback_score) > 0.3:
            self.trigger_learning()
        
        return {
            "conversation_id": len(self.conversations),
            "feedback_score": feedback_score,
            "learning_triggered": abs(feedback_score) > 0.3
        }
    
    def trigger_learning(self):
        """í•™ìŠµ ì‹¤í–‰"""
        if len(self.conversations) < 3:
            return
        
        print("ğŸ”„ ì‹ ê²½ë§ í•™ìŠµ ì‹œì‘...")
        
        # í•™ìŠµ ë°ì´í„° ì¤€ë¹„
        recent_conversations = self.conversations[-10:]
        
        X = []
        y = []
        
        for conv in recent_conversations:
            input_vector = self.text_to_vector(conv.user_input)
            X.append(input_vector)
            
            # í”¼ë“œë°± ì ìˆ˜ë¥¼ 0-1 ë²”ìœ„ë¡œ ë³€í™˜
            normalized_score = (conv.feedback_score + 1.0) / 2.0
            y.append([normalized_score])
        
        if len(X) > 0:
            # í•™ìŠµ ì‹¤í–‰
            total_loss = 0.0
            epochs = 20
            
            for epoch in range(epochs):
                loss = self.neural_network.train_step(X, y)
                total_loss += loss
            
            avg_loss = total_loss / epochs
            self.stats["total_training_epochs"] += epochs
            self.stats["average_loss"] = avg_loss
            self.stats["last_learning_time"] = datetime.now().isoformat()
            
            print(f"âœ… í•™ìŠµ ì™„ë£Œ - í‰ê·  ì†ì‹¤: {avg_loss:.4f}")
    
    def generate_response(self, user_input: str) -> Tuple[str, float]:
        """ì‘ë‹µ ìƒì„±"""
        # ì‹ ê²½ë§ìœ¼ë¡œ í’ˆì§ˆ ì˜ˆì¸¡
        try:
            input_vector = self.text_to_vector(user_input)
            prediction = self.neural_network.predict([input_vector])
            quality_score = prediction[0][0]
            
            # 0-1 ë²”ìœ„ë¥¼ ì‹ ë¢°ë„ë¡œ ë³€í™˜
            confidence = quality_score
            
        except Exception as e:
            confidence = 0.5
        
        # ê·œì¹™ ê¸°ë°˜ ì‘ë‹µ ìƒì„±
        user_lower = user_input.lower()
        
        if any(word in user_lower for word in ["ì•ˆë…•", "hello", "hi"]):
            response = "ì•ˆë…•í•˜ì„¸ìš”! AutoCIì…ë‹ˆë‹¤. ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?"
        elif any(word in user_lower for word in ["unity", "ìœ ë‹ˆí‹°"]):
            response = "Unity ê°œë°œì„ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤! ì–´ë–¤ ë¶€ë¶„ì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?"
        elif any(word in user_lower for word in ["ì½”ë“œ", "code", "ìŠ¤í¬ë¦½íŠ¸"]):
            response = "ì½”ë“œë¥¼ ë¶„ì„í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì½”ë“œë¥¼ ë³´ì—¬ì£¼ì„¸ìš”."
        elif any(word in user_lower for word in ["ì˜¤ë¥˜", "ì—ëŸ¬", "error"]):
            response = "ì˜¤ë¥˜ë¥¼ í•´ê²°í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì–´ë–¤ ì˜¤ë¥˜ì¸ì§€ ì•Œë ¤ì£¼ì„¸ìš”."
        elif any(word in user_lower for word in ["ê³ ë§ˆì›Œ", "ê°ì‚¬"]):
            response = "ì²œë§Œì—ìš”! ë” ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ì£¼ì„¸ìš”."
        else:
            response = "ë„¤, ì´í•´í–ˆìŠµë‹ˆë‹¤. ë” ìì„¸íˆ ì„¤ëª…í•´ì£¼ì‹œë©´ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        
        return response, confidence
    
    def get_learning_status(self) -> Dict:
        """í•™ìŠµ ìƒíƒœ ë°˜í™˜"""
        return {
            "stats": self.stats,
            "total_conversations": len(self.conversations),
            "neural_network_info": {
                "input_size": len(self.neural_network.W1),
                "hidden_size": len(self.neural_network.W1[0]),
                "output_size": len(self.neural_network.W2[0])
            }
        }

def test_pure_python_neural_learning():
    """ìˆœìˆ˜ Python ì‹ ê²½ë§ í•™ìŠµ í…ŒìŠ¤íŠ¸"""
    print("ğŸš€ ìˆœìˆ˜ Python ì‹ ê²½ë§ í•™ìŠµ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # AI ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    ai = PurePythonLearningAutoCI()
    print("âœ… AI ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì„±ê³µ")
    
    # í…ŒìŠ¤íŠ¸ ëŒ€í™”ë“¤
    test_conversations = [
        ("ì•ˆë…•í•˜ì„¸ìš”", "ì•ˆë…•í•˜ì„¸ìš”! AutoCIì…ë‹ˆë‹¤.", 1.0),
        ("Unity ë„ì›€ì´ í•„ìš”í•´ìš”", "Unity ê°œë°œì„ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤!", 0.8),
        ("ì½”ë“œ ë¶„ì„í•´ì£¼ì„¸ìš”", "ì½”ë“œë¥¼ ë¶„ì„í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.", 0.6),
        ("ì´ìƒí•œ ì‘ë‹µì´ë„¤ìš”", "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ë³´ê² ìŠµë‹ˆë‹¤.", -0.5),
        ("ê³ ë§ˆì›Œìš”", "ì²œë§Œì—ìš”! ë„ì›€ì´ ë˜ì–´ì„œ ê¸°ë»ìš”!", 0.9),
        ("Unityì—ì„œ ì˜¤ë¸Œì íŠ¸ ìƒì„±", "Instantiateë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.", 0.7),
        ("ìŠ¤í¬ë¦½íŠ¸ ì˜¤ë¥˜", "ì–´ë–¤ ì˜¤ë¥˜ì¸ì§€ ì•Œë ¤ì£¼ì„¸ìš”.", 0.5),
        ("ì˜ëª»ëœ ë‹µë³€", "ì£„ì†¡í•©ë‹ˆë‹¤. ê°œì„ í•˜ê² ìŠµë‹ˆë‹¤.", -0.3)
    ]
    
    print(f"\nğŸ—£ï¸ {len(test_conversations)}ê°œ í…ŒìŠ¤íŠ¸ ëŒ€í™” ì²˜ë¦¬ ì¤‘...")
    
    # ëŒ€í™” ì²˜ë¦¬
    for i, (user_input, ai_response, feedback) in enumerate(test_conversations, 1):
        print(f"\ní…ŒìŠ¤íŠ¸ {i}/{len(test_conversations)}:")
        print(f"ì‚¬ìš©ì: {user_input}")
        print(f"AI: {ai_response}")
        print(f"í”¼ë“œë°±: {feedback}")
        
        result = ai.process_conversation(user_input, ai_response, feedback)
        
        print(f"âœ… ëŒ€í™” ID: {result['conversation_id']}")
        print(f"âœ… í•™ìŠµ íŠ¸ë¦¬ê±°: {result['learning_triggered']}")
    
    print(f"\nğŸ“Š ìµœì¢… í•™ìŠµ ìƒíƒœ:")
    status = ai.get_learning_status()
    for key, value in status["stats"].items():
        print(f"  {key}: {value}")
    
    print(f"\nğŸ¤– ì‘ë‹µ ìƒì„± í…ŒìŠ¤íŠ¸:")
    test_inputs = [
        "ì•ˆë…•í•˜ì„¸ìš”",
        "Unity ìŠ¤í¬ë¦½íŠ¸ ë„ì›€",
        "ì½”ë“œ ì˜¤ë¥˜ í•´ê²°",
        "ê°ì‚¬í•©ë‹ˆë‹¤"
    ]
    
    for test_input in test_inputs:
        response, confidence = ai.generate_response(test_input)
        print(f"ì…ë ¥: {test_input}")
        print(f"ì‘ë‹µ: {response}")
        print(f"ì‹ ë¢°ë„: {confidence:.2f}\n")
    
    print("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("âœ… ìˆœìˆ˜ Python ì‹ ê²½ë§ ê¸°ë°˜ í•™ìŠµ ì‹œìŠ¤í…œì´ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤.")
    
    return ai

if __name__ == "__main__":
    test_pure_python_neural_learning()