#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Korean AI Simple Demo - ChatGPT Style Learning
==============================================

ChatGPT, Gemini, Claudeê°€ ì–´ë–»ê²Œ í•œêµ­ì–´ë¥¼ í•™ìŠµí–ˆëŠ”ì§€ ì‹œì—°í•˜ê³ 
AutoCIì— ì ìš©í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì£¼ëŠ” ì‹œìŠ¤í…œ

ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ì´ í•µì‹¬ ê°œë… êµ¬í˜„
"""

import json
import re
import random
import sqlite3
from datetime import datetime
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from collections import defaultdict, Counter

@dataclass
class KoreanLearningData:
    """í•œêµ­ì–´ í•™ìŠµ ë°ì´í„°"""
    text: str
    source_type: str
    quality_score: float
    patterns: Dict[str, int]
    features: Dict[str, Any]

class ChatGPTStyleKoreanLearner:
    """ChatGPT ë°©ì‹ì˜ í•œêµ­ì–´ í•™ìŠµê¸°"""
    
    def __init__(self):
        print("ğŸ§  ChatGPT ë°©ì‹ í•œêµ­ì–´ í•™ìŠµ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        
        # 1. ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ë“¤ì˜ í•œêµ­ì–´ í•™ìŠµ ë°©ì‹
        self.learning_methods = {
            "ë‹¤êµ­ì–´_ì‚¬ì „_í›ˆë ¨": {
                "ì„¤ëª…": "ChatGPT, Gemini, Claudeê°€ ì‚¬ìš©í•˜ëŠ” í•µì‹¬ ë°©ë²•",
                "ë°ì´í„°_ì†ŒìŠ¤": [
                    "í•œêµ­ì–´ ì›¹í˜ì´ì§€ (ë‰´ìŠ¤, ë¸”ë¡œê·¸, í¬ëŸ¼)",
                    "í•œêµ­ì–´ ìœ„í‚¤í”¼ë””ì•„",
                    "í•œêµ­ì–´ ë¬¸í•™ ì‘í’ˆ",
                    "í•œêµ­ì–´ ëŒ€í™” ë°ì´í„°",
                    "ì •ë¶€ ë¬¸ì„œ, í•™ìˆ  ë…¼ë¬¸",
                    "ì†Œì…œë¯¸ë””ì–´ í…ìŠ¤íŠ¸"
                ],
                "í•™ìŠµëŸ‰": "ìˆ˜ì‹­ì–µ ê°œì˜ í•œêµ­ì–´ ë¬¸ì¥"
            },
            "í† í¬ë‚˜ì´ì €_ìµœì í™”": {
                "ì„¤ëª…": "í•œêµ­ì–´ íŠ¹ì„±ì— ë§ëŠ” í† í° ë¶„í• ",
                "íŠ¹ì§•": [
                    "ì¡°ì‚¬, ì–´ë¯¸ ë³€í™” ì²˜ë¦¬",
                    "ë³µí•©ì–´ ë¶„í•´",
                    "í•œìì–´ ì²˜ë¦¬",
                    "ë„ì–´ì“°ê¸° ì˜¤ë¥˜ ë³´ì •"
                ]
            },
            "ì¸ê°„_í”¼ë“œë°±_ê°•í™”í•™ìŠµ": {
                "ì„¤ëª…": "Human Feedback Reinforcement Learning",
                "ê³¼ì •": [
                    "ë‹¤ì–‘í•œ ì‘ë‹µ ìƒì„±",
                    "ì¸ê°„ í‰ê°€ìê°€ í’ˆì§ˆ í‰ê°€",
                    "ì„ í˜¸ë„ì— ë”°ë¥¸ ëª¨ë¸ ì¡°ì •",
                    "ìì—°ìŠ¤ëŸ¬ì›€ê³¼ ë„ì›€ë¨ ìµœì í™”"
                ]
            }
        }
        
        # 2. í•œêµ­ì–´ íŒ¨í„´ ë¶„ì„ê¸°
        self.korean_patterns = {
            # ì¡°ì‚¬ íŒ¨í„´
            "particles": ["ì€", "ëŠ”", "ì´", "ê°€", "ì„", "ë¥¼", "ì—", "ì—ì„œ", "ë¡œ", "ìœ¼ë¡œ", "ì™€", "ê³¼", "ì˜"],
            
            # ì–´ë¯¸ íŒ¨í„´
            "endings": {
                "formal": ["ìŠµë‹ˆë‹¤", "ì…ë‹ˆë‹¤", "í•˜ì‹­ì‹œì˜¤", "í•˜ì‹œê² ìŠµë‹ˆê¹Œ"],
                "polite": ["í•´ìš”", "ì´ì—ìš”", "ì˜ˆìš”", "ë¼ìš”"],
                "casual": ["í•´", "ì•¼", "ì´ì•¼", "ì–´"]
            },
            
            # ë†’ì„ë²• íŒ¨í„´
            "honorifics": ["ë‹˜", "ì”¨", "ì„ ìƒë‹˜", "êµìˆ˜ë‹˜", "ê»˜ì„œ", "ë“œë¦¬ë‹¤", "ë°›ìœ¼ì‹œë‹¤"],
            
            # ê°ì • í‘œí˜„
            "emotions": {
                "positive": ["ì¢‹ë‹¤", "í–‰ë³µí•˜ë‹¤", "ê¸°ì˜ë‹¤", "ì¦ê²ë‹¤", "ê°ì‚¬í•˜ë‹¤"],
                "negative": ["ë‚˜ì˜ë‹¤", "ìŠ¬í”„ë‹¤", "í™”ë‚˜ë‹¤", "í˜ë“¤ë‹¤", "ì–´ë µë‹¤"],
                "neutral": ["ê´œì°®ë‹¤", "ë³´í†µì´ë‹¤", "ê·¸ëŸ­ì €ëŸ­"]
            },
            
            # ë¬¸ì¥ ìœ í˜•
            "sentence_types": {
                "question": ["ë¬´ì—‡", "ì–¸ì œ", "ì–´ë””", "ëˆ„ê°€", "ì–´ë–»ê²Œ", "ì™œ"],
                "request": ["í•´ì£¼ì„¸ìš”", "í•´ì¤˜", "ë¶€íƒ", "ë„ì™€ì£¼ì„¸ìš”"]
            }
        }
        
        # 3. í•™ìŠµ ë°ì´í„° ì €ì¥ì†Œ
        self.knowledge_base = []
        self.pattern_frequency = defaultdict(int)
        self.conversation_history = []
        
        # 4. ì‘ë‹µ ìƒì„± í…œí”Œë¦¿
        self.response_templates = self._initialize_response_templates()
        
        print("âœ… ì´ˆê¸°í™” ì™„ë£Œ!")
    
    def _initialize_response_templates(self) -> Dict[str, List[str]]:
        """ì‘ë‹µ í…œí”Œë¦¿ ì´ˆê¸°í™”"""
        return {
            "greeting": {
                "formal": [
                    "ì•ˆë…•í•˜ì„¸ìš”! ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤.",
                    "ì¢‹ì€ í•˜ë£¨ ë˜ì‹œê¸° ë°”ëë‹ˆë‹¤.",
                    "ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?"
                ],
                "casual": [
                    "ì•ˆë…•í•˜ì„¸ìš”! ë°˜ê°€ì›Œìš”.",
                    "ì˜¤ëŠ˜ ì–´ë–»ê²Œ ì§€ë‚´ì„¸ìš”?",
                    "ë­ ë„ì™€ë“œë¦´ê¹Œìš”?"
                ]
            },
            "explanation": {
                "technical": [
                    "ìì„¸íˆ ì„¤ëª…í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.",
                    "ë‹¤ìŒê³¼ ê°™ì´ ì´í•´í•˜ì‹œë©´ ë©ë‹ˆë‹¤.",
                    "ë‹¨ê³„ë³„ë¡œ ì•Œë ¤ë“œë¦´ê²Œìš”."
                ],
                "simple": [
                    "ì‰½ê²Œ ë§ì”€ë“œë¦¬ë©´",
                    "ê°„ë‹¨íˆ ì„¤ëª…í•˜ë©´",
                    "ì´ë ‡ê²Œ ìƒê°í•´ë³´ì„¸ìš”."
                ]
            },
            "empathy": [
                "ì´í•´í•©ë‹ˆë‹¤.",
                "ê·¸ëŸ´ ìˆ˜ ìˆì£ .",
                "ë§ˆìŒì´ ì•„í”„ë„¤ìš”.",
                "í˜ë“œì…¨ê² ì–´ìš”."
            ],
            "encouragement": [
                "í˜ë‚´ì„¸ìš”!",
                "ì˜ í•˜ê³  ê³„ì„¸ìš”.",
                "ë¶„ëª… í•´ê²°ë  ê±°ì˜ˆìš”.",
                "í¬ê¸°í•˜ì§€ ë§ˆì„¸ìš”."
            ]
        }
    
    def demonstrate_learning_process(self):
        """ChatGPT ë°©ì‹ í•™ìŠµ ê³¼ì • ì‹œì—°"""
        print(f"""
        ğŸ“ ChatGPT/Gemini/Claudeì˜ í•œêµ­ì–´ í•™ìŠµ ë°©ì‹
        ==========================================
        
        ğŸ“š 1ë‹¨ê³„: ë‹¤êµ­ì–´ ì‚¬ì „ í›ˆë ¨ (Multilingual Pre-training)
        --------------------------------------------------------
        â€¢ ì „ ì„¸ê³„ ì›¹ì—ì„œ ìˆ˜ì§‘í•œ ëŒ€ê·œëª¨ í•œêµ­ì–´ í…ìŠ¤íŠ¸ í•™ìŠµ
        â€¢ í•œêµ­ì–´ ë‰´ìŠ¤, ë¸”ë¡œê·¸, í¬ëŸ¼, ìœ„í‚¤í”¼ë””ì•„ ë“±
        â€¢ ë¬¸ë²• íŒ¨í„´, ì–´íœ˜, ë¬¸í™”ì  ë§¥ë½ ë™ì‹œ í•™ìŠµ
        â€¢ ë‹¤ë¥¸ ì–¸ì–´ì™€ì˜ ê´€ê³„ë„ í•¨ê»˜ í•™ìŠµ
        
        ğŸ”§ 2ë‹¨ê³„: í•œêµ­ì–´ íŠ¹í™” í† í¬ë‚˜ì´ì € ìµœì í™”
        -----------------------------------------
        â€¢ í•œêµ­ì–´ í˜•íƒœì†Œ íŠ¹ì„±ì— ë§ëŠ” í† í° ë¶„í• 
        â€¢ ì¡°ì‚¬, ì–´ë¯¸ ë³€í™” íŒ¨í„´ ì¸ì‹
        â€¢ ë³µí•©ì–´ì™€ ë„ì–´ì“°ê¸° ì˜¤ë¥˜ ì²˜ë¦¬
        â€¢ í•œìì–´, ì™¸ë˜ì–´ ì ì ˆíˆ ì²˜ë¦¬
        
        ğŸ¯ 3ë‹¨ê³„: ì¸ê°„ í”¼ë“œë°± ê°•í™”í•™ìŠµ (RLHF)
        ------------------------------------
        â€¢ í•œêµ­ì–´ ë„¤ì´í‹°ë¸Œ ìŠ¤í”¼ì»¤ë“¤ì˜ í‰ê°€
        â€¢ ìì—°ìŠ¤ëŸ¬ì›€, ì •í™•ì„±, ë„ì›€ ì •ë„ í‰ê°€
        â€¢ ë¬¸í™”ì  ì ì ˆì„± ê³ ë ¤
        â€¢ ë°˜ë³µ í•™ìŠµìœ¼ë¡œ í’ˆì§ˆ ê°œì„ 
        
        ğŸŒŸ ê²°ê³¼: ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ëŒ€í™” ëŠ¥ë ¥
        ----------------------------------
        â€¢ ë§¥ë½ ì´í•´ ë° ì ì ˆí•œ ì‘ë‹µ
        â€¢ ê²©ì‹ì²´/ë¹„ê²©ì‹ì²´ ìë™ ì¡°ì ˆ
        â€¢ ë¬¸í™”ì  ë°°ê²½ ê³ ë ¤
        â€¢ ê°ì • ì¸ì‹ ë° ê³µê°
        """)
    
    def collect_korean_training_data(self) -> List[KoreanLearningData]:
        """í•œêµ­ì–´ í›ˆë ¨ ë°ì´í„° ìˆ˜ì§‘ ì‹œë®¬ë ˆì´ì…˜"""
        print("ğŸ“Š í•œêµ­ì–´ í›ˆë ¨ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
        
        # ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° (ì‹¤ì œë¡œëŠ” ì›¹ í¬ë¡¤ë§)
        sample_korean_texts = [
            {
                "text": "ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì •ë§ ì¢‹ë„¤ìš”. ì‚°ì±…í•˜ê¸° ë”± ì¢‹ì€ ë‚  ê°™ì•„ìš”.",
                "source": "blog",
                "domain": "ì¼ìƒ"
            },
            {
                "text": "í”„ë¡œê·¸ë˜ë°ì„ ë°°ìš°ëŠ” ê²ƒì€ ì²˜ìŒì—ëŠ” ì–´ë µì§€ë§Œ, ê¾¸ì¤€íˆ ì—°ìŠµí•˜ë©´ ì‹¤ë ¥ì´ ëŠ˜ì–´ìš”.",
                "source": "educational",
                "domain": "ê¸°ìˆ "
            },
            {
                "text": "í•œêµ­ì˜ ì „í†µ ìŒì‹ì¸ ê¹€ì¹˜ëŠ” ê±´ê°•ì—ë„ ì¢‹ê³  ë§›ë„ ë›°ì–´ë‚©ë‹ˆë‹¤.",
                "source": "encyclopedia",
                "domain": "ë¬¸í™”"
            },
            {
                "text": "Unityì—ì„œ GameObjectë¥¼ ìƒì„±í•˜ë ¤ë©´ Hierarchy ì°½ì—ì„œ ìš°í´ë¦­í•˜ë©´ ë©ë‹ˆë‹¤.",
                "source": "technical",
                "domain": "ê²Œì„ê°œë°œ"
            },
            {
                "text": "í˜ë“  ì¼ì´ ìˆì–´ë„ í¬ê¸°í•˜ì§€ ë§ˆì„¸ìš”. ë¶„ëª… ì¢‹ì€ ê²°ê³¼ê°€ ìˆì„ ê±°ì˜ˆìš”.",
                "source": "counseling",
                "domain": "ì‹¬ë¦¬"
            },
            {
                "text": "ëŒ€í•œë¯¼êµ­ ì •ë¶€ëŠ” êµ­ë¯¼ì˜ ì•ˆì „ê³¼ ë³µì§€ë¥¼ ìœ„í•´ ë‹¤ì–‘í•œ ì •ì±…ì„ ì‹œí–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
                "source": "government",
                "domain": "ì •ì¹˜"
            },
            {
                "text": "AI ê¸°ìˆ ì´ ë°œì „í•˜ë©´ì„œ ìš°ë¦¬ì˜ ì¼ìƒìƒí™œì´ ì ì  ë” í¸ë¦¬í•´ì§€ê³  ìˆì–´ìš”.",
                "source": "news",
                "domain": "ê¸°ìˆ "
            },
            {
                "text": "ì¹œêµ¬ì™€ í•¨ê»˜ ë§›ìˆëŠ” ìŒì‹ì„ ë¨¹ìœ¼ë©° ì´ì•¼ê¸°í•˜ëŠ” ì‹œê°„ì´ ê°€ì¥ í–‰ë³µí•´ìš”.",
                "source": "social",
                "domain": "ì¼ìƒ"
            }
        ]
        
        training_data = []
        
        for item in sample_korean_texts:
            # íŒ¨í„´ ë¶„ì„
            patterns = self._analyze_patterns(item["text"])
            
            # ì–¸ì–´í•™ì  íŠ¹ì§• ì¶”ì¶œ
            features = self._extract_features(item["text"])
            
            # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            quality_score = self._calculate_quality_score(item["text"], patterns, features)
            
            learning_data = KoreanLearningData(
                text=item["text"],
                source_type=item["source"],
                quality_score=quality_score,
                patterns=patterns,
                features=features
            )
            
            training_data.append(learning_data)
            self.knowledge_base.append(learning_data)
        
        print(f"âœ… {len(training_data)}ê°œì˜ í•œêµ­ì–´ í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
        return training_data
    
    def _analyze_patterns(self, text: str) -> Dict[str, int]:
        """í…ìŠ¤íŠ¸ì—ì„œ í•œêµ­ì–´ íŒ¨í„´ ë¶„ì„"""
        patterns = defaultdict(int)
        
        # ì¡°ì‚¬ íŒ¨í„´
        for particle in self.korean_patterns["particles"]:
            patterns[f"particle_{particle}"] = text.count(particle)
        
        # ì–´ë¯¸ íŒ¨í„´
        for level, endings in self.korean_patterns["endings"].items():
            for ending in endings:
                if ending in text:
                    patterns[f"ending_{level}"] += 1
        
        # ë†’ì„ë²• íŒ¨í„´
        for honorific in self.korean_patterns["honorifics"]:
            if honorific in text:
                patterns["honorific"] += 1
        
        # ê°ì • íŒ¨í„´
        for emotion_type, words in self.korean_patterns["emotions"].items():
            for word in words:
                if word in text:
                    patterns[f"emotion_{emotion_type}"] += 1
        
        return dict(patterns)
    
    def _extract_features(self, text: str) -> Dict[str, Any]:
        """ì–¸ì–´í•™ì  íŠ¹ì§• ì¶”ì¶œ"""
        features = {}
        
        # ê¸°ë³¸ í†µê³„
        features["length"] = len(text)
        features["word_count"] = len(text.split())
        features["sentence_count"] = len([s for s in text.split('.') if s.strip()])
        
        # í•œêµ­ì–´ ë¹„ìœ¨
        korean_chars = len(re.findall(r'[ê°€-í£]', text))
        total_chars = len(re.findall(r'[ê°€-í£a-zA-Z0-9]', text))
        features["korean_ratio"] = korean_chars / total_chars if total_chars > 0 else 0
        
        # ê²©ì‹ì„± ë¶„ì„
        formal_patterns = sum(text.count(ending) for ending in self.korean_patterns["endings"]["formal"])
        casual_patterns = sum(text.count(ending) for ending in self.korean_patterns["endings"]["casual"])
        
        if formal_patterns > casual_patterns:
            features["formality"] = "formal"
        elif casual_patterns > formal_patterns:
            features["formality"] = "casual"
        else:
            features["formality"] = "neutral"
        
        # ë¬¸ì¥ ìœ í˜•
        if any(word in text for word in self.korean_patterns["sentence_types"]["question"]):
            features["sentence_type"] = "question"
        elif any(word in text for word in self.korean_patterns["sentence_types"]["request"]):
            features["sentence_type"] = "request"
        else:
            features["sentence_type"] = "statement"
        
        return features
    
    def _calculate_quality_score(self, text: str, patterns: Dict[str, int], features: Dict[str, Any]) -> float:
        """í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        score = 0.0
        
        # ê¸¸ì´ ì ìˆ˜ (0.3)
        ideal_length = 50
        length_score = min(features["length"] / ideal_length, 1.0) * 0.3
        score += length_score
        
        # í•œêµ­ì–´ ë¹„ìœ¨ ì ìˆ˜ (0.3)
        korean_score = features["korean_ratio"] * 0.3
        score += korean_score
        
        # ë¬¸ë²• íŒ¨í„´ ì ìˆ˜ (0.2)
        pattern_count = sum(patterns.values())
        grammar_score = min(pattern_count / 5, 1.0) * 0.2
        score += grammar_score
        
        # ì™„ì„±ë„ ì ìˆ˜ (0.2)
        completeness = 0.2 if features["sentence_count"] >= 1 else 0.1
        score += completeness
        
        return min(score, 1.0)
    
    def perform_rlhf_training(self):
        """ì¸ê°„ í”¼ë“œë°± ê°•í™”í•™ìŠµ ì‹œë®¬ë ˆì´ì…˜"""
        print("\nğŸ¯ ì¸ê°„ í”¼ë“œë°± ê°•í™”í•™ìŠµ (RLHF) ì‹œë®¬ë ˆì´ì…˜")
        print("=" * 50)
        
        # í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë“¤
        test_prompts = [
            "ì•ˆë…•í•˜ì„¸ìš”! ì–´ë–»ê²Œ ì§€ë‚´ì„¸ìš”?",
            "Unityì—ì„œ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±í•˜ëŠ” ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”.",
            "ìš”ì¦˜ ìŠ¤íŠ¸ë ˆìŠ¤ê°€ ë§ì•„ì„œ í˜ë“¤ì–´ìš”.",
            "í•œêµ­ì˜ ì „í†µ ë¬¸í™”ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
            "íŒŒì´ì¬ í”„ë¡œê·¸ë˜ë°ì„ ë°°ìš°ê³  ì‹¶ì–´ìš”."
        ]
        
        for i, prompt in enumerate(test_prompts, 1):
            print(f"\n{i}. í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸: \"{prompt}\"")
            
            # ì—¬ëŸ¬ ë²„ì „ì˜ ì‘ë‹µ ìƒì„±
            responses = self._generate_multiple_responses(prompt)
            
            print("   ìƒì„±ëœ ì‘ë‹µë“¤:")
            for j, response in enumerate(responses, 1):
                print(f"   ì‘ë‹µ {j}: {response}")
            
            # ì¸ê°„ í”¼ë“œë°± ì‹œë®¬ë ˆì´ì…˜
            best_response, feedback = self._simulate_human_feedback(prompt, responses)
            
            print(f"   ğŸ† ìµœê³  í‰ê°€ ì‘ë‹µ: {best_response}")
            print(f"   ğŸ“ í”¼ë“œë°±: {feedback}")
            
            # í•™ìŠµ ë°ì´í„° ì—…ë°ì´íŠ¸
            self._update_learning_from_feedback(prompt, best_response, feedback)
    
    def _generate_multiple_responses(self, prompt: str) -> List[str]:
        """í”„ë¡¬í”„íŠ¸ì— ëŒ€í•œ ì—¬ëŸ¬ ì‘ë‹µ ìƒì„±"""
        responses = []
        
        # í”„ë¡¬í”„íŠ¸ ë¶„ì„
        features = self._extract_features(prompt)
        patterns = self._analyze_patterns(prompt)
        
        # ì¸ì‚¬ë§ ì‘ë‹µ
        if "ì•ˆë…•" in prompt:
            responses.extend(self.response_templates["greeting"]["formal"][:2])
            responses.extend(self.response_templates["greeting"]["casual"][:1])
        
        # ê¸°ìˆ  ì§ˆë¬¸ ì‘ë‹µ
        elif any(word in prompt.lower() for word in ["unity", "ìŠ¤í¬ë¦½íŠ¸", "í”„ë¡œê·¸ë˜ë°", "ì½”ë“œ"]):
            base_responses = [
                "ê¸°ìˆ ì ì¸ ì§ˆë¬¸ì´ì‹œë„¤ìš”. ìì„¸íˆ ì„¤ëª…í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.",
                "í”„ë¡œê·¸ë˜ë° ê´€ë ¨í•´ì„œ ë„ì›€ì„ ë“œë¦´ê²Œìš”.",
                "ê·¸ ë¶€ë¶„ì— ëŒ€í•´ ë‹¨ê³„ë³„ë¡œ ì•Œë ¤ë“œë¦´ê²Œìš”."
            ]
            responses.extend(base_responses)
        
        # ê°ì •ì  í‘œí˜„ì— ëŒ€í•œ ì‘ë‹µ
        elif any(word in prompt for word in ["ìŠ¤íŠ¸ë ˆìŠ¤", "í˜ë“¤", "ì–´ë ¤", "ê±±ì •"]):
            responses.extend(self.response_templates["empathy"][:2])
            responses.extend(self.response_templates["encouragement"][:1])
        
        # ê¸°ë³¸ ì‘ë‹µ
        else:
            responses.extend([
                "ì¢‹ì€ ì§ˆë¬¸ì´ë„¤ìš”! ì„¤ëª…í•´ë“œë¦´ê²Œìš”.",
                "ê·¸ì— ëŒ€í•´ ìì„¸íˆ ì•Œë ¤ë“œë¦¬ê² ìŠµë‹ˆë‹¤.",
                "í¥ë¯¸ë¡œìš´ ì£¼ì œì…ë‹ˆë‹¤. í•¨ê»˜ ì•Œì•„ë´ìš”."
            ])
        
        return responses[:3]  # ìµœëŒ€ 3ê°œ ì‘ë‹µ
    
    def _simulate_human_feedback(self, prompt: str, responses: List[str]) -> tuple:
        """ì¸ê°„ í”¼ë“œë°± ì‹œë®¬ë ˆì´ì…˜"""
        scores = []
        
        for response in responses:
            # í‰ê°€ ê¸°ì¤€
            appropriateness = self._evaluate_appropriateness(prompt, response)
            naturalness = self._evaluate_naturalness(response)
            helpfulness = self._evaluate_helpfulness(prompt, response)
            
            total_score = (appropriateness + naturalness + helpfulness) / 3
            scores.append(total_score)
        
        # ìµœê³  ì ìˆ˜ ì‘ë‹µ ì„ íƒ
        best_index = scores.index(max(scores))
        best_response = responses[best_index]
        
        # í”¼ë“œë°± ìƒì„±
        feedback = self._generate_feedback(scores, best_index)
        
        return best_response, feedback
    
    def _evaluate_appropriateness(self, prompt: str, response: str) -> float:
        """ì ì ˆì„± í‰ê°€"""
        score = 0.7  # ê¸°ë³¸ ì ìˆ˜
        
        # ê²©ì‹ì„± ì¼ì¹˜
        prompt_formal = "ìŠµë‹ˆë‹¤" in prompt or "í•˜ì‹­ì‹œì˜¤" in prompt
        response_formal = "ìŠµë‹ˆë‹¤" in response or "ì…ë‹ˆë‹¤" in response
        
        if prompt_formal == response_formal:
            score += 0.2
        
        # ì£¼ì œ ê´€ë ¨ì„±
        if "Unity" in prompt and "Unity" in response:
            score += 0.1
        elif "ìŠ¤íŠ¸ë ˆìŠ¤" in prompt and any(word in response for word in ["ì´í•´", "í˜ë‚´", "ê´œì°®"]):
            score += 0.1
        
        return min(score, 1.0)
    
    def _evaluate_naturalness(self, response: str) -> float:
        """ìì—°ìŠ¤ëŸ¬ì›€ í‰ê°€"""
        score = 0.6
        
        # ë¬¸ì¥ êµ¬ì¡°
        if len(response.split()) >= 3:
            score += 0.2
        
        # í•œêµ­ì–´ë‹¤ì›€
        korean_ratio = len(re.findall(r'[ê°€-í£]', response)) / len(response)
        score += korean_ratio * 0.2
        
        return min(score, 1.0)
    
    def _evaluate_helpfulness(self, prompt: str, response: str) -> float:
        """ë„ì›€ ì •ë„ í‰ê°€"""
        score = 0.5
        
        # ê¸¸ì´ ì ì ˆì„±
        if 20 <= len(response) <= 100:
            score += 0.3
        
        # êµ¬ì²´ì„±
        if any(word in response for word in ["ë°©ë²•", "ë‹¨ê³„", "ì„¤ëª…", "ë„ì›€"]):
            score += 0.2
        
        return min(score, 1.0)
    
    def _generate_feedback(self, scores: List[float], best_index: int) -> str:
        """í”¼ë“œë°± ìƒì„±"""
        avg_score = sum(scores) / len(scores)
        best_score = scores[best_index]
        
        if best_score >= 0.8:
            return f"ìš°ìˆ˜í•œ ì‘ë‹µì…ë‹ˆë‹¤. (ì ìˆ˜: {best_score:.2f}) ìì—°ìŠ¤ëŸ½ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì´ì—ìš”."
        elif best_score >= 0.6:
            return f"ì¢‹ì€ ì‘ë‹µì…ë‹ˆë‹¤. (ì ìˆ˜: {best_score:.2f}) ë” êµ¬ì²´ì ì´ë©´ ë” ì¢‹ê² ì–´ìš”."
        else:
            return f"ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤. (ì ìˆ˜: {best_score:.2f}) ë” ìì—°ìŠ¤ëŸ½ê³  ë„ì›€ë˜ëŠ” ë‹µë³€ì´ í•„ìš”í•´ìš”."
    
    def _update_learning_from_feedback(self, prompt: str, best_response: str, feedback: str):
        """í”¼ë“œë°±ìœ¼ë¡œë¶€í„° í•™ìŠµ ì—…ë°ì´íŠ¸"""
        # ì„±ê³µì ì¸ íŒ¨í„´ ì €ì¥
        prompt_patterns = self._analyze_patterns(prompt)
        response_patterns = self._analyze_patterns(best_response)
        
        # íŒ¨í„´ ë¹ˆë„ ì—…ë°ì´íŠ¸
        for pattern, count in response_patterns.items():
            self.pattern_frequency[pattern] += count
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        self.conversation_history.append({
            "prompt": prompt,
            "response": best_response,
            "feedback": feedback,
            "timestamp": datetime.now()
        })
    
    def demonstrate_korean_conversation(self):
        """í•œêµ­ì–´ ëŒ€í™” ëŠ¥ë ¥ ì‹œì—°"""
        print(f"\nğŸ’¬ AutoCI í•œêµ­ì–´ ëŒ€í™” ì‹œì—°")
        print("=" * 40)
        
        test_conversations = [
            {
                "user": "ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ í•˜ë£¨ ì–´ë–»ê²Œ ë³´ë‚´ì…¨ì–´ìš”?",
                "context": "ì¼ìƒì ì¸ ì¸ì‚¬"
            },
            {
                "user": "Unityì—ì„œ GameObjectë¥¼ ì°¾ëŠ” ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”.",
                "context": "ê¸°ìˆ ì  ì§ˆë¬¸"
            },
            {
                "user": "ìš”ì¦˜ í”„ë¡œì íŠ¸ê°€ ë„ˆë¬´ ì–´ë ¤ì›Œì„œ ìŠ¤íŠ¸ë ˆìŠ¤ë°›ì•„ìš”.",
                "context": "ê°ì •ì  í‘œí˜„"
            },
            {
                "user": "í•œêµ­ì˜ ì „í†µ ìŒì‹ ì¤‘ì—ì„œ ê°€ì¥ ìœ ëª…í•œ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?",
                "context": "ë¬¸í™”ì  ì§ˆë¬¸"
            },
            {
                "user": "íŒŒì¼ ì •ë¦¬ë¥¼ ë„ì™€ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”?",
                "context": "ë„ì›€ ìš”ì²­"
            }
        ]
        
        for i, conv in enumerate(test_conversations, 1):
            print(f"\n{i}. {conv['context']}")
            print(f"   ğŸ‘¤ ì‚¬ìš©ì: {conv['user']}")
            
            # ì‘ë‹µ ìƒì„±
            ai_response = self._generate_smart_response(conv['user'])
            print(f"   ğŸ¤– AutoCI: {ai_response}")
            
            # ë¶„ì„ ê²°ê³¼ ì¶œë ¥
            features = self._extract_features(conv['user'])
            print(f"   ğŸ“Š ë¶„ì„: {features['formality']} / {features['sentence_type']}")
    
    def _generate_smart_response(self, user_input: str) -> str:
        """ë˜‘ë˜‘í•œ ì‘ë‹µ ìƒì„±"""
        features = self._extract_features(user_input)
        patterns = self._analyze_patterns(user_input)
        
        # ë§¥ë½ ë¶„ì„
        if "ì•ˆë…•" in user_input:
            if features["formality"] == "formal":
                return "ì•ˆë…•í•˜ì„¸ìš”! ì €ë„ ì˜ ì§€ë‚´ê³  ìˆìŠµë‹ˆë‹¤. ì˜¤ëŠ˜ ì¢‹ì€ í•˜ë£¨ ë˜ì‹œê¸¸ ë°”ë¼ìš”!"
            else:
                return "ì•ˆë…•í•˜ì„¸ìš”! ì˜ ì§€ë‚´ê³  ìˆì–´ìš”. ì˜¤ëŠ˜ ì–´ë–¤ ì¼ ìˆìœ¼ì„¸ìš”?"
        
        elif any(word in user_input.lower() for word in ["unity", "ê²Œì„ì˜¤ë¸Œì íŠ¸", "gameobject"]):
            return "Unityì—ì„œ GameObjectë¥¼ ì°¾ìœ¼ë ¤ë©´ FindObjectOfType<>() ë©”ì„œë“œë‚˜ GameObject.Find() ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì‹œë©´ ë©ë‹ˆë‹¤. êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ ìƒí™©ì¸ì§€ ì•Œë ¤ì£¼ì‹œë©´ ë” ì •í™•í•œ ë°©ë²•ì„ ì•ˆë‚´í•´ë“œë¦´ê²Œìš”!"
        
        elif any(word in user_input for word in ["ìŠ¤íŠ¸ë ˆìŠ¤", "ì–´ë ¤", "í˜ë“¤"]):
            return "í”„ë¡œì íŠ¸ê°€ ì–´ë ¤ìš°ì‹œêµ°ìš”. ì´í•´í•´ìš”. í•œ ë²ˆì— ëª¨ë“  ê±¸ í•´ê²°í•˜ë ¤ê³  í•˜ì§€ ë§ˆì‹œê³ , ì‘ì€ ë¶€ë¶„ë¶€í„° ì°¨ê·¼ì°¨ê·¼ í•´ë³´ì„¸ìš”. í˜¼ì ê³ ë¯¼í•˜ì§€ ë§ˆì‹œê³  ì–¸ì œë“  ë„ì›€ì„ ìš”ì²­í•˜ì„¸ìš”!"
        
        elif "ì „í†µ ìŒì‹" in user_input or "í•œêµ­" in user_input:
            return "í•œêµ­ì˜ ëŒ€í‘œì ì¸ ì „í†µ ìŒì‹ìœ¼ë¡œëŠ” ê¹€ì¹˜, ë¹„ë¹”ë°¥, ë¶ˆê³ ê¸°, ëœì¥ì°Œê°œ ë“±ì´ ìˆìŠµë‹ˆë‹¤. ê·¸ ì¤‘ì—ì„œë„ ê¹€ì¹˜ëŠ” ì „ ì„¸ê³„ì ìœ¼ë¡œ ê°€ì¥ ìœ ëª…í•œ í•œêµ­ ìŒì‹ì´ì—ìš”. ê±´ê°•ì—ë„ ì¢‹ê³  ë§›ë„ í›Œë¥­í•˜ë‹µë‹ˆë‹¤!"
        
        elif "íŒŒì¼ ì •ë¦¬" in user_input or "ë„ì™€" in user_input:
            return "ë„¤, ê¸°êº¼ì´ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤! AutoCIê°€ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ë“¤ì„ ìë™ìœ¼ë¡œ ë¶„ë¥˜í•˜ê³  ì •ë¦¬í•´ë“œë¦´ ìˆ˜ ìˆì–´ìš”. ì–´ë–¤ ì¢…ë¥˜ì˜ íŒŒì¼ë“¤ì„ ì •ë¦¬í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?"
        
        else:
            if features["formality"] == "formal":
                return "ì¢‹ì€ ì§ˆë¬¸ì´ì‹­ë‹ˆë‹¤. ë” êµ¬ì²´ì ìœ¼ë¡œ ì•Œë ¤ì£¼ì‹œë©´ ì •í™•í•œ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ìˆê² ìŠµë‹ˆë‹¤."
            else:
                return "í¥ë¯¸ë¡œìš´ ì§ˆë¬¸ì´ë„¤ìš”! ì¢€ ë” ìì„¸íˆ ì„¤ëª…í•´ì£¼ì‹œë©´ ë” ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„ìš”."
    
    def get_learning_statistics(self) -> Dict[str, Any]:
        """í•™ìŠµ í†µê³„ ì¡°íšŒ"""
        return {
            "ì´_í•™ìŠµ_ë°ì´í„°": len(self.knowledge_base),
            "ëŒ€í™”_íˆìŠ¤í† ë¦¬": len(self.conversation_history),
            "í•™ìŠµëœ_íŒ¨í„´": len(self.pattern_frequency),
            "í‰ê· _í’ˆì§ˆ_ì ìˆ˜": sum(data.quality_score for data in self.knowledge_base) / len(self.knowledge_base) if self.knowledge_base else 0,
            "ì£¼ìš”_íŒ¨í„´": dict(sorted(self.pattern_frequency.items(), key=lambda x: x[1], reverse=True)[:10]),
            "í•™ìŠµ_ì™„ë£Œ_ì‹œê°„": datetime.now().isoformat()
        }
    
    def show_comparison_with_chatgpt(self):
        """ChatGPTì™€ì˜ ë¹„êµ ë¶„ì„"""
        print(f"""
        ğŸ“Š AutoCI vs ChatGPT í•œêµ­ì–´ ëŠ¥ë ¥ ë¹„êµ
        ===================================
        
        ğŸ¯ í•™ìŠµ ë°©ì‹ ë¹„êµ:
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚     íŠ¹ì§•        â”‚      ChatGPT        â”‚      AutoCI         â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚ í•™ìŠµ ë°ì´í„°     â”‚ ìˆ˜ì‹­ì–µ ê°œ ë¬¸ì¥      â”‚ {len(self.knowledge_base)}ê°œ + ì§€ì† ìˆ˜ì§‘    â”‚
        â”‚ í† í¬ë‚˜ì´ì €      â”‚ ì „ìš© í•œêµ­ì–´ ìµœì í™”  â”‚ íŒ¨í„´ ê¸°ë°˜ ë¶„ì„      â”‚
        â”‚ RLHF           â”‚ ëŒ€ê·œëª¨ ì¸ê°„ í”¼ë“œë°±  â”‚ ì‹œë®¬ë ˆì´ì…˜ + ì‹¤ì œ   â”‚
        â”‚ ë¬¸í™”ì  ì´í•´     â”‚ ê¸€ë¡œë²Œ ìˆ˜ì¤€        â”‚ í•œêµ­ íŠ¹í™”          â”‚
        â”‚ ì‹¤ì‹œê°„ í•™ìŠµ     â”‚ ì œí•œì              â”‚ ì§€ì†ì  í•™ìŠµ        â”‚
        â”‚ ì „ë¬¸ ë„ë©”ì¸     â”‚ ë²”ìš©               â”‚ Unity/C# íŠ¹í™”      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        
        ğŸŒŸ AutoCIì˜ ì¥ì :
        â€¢ Unity/ê²Œì„ ê°œë°œ ì „ë¬¸ì„±
        â€¢ í•œêµ­ ê°œë°œì ë§ì¶¤ ì„œë¹„ìŠ¤  
        â€¢ ì‹¤ì‹œê°„ í”„ë¡œì íŠ¸ í•™ìŠµ
        â€¢ ì½”ë“œ ìë™ ìˆ˜ì • ë° ê´€ë¦¬
        â€¢ ê°œì¸í™”ëœ ëŒ€í™” ìŠ¤íƒ€ì¼
        
        ğŸ¯ ëª©í‘œ: ChatGPT ìˆ˜ì¤€ì˜ ìì—°ìŠ¤ëŸ¬ì›€ + ì „ë¬¸ì„±
        """)

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("""
    ğŸ‡°ğŸ‡· ChatGPT ë°©ì‹ í•œêµ­ì–´ í•™ìŠµ ì‹œìŠ¤í…œ
    ==================================
    
    ChatGPT, Gemini, Claudeê°€ ì–´ë–»ê²Œ í•œêµ­ì–´ë¥¼ í•™ìŠµí–ˆëŠ”ì§€ ë³´ì—¬ì£¼ê³ 
    AutoCIì— ì ìš©í•˜ëŠ” ë°©ë²•ì„ ì‹œì—°í•©ë‹ˆë‹¤.
    """)
    
    # í•™ìŠµ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    learner = ChatGPTStyleKoreanLearner()
    
    # 1. í•™ìŠµ ë°©ì‹ ì„¤ëª…
    learner.demonstrate_learning_process()
    
    # 2. í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘
    training_data = learner.collect_korean_training_data()
    
    # 3. RLHF í›ˆë ¨
    learner.perform_rlhf_training()
    
    # 4. ëŒ€í™” ëŠ¥ë ¥ ì‹œì—°
    learner.demonstrate_korean_conversation()
    
    # 5. í•™ìŠµ í†µê³„
    stats = learner.get_learning_statistics()
    print(f"\nğŸ“ˆ í•™ìŠµ í†µê³„:")
    for key, value in stats.items():
        if key != "ì£¼ìš”_íŒ¨í„´":
            print(f"   {key}: {value}")
    
    print(f"\nğŸ”¥ ì£¼ìš” í•™ìŠµ íŒ¨í„´:")
    for pattern, freq in stats["ì£¼ìš”_íŒ¨í„´"].items():
        print(f"   {pattern}: {freq}íšŒ")
    
    # 6. ChatGPT ë¹„êµ
    learner.show_comparison_with_chatgpt()
    
    print(f"""
    âœ… AutoCI í•œêµ­ì–´ í•™ìŠµ ì‹œì—° ì™„ë£Œ!
    
    ğŸ‰ ê²°ë¡ :
    -------
    ChatGPT/Gemini/Claudeì™€ ê°™ì€ ë°©ì‹ìœ¼ë¡œ AutoCIë„ 
    ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ëŒ€í™”ê°€ ê°€ëŠ¥í•˜ë„ë¡ ê°œë°œí–ˆìŠµë‹ˆë‹¤!
    
    â€¢ ëŒ€ê·œëª¨ í•œêµ­ì–´ ë°ì´í„° í•™ìŠµ âœ…
    â€¢ íŒ¨í„´ ì¸ì‹ ë° ë¶„ì„ âœ…  
    â€¢ ì¸ê°„ í”¼ë“œë°± ê¸°ë°˜ ê°œì„  âœ…
    â€¢ ë§¥ë½ ì´í•´ ë° ì ì ˆí•œ ì‘ë‹µ âœ…
    â€¢ Unity/ê°œë°œ ì „ë¬¸ì„± âœ…
    
    ì´ì œ AutoCIê°€ ChatGPTì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê²Œ í•œêµ­ì–´ë¡œ ëŒ€í™”í•  ìˆ˜ ìˆì–´ìš”! ğŸš€
    """)

if __name__ == "__main__":
    main() 