# AutoCI íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ê°€ì´ë“œ

## ğŸš€ ì‹¤í–‰ ë°©ë²•

### ë¹ ë¥¸ ì‹œì‘ (ê¶Œì¥)
```bash
# AutoCI ë£¨íŠ¸ ë””ë ‰í† ë¦¬ì—ì„œ ì‹¤í–‰
python start_all.py
```

### ìˆ˜ë™ ì‹¤í–‰ (4ê°œ í„°ë¯¸ë„ í•„ìš”)

#### í„°ë¯¸ë„ 1: Python AI ì„œë²„ (í¬íŠ¸ 8000)
```bash
# ê°€ìƒí™˜ê²½ í™œì„±í™”
source llm_venv_wsl/bin/activate  # WSL/Linux
# ë˜ëŠ”
llm_venv\Scripts\activate  # Windows

# ì„œë²„ ì‹¤í–‰
python simple_server.py
# ë˜ëŠ” enhanced_server.py ì‚¬ìš©
```

#### í„°ë¯¸ë„ 2: ìë™ í•™ìŠµ ì‹œìŠ¤í…œ
```bash
python auto_train_collector.py
```

#### í„°ë¯¸ë„ 3: C# Backend (í¬íŠ¸ 5049)
```bash
cd MyAIWebApp/Backend
dotnet run
```

#### í„°ë¯¸ë„ 4: Frontend (í¬íŠ¸ 7100/5100)
```bash
cd MyAIWebApp/Frontend
dotnet run
```

## ğŸ“‹ ì‹¤í–‰ ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸

### 1. í•„ìˆ˜ ì†Œí”„íŠ¸ì›¨ì–´ ì„¤ì¹˜ í™•ì¸
```bash
# Python ë²„ì „ í™•ì¸ (3.8 ì´ìƒ)
python --version

# .NET SDK í™•ì¸ (8.0 ì´ìƒ)
dotnet --version

# Node.js í™•ì¸ (ì„ íƒì‚¬í•­)
node --version
```

### 2. Python í™˜ê²½ ì„¤ì •
```bash
# ê°€ìƒí™˜ê²½ ìƒì„± (ì²˜ìŒ í•œ ë²ˆë§Œ)
python -m venv llm_venv

# íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r MyAIWebApp/Models/requirements.txt
```

### 3. Code Llama ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
```bash
# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ì•½ 13GB)
python download_model.py

# ë‹¤ìš´ë¡œë“œ í™•ì¸
ls -la CodeLlama-7b-Instruct-hf/
```

## ğŸ”§ ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œì™€ í•´ê²°ë²•

### Frontendê°€ http://localhost:5100ì—ì„œ ì‹¤í–‰ë˜ì§€ ì•ŠëŠ” ê²½ìš°

#### 1. í¬íŠ¸ ì¶©ëŒ í™•ì¸
```bash
# Windows
netstat -ano | findstr :5100
netstat -ano | findstr :7100
netstat -ano | findstr :5049
netstat -ano | findstr :8000

# Linux/Mac
lsof -i :5100
lsof -i :7100
lsof -i :5049
lsof -i :8000
```

#### 2. launchSettings.json í™•ì¸
Frontendì˜ í¬íŠ¸ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”:
```json
// MyAIWebApp/Frontend/Properties/launchSettings.json
{
  "profiles": {
    "http": {
      "applicationUrl": "http://localhost:5100"
    },
    "https": {
      "applicationUrl": "https://localhost:7100;http://localhost:5100"
    }
  }
}
```

### Python ê´€ë ¨ ë¬¸ì œ

#### "transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
```bash
# ê°€ìƒí™˜ê²½ í™œì„±í™” í™•ì¸
which python  # Linux/Mac
where python  # Windows

# íŒ¨í‚¤ì§€ ì¬ì„¤ì¹˜
pip install transformers torch accelerate sentencepiece protobuf
```

#### "No module named 'fastapi'"
```bash
pip install fastapi uvicorn[standard] watchdog
```

#### CUDA/GPU ì˜¤ë¥˜
```bash
# CPU ëª¨ë“œë¡œ ì „í™˜
pip install torch --index-url https://download.pytorch.org/whl/cpu

# CUDA ë²„ì „ í™•ì¸
nvidia-smi

# CUDA 11.8ìš© PyTorch ì„¤ì¹˜
pip install torch --index-url https://download.pytorch.org/whl/cu118
```

### ëª¨ë¸ ê´€ë ¨ ë¬¸ì œ

#### "ëª¨ë¸ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
```bash
# ëª¨ë¸ ì¡´ì¬ í™•ì¸
ls CodeLlama-7b-Instruct-hf/

# ëª¨ë¸ ì¬ë‹¤ìš´ë¡œë“œ
python download_model.py
```

#### ë©”ëª¨ë¦¬ ë¶€ì¡±
- ìµœì†Œ 16GB RAM í•„ìš”
- 8-bit ì–‘ìí™” ì‚¬ìš©:
```python
# simple_server.py ìˆ˜ì •
model = AutoModelForCausalLM.from_pretrained(
    model_path,
    load_in_8bit=True,  # ë©”ëª¨ë¦¬ ì ˆì•½
    device_map="auto"
)
```

### .NET/C# ê´€ë ¨ ë¬¸ì œ

#### "dotnet: command not found"
```bash
# .NET ì„¤ì¹˜ í™•ì¸
dotnet --version

# ì„¤ì¹˜ í•„ìš”ì‹œ
# https://dotnet.microsoft.com/download
```

#### HTTP/HTTPS ë¦¬ë‹¤ì´ë ‰ì…˜ ë¬¸ì œ
```csharp
// Backend/Program.csì—ì„œ HTTPS ë¦¬ë‹¤ì´ë ‰ì…˜ ë¹„í™œì„±í™”
// app.UseHttpsRedirection(); // ì£¼ì„ ì²˜ë¦¬
```

### CORS ë¬¸ì œ

#### Frontend-Backend ì—°ê²° ì‹¤íŒ¨
```csharp
// Backend/Program.cs í™•ì¸
builder.Services.AddCors(options =>
{
    options.AddPolicy("AllowBlazorClient",
        builder => builder
            .WithOrigins("https://localhost:7100", "http://localhost:5100")
            .AllowAnyMethod()
            .AllowAnyHeader()
            .AllowCredentials());
});

// ë¯¸ë“¤ì›¨ì–´ ìˆœì„œ í™•ì¸
app.UseCors("AllowBlazorClient");  // UseRouting() ë‹¤ìŒì— ìœ„ì¹˜
```

### WSL íŠ¹í™” ë¬¸ì œ

#### localhost ì ‘ê·¼ ë¬¸ì œ
```bash
# WSL IP í™•ì¸
hostname -I

# Windowsì—ì„œ WSL ì„œë¹„ìŠ¤ ì ‘ê·¼
# localhost ëŒ€ì‹  WSL IP ì‚¬ìš©
```

#### íŒŒì¼ ê¶Œí•œ
```bash
chmod +x start_all.py
chmod +x download_model.py
chmod +x start.sh
```

## ğŸ› ï¸ ë””ë²„ê¹… ë°©ë²•

### 1. ì„œë¹„ìŠ¤ë³„ ìƒíƒœ í™•ì¸
- Python AI Server: http://localhost:8000/status
- Backend Swagger: http://localhost:5049/swagger
- Frontend: http://localhost:7100

### 2. ìƒì„¸ ë¡œê·¸ í™œì„±í™”
```bash
# Python ì„œë²„
uvicorn simple_server:app --log-level debug

# .NET ì• í”Œë¦¬ì¼€ì´ì…˜
dotnet run --verbosity detailed
```

### 3. ë„¤íŠ¸ì›Œí¬ í…ŒìŠ¤íŠ¸
```bash
# API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸
curl http://localhost:8000/generate -X POST -H "Content-Type: application/json" -d '{"prompt":"Hello"}'

# Backend ìƒíƒœ í™•ì¸
curl http://localhost:5049/api/ai/status
```

## ğŸ’¡ ì„±ëŠ¥ ìµœì í™” íŒ

### 1. GPU ì‚¬ìš©
```python
import torch
if torch.cuda.is_available():
    print(f"GPU: {torch.cuda.get_device_name(0)}")
    print(f"Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
```

### 2. ëª¨ë¸ ìºì‹±
```python
# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
os.environ['TRANSFORMERS_CACHE'] = './model_cache'
```

### 3. ë°°ì¹˜ ì²˜ë¦¬
```python
# ì—¬ëŸ¬ ìš”ì²­ì„ í•œ ë²ˆì— ì²˜ë¦¬
batch_size = 4  # GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì •
```

## ğŸ†˜ ê¸´ê¸‰ ë³µêµ¬

### ëª¨ë“  í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
```bash
# Windows
taskkill /F /IM python.exe
taskkill /F /IM dotnet.exe

# Linux/Mac
pkill -f python
pkill -f dotnet
```

### ì™„ì „ ì¬ì„¤ì¹˜
```bash
# ê°€ìƒí™˜ê²½ ì‚­ì œ
rm -rf llm_venv llm_venv_wsl

# ìºì‹œ ì‚­ì œ
rm -rf ~/.cache/huggingface
rm -rf model_cache

# ì¬ì„¤ì¹˜
python -m venv llm_venv
source llm_venv/bin/activate
pip install -r MyAIWebApp/Models/requirements.txt
```

## ğŸ“ ì¶”ê°€ ì§€ì›

ë¬¸ì œ í•´ê²°ì´ ì–´ë ¤ìš´ ê²½ìš°:
1. ì „ì²´ ì—ëŸ¬ ë¡œê·¸ ìˆ˜ì§‘
2. ì‹œìŠ¤í…œ ì •ë³´: OS, Python ë²„ì „, .NET ë²„ì „
3. ì‹¤í–‰í•œ ëª…ë ¹ì–´ ìˆœì„œ
4. GitHub Issuesì— ìƒì„¸ ë‚´ìš© ì œì¶œ