#!/usr/bin/env python3
"""
ê³ ê¸‰ í•œêµ­ì–´ AI ì²˜ë¦¬ ëª¨ë“ˆ
ChatGPT ìˆ˜ì¤€ì˜ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ëŒ€í™” ì²˜ë¦¬
"""

import re
import json
import random
from typing import Dict, List, Tuple, Optional
from datetime import datetime
import sqlite3
from pathlib import Path
from collections import defaultdict
import logging

logger = logging.getLogger(__name__)


class AdvancedKoreanAI:
    """ChatGPT ìˆ˜ì¤€ì˜ ê³ ê¸‰ í•œêµ­ì–´ AI"""
    
    def __init__(self):
        self.base_path = Path(__file__).parent
        
        # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬
        self.conversation_history = []
        self.user_profile = {
            'formality_preference': 'polite',
            'expertise_level': 'intermediate',
            'preferred_topics': [],
            'interaction_count': 0
        }
        
        # ê³ ê¸‰ ì–¸ì–´ íŒ¨í„´
        self.advanced_patterns = {
            # ì˜ë„ ë¶„ë¥˜
            'intent_patterns': {
                'greeting': ['ì•ˆë…•', 'ë°˜ê°€', 'ì²˜ìŒ', 'ë§Œë‚˜ì„œ', 'ì¸ì‚¬', 'í•˜ì´', 'í—¬ë¡œ'],
                'farewell': ['ì˜ê°€', 'ì•ˆë…•íˆ', 'ë‹¤ìŒì—', 'ë‚˜ì¤‘ì—', 'ì¢…ë£Œ', 'ë', 'ë°”ì´'],
                'question': ['ë­', 'ë­˜', 'ì–´ë–»ê²Œ', 'ì™œ', 'ì–¸ì œ', 'ì–´ë””', 'ëˆ„ê°€', 'ì–¼ë§ˆë‚˜', 'ë¬´ì—‡', 'ì–´ëŠ'],
                'request': ['í•´ì¤˜', 'í•´ì£¼ì„¸ìš”', 'ë¶€íƒ', 'ì¢€', 'ì œë°œ', 'ì›í•´', 'ì›í•©ë‹ˆë‹¤', 'ì‹¶ì–´', 'ì‹¶ìŠµë‹ˆë‹¤'],
                'confirmation': ['ë§ì•„', 'ë§ì£ ', 'ê·¸ë ‡ì£ ', 'ë„¤', 'ì˜ˆ', 'ì‘', 'í™•ì¸', 'ì•Œì•˜ì–´'],
                'denial': ['ì•„ë‹ˆ', 'ì•„ëƒ', 'ì•„ë‹™ë‹ˆë‹¤', 'í‹€ë ¤', 'ì˜ëª»', 'ì•ˆë¼', 'ì•ˆë©ë‹ˆë‹¤'],
                'appreciation': ['ê³ ë§ˆì›Œ', 'ê°ì‚¬', 'ë•¡í', 'ê³ ë§™ìŠµë‹ˆë‹¤', 'ê°ì‚¬í•©ë‹ˆë‹¤', 'ìµœê³ ', 'ì¢‹ì•„'],
                'complaint': ['í˜ë“¤ì–´', 'ì–´ë ¤ì›Œ', 'ì•ˆë¼', 'ë¬¸ì œ', 'ì˜¤ë¥˜', 'ì—ëŸ¬', 'ë²„ê·¸', 'ì´ìƒí•´']
            },
            
            # ì£¼ì œ ë¶„ë¥˜
            'topic_patterns': {
                'unity': ['ìœ ë‹ˆí‹°', 'Unity', 'ê²Œì„', 'ì”¬', 'Scene', 'GameObject', 'Prefab', 
                         'Component', 'Transform', 'Rigidbody', 'Collider', 'UI', 'Canvas'],
                'csharp': ['C#', 'csharp', 'ì”¨ìƒµ', 'async', 'await', 'class', 'interface', 
                          'namespace', 'using', 'public', 'private', 'void', 'return'],
                'coding': ['ì½”ë“œ', 'ì½”ë”©', 'í”„ë¡œê·¸ë˜ë°', 'ê°œë°œ', 'í•¨ìˆ˜', 'ë©”ì†Œë“œ', 'ë³€ìˆ˜', 
                          'í´ë˜ìŠ¤', 'ì•Œê³ ë¦¬ì¦˜', 'ë””ë²„ê¹…', 'ë¦¬íŒ©í† ë§', 'ìµœì í™”'],
                'error': ['ì—ëŸ¬', 'ì˜¤ë¥˜', 'ë²„ê·¸', 'ë¬¸ì œ', 'ì•ˆë¼', 'ì•ˆë¨', 'ì‹¤íŒ¨', 'null', 
                         'exception', 'NullReference', 'IndexOutOfRange'],
                'help': ['ë„ì›€', 'ë„ì™€', 'ì„¤ëª…', 'ì•Œë ¤', 'ê°€ë¥´ì³', 'ëª¨ë¥´ê² ', 'ì–´ë–»ê²Œ', 'ë°©ë²•'],
                'project': ['í”„ë¡œì íŠ¸', 'íŒŒì¼', 'í´ë”', 'ë””ë ‰í† ë¦¬', 'ê²½ë¡œ', 'ì €ì¥', 'ë¶ˆëŸ¬ì˜¤ê¸°', 'git']
            },
            
            # ê°ì • ë¶„ì„ í™•ì¥
            'emotion_patterns': {
                'happy': ['ê¸°ë»', 'ì¢‹ì•„', 'í–‰ë³µ', 'ì¦ê±°ì›Œ', 'ì‹ ë‚˜', 'ìµœê³ ', 'ì§±', 'ëŒ€ë°•', 'êµ¿', 'ë‚˜ì´ìŠ¤'],
                'sad': ['ìŠ¬í¼', 'ìš°ìš¸', 'í˜ë“¤ì–´', 'ì§€ì³', 'í”¼ê³¤', 'ì™¸ë¡œì›Œ', 'ì“¸ì“¸'],
                'angry': ['í™”ë‚˜', 'ì§œì¦', 'ì—´ë°›ì•„', 'ë¹¡ì³', 'ì‹«ì–´', 'ë¯¸ì›Œ', 'ë‚˜ë¹ '],
                'confused': ['í—·ê°ˆë ¤', 'ëª¨ë¥´ê² ì–´', 'ì–´ë ¤ì›Œ', 'ë³µì¡í•´', 'ì´í•´ì•ˆë¼', 'ë­”ì†Œë¦¬'],
                'excited': ['ì‹ ë‚˜', 'ê¸°ëŒ€', 'ì„¤ë ˆ', 'ì¢‹ì•„', 'ì™€', 'ëŒ€ë°•', 'ì©ë‹¤', 'ë©‹ì ¸'],
                'frustrated': ['ë‹µë‹µí•´', 'ë§‰ë§‰í•´', 'ê°‘ê°‘í•´', 'ì•ˆí’€ë ¤', 'ë§‰í˜€', 'ì–´ë ¤ì›Œ']
            },
            
            # ì „ë¬¸ ìš©ì–´ ì‚¬ì „
            'technical_terms': {
                'design_patterns': ['ì‹±ê¸€í†¤', 'íŒ©í† ë¦¬', 'ì˜µì €ë²„', 'ì „ëµ', 'ë°ì½”ë ˆì´í„°', 'MVC', 'MVP', 'MVVM'],
                'unity_specific': ['ì½”ë£¨í‹´', 'í”„ë¦¬íŒ¹', 'ì—ì…‹', 'ì”¬', 'ë Œë”ë§', 'ë¼ì´íŠ¸ë§µ', 'ì‰ì´ë”', 'ë¨¸í‹°ë¦¬ì–¼'],
                'programming': ['ë¹„ë™ê¸°', 'ë™ê¸°', 'ìŠ¤ë ˆë“œ', 'í”„ë¡œì„¸ìŠ¤', 'ë©”ëª¨ë¦¬', 'ê°€ë¹„ì§€ì»¬ë ‰ì…˜', 'LINQ', 'ëŒë‹¤']
            }
        }
        
        # ì‘ë‹µ í…œí”Œë¦¿ (ë” ë‹¤ì–‘í•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ)
        self.response_templates = {
            'greeting': {
                'formal': [
                    "ì•ˆë…•í•˜ì„¸ìš”! AutoCIì™€ í•¨ê»˜ ì¦ê±°ìš´ ì½”ë”© ì‹œê°„ ë˜ì„¸ìš”! ğŸ˜Š",
                    "ë°˜ê°‘ìŠµë‹ˆë‹¤! ì˜¤ëŠ˜ì€ ì–´ë–¤ í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í•˜ê³  ê³„ì‹ ê°€ìš”?",
                    "í™˜ì˜í•©ë‹ˆë‹¤! Unityì™€ C# ê°œë°œì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!"
                ],
                'casual': [
                    "ì•ˆë…•! ì˜¤ëŠ˜ë„ ì—´ì‹¬íˆ ì½”ë”©í•˜ëŠ”êµ¬ë‚˜! ğŸ‘‹",
                    "ë°˜ê°€ì›Œ! ë­ ë„ì™€ì¤„ê¹Œ?",
                    "í•˜ì´! ì˜¤ëŠ˜ì€ ë­˜ ë§Œë“¤ì–´ë³¼ê¹Œ?"
                ]
            },
            'understanding': [
                "ë„¤, ì´í•´í–ˆìŠµë‹ˆë‹¤. {detail}",
                "ì•„, ê·¸ëŸ° ëœ»ì´ì—ˆêµ°ìš”! {detail}",
                "ì•Œê² ìŠµë‹ˆë‹¤. {detail}",
                "ì¢‹ì€ ì§ˆë¬¸ì´ë„¤ìš”! {detail}"
            ],
            'thinking': [
                "í ... ì ì‹œë§Œ ìƒê°í•´ë³¼ê²Œìš”.",
                "ì•„, ê·¸ê±°ë¼ë©´...",
                "ì¢‹ì€ í¬ì¸íŠ¸ë„¤ìš”. ì œ ìƒê°ì—”...",
                "ê·¸ ë¶€ë¶„ì— ëŒ€í•´ì„œëŠ”..."
            ],
            'suggestion': [
                "ì œì•ˆë“œë¦¬ìë©´, {suggestion}",
                "ì´ëŸ° ë°©ë²•ì€ ì–´ë–¨ê¹Œìš”? {suggestion}",
                "{suggestion} ì´ë ‡ê²Œ í•´ë³´ì‹œëŠ” ê±´ ì–´ë–¨ê¹Œìš”?",
                "ê²½í—˜ìƒ {suggestion} ì´ ë°©ë²•ì´ íš¨ê³¼ì ì´ì—ˆì–´ìš”."
            ],
            'encouragement': [
                "ì˜í•˜ê³  ê³„ì„¸ìš”! ì¡°ê¸ˆë§Œ ë” í•˜ë©´ ì™„ì„±ì´ì—ìš”! ğŸ’ª",
                "í›Œë¥­í•©ë‹ˆë‹¤! ì´ëŸ° ì†ë„ë¼ë©´ ê¸ˆë°© ë§ˆìŠ¤í„°í•˜ì‹¤ ê±°ì˜ˆìš”!",
                "ì¢‹ì€ ì§„ì „ì´ë„¤ìš”! ê³„ì† ì´ë ‡ê²Œë§Œ í•˜ì‹œë©´ ë©ë‹ˆë‹¤!",
                "ë©‹ì ¸ìš”! ì‹¤ë ¥ì´ ê³„ì† ëŠ˜ê³  ìˆë„¤ìš”! ğŸ‘"
            ],
            'empathy': {
                'frustration': [
                    "í”„ë¡œê·¸ë˜ë°í•˜ë‹¤ ë³´ë©´ ê·¸ëŸ° ìˆœê°„ë“¤ì´ ìˆì£ . ì €ë„ ì´í•´í•´ìš”.",
                    "í˜ë“œì‹œì£ ? í•˜ì§€ë§Œ ì´ëŸ° ê³¼ì •ì„ ê±°ì³ì•¼ ì„±ì¥í•˜ëŠ” ê±°ì˜ˆìš”.",
                    "ë‹µë‹µí•˜ì‹¤ ê±°ì˜ˆìš”. ì²œì²œíˆ í•˜ë‚˜ì”© í•´ê²°í•´ë´ìš”."
                ],
                'confusion': [
                    "ë³µì¡í•´ ë³´ì´ì§€ë§Œ, ì°¨ê·¼ì°¨ê·¼ ì„¤ëª…ë“œë¦´ê²Œìš”.",
                    "ì²˜ìŒì—” ë‹¤ ì–´ë ¤ì›Œìš”. ê±±ì •í•˜ì§€ ë§ˆì„¸ìš”!",
                    "ì´í•´ê°€ ì•ˆ ë˜ëŠ” ê²Œ ë‹¹ì—°í•´ìš”. ë” ì‰½ê²Œ ì„¤ëª…í•´ë“œë¦´ê²Œìš”."
                ]
            }
        }
        
        # ëŒ€í™” ìƒíƒœ ê´€ë¦¬
        self.conversation_state = {
            'current_topic': None,
            'pending_tasks': [],
            'user_mood': 'neutral',
            'context_stack': [],
            'last_interaction': datetime.now()
        }
        
        # í•™ìŠµ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
        self.init_knowledge_base()
        
    def init_knowledge_base(self):
        """ì§€ì‹ ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        db_path = self.base_path / "korean_ai_knowledge.db"
        self.conn = sqlite3.connect(str(db_path), check_same_thread=False)
        cursor = self.conn.cursor()
        
        # ëŒ€í™” ê¸°ë¡ í…Œì´ë¸”
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS conversations (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                user_input TEXT,
                ai_response TEXT,
                intent TEXT,
                topic TEXT,
                emotion TEXT,
                formality TEXT
            )
        ''')
        
        # í•™ìŠµëœ íŒ¨í„´ í…Œì´ë¸”
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS learned_patterns (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                pattern TEXT UNIQUE,
                intent TEXT,
                frequency INTEGER DEFAULT 1,
                last_used DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # ì‚¬ìš©ì ì„ í˜¸ë„ í…Œì´ë¸”
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS user_preferences (
                key TEXT PRIMARY KEY,
                value TEXT,
                updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        self.conn.commit()
        
    def analyze_input(self, user_input: str) -> Dict:
        """ê³ ê¸‰ ì…ë ¥ ë¶„ì„"""
        analysis = {
            'raw_input': user_input,
            'normalized': self._normalize_text(user_input),
            'intent': self._detect_intent(user_input),
            'topic': self._detect_topic(user_input),
            'emotion': self._detect_emotion(user_input),
            'formality': self._detect_formality(user_input),
            'entities': self._extract_entities(user_input),
            'keywords': self._extract_keywords(user_input),
            'complexity': self._assess_complexity(user_input),
            'context_needed': self._check_context_dependency(user_input)
        }
        
        # ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
        self.conversation_history.append({
            'timestamp': datetime.now(),
            'type': 'user',
            'content': user_input,
            'analysis': analysis
        })
        
        # ì‚¬ìš©ì í”„ë¡œí•„ ì—…ë°ì´íŠ¸
        self._update_user_profile(analysis)
        
        return analysis
        
    def generate_response(self, analysis: Dict) -> str:
        """ìì—°ìŠ¤ëŸ¬ìš´ ì‘ë‹µ ìƒì„±"""
        # ì»¨í…ìŠ¤íŠ¸ ê³ ë ¤
        context = self._build_context()
        
        # ì˜ë„ë³„ ì‘ë‹µ ì „ëµ
        response_strategy = self._determine_response_strategy(analysis, context)
        
        # ê¸°ë³¸ ì‘ë‹µ ìƒì„±
        base_response = self._generate_base_response(analysis, response_strategy)
        
        # ì‘ë‹µ ê°œì¸í™”
        personalized_response = self._personalize_response(base_response, analysis)
        
        # ì¶”ê°€ ì •ë³´ ì œê³µ
        enhanced_response = self._enhance_response(personalized_response, analysis)
        
        # ëŒ€í™” ê¸°ë¡ ì €ì¥
        self._save_conversation(analysis, enhanced_response)
        
        return enhanced_response
        
    def _normalize_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì •ê·œí™”"""
        # ê¸°ë³¸ ì •ê·œí™”
        normalized = text.strip().lower()
        
        # ì¼ë°˜ì ì¸ ì˜¤íƒ€ ìˆ˜ì •
        typo_corrections = {
            'ì•ˆë‡½': 'ì•ˆë…•',
            'ì—…ã…‚ì„œ': 'ì—†ì–´',
            'ã… ã… ': '',
            'ã…‹ã…‹': '',
            'ã…ã…': ''
        }
        
        for typo, correction in typo_corrections.items():
            normalized = normalized.replace(typo, correction)
            
        return normalized
        
    def _detect_intent(self, text: str) -> str:
        """ì˜ë„ ê°ì§€ (ê°œì„ ëœ ë²„ì „)"""
        text_lower = text.lower()
        intent_scores = defaultdict(int)
        
        # íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ì ìˆ˜ ê³„ì‚°
        for intent, patterns in self.advanced_patterns['intent_patterns'].items():
            for pattern in patterns:
                if pattern in text_lower:
                    intent_scores[intent] += 1
                    
        # ë¬¸ì¥ êµ¬ì¡° ë¶„ì„
        if text.endswith('?') or text.endswith('ìš”?') or text.endswith('ê¹Œ?'):
            intent_scores['question'] += 2
            
        if any(ending in text for ending in ['í•´ì¤˜', 'í•´ì£¼ì„¸ìš”', 'ë¶€íƒ', 'í•´ë´', 'í•´ë³´ì„¸ìš”']):
            intent_scores['request'] += 2
            
        # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ì˜ë„ ë°˜í™˜
        if intent_scores:
            return max(intent_scores.items(), key=lambda x: x[1])[0]
        
        return 'statement'
        
    def _detect_topic(self, text: str) -> str:
        """ì£¼ì œ ê°ì§€ (ê°œì„ ëœ ë²„ì „)"""
        text_lower = text.lower()
        topic_scores = defaultdict(int)
        
        # ì£¼ì œë³„ í‚¤ì›Œë“œ ë§¤ì¹­
        for topic, keywords in self.advanced_patterns['topic_patterns'].items():
            for keyword in keywords:
                if keyword.lower() in text_lower:
                    topic_scores[topic] += 1
                    
        # ì „ë¬¸ ìš©ì–´ ì²´í¬
        for category, terms in self.advanced_patterns['technical_terms'].items():
            for term in terms:
                if term in text:
                    if 'unity' in category:
                        topic_scores['unity'] += 2
                    else:
                        topic_scores['coding'] += 1
                        
        if topic_scores:
            return max(topic_scores.items(), key=lambda x: x[1])[0]
            
        return 'general'
        
    def _detect_emotion(self, text: str) -> str:
        """ê°ì • ê°ì§€ (ê°œì„ ëœ ë²„ì „)"""
        emotion_scores = defaultdict(int)
        
        # ê°ì • í‚¤ì›Œë“œ ë§¤ì¹­
        for emotion, keywords in self.advanced_patterns['emotion_patterns'].items():
            for keyword in keywords:
                if keyword in text:
                    emotion_scores[emotion] += 1
                    
        # ì´ëª¨í‹°ì½˜ ë¶„ì„
        emoji_emotions = {
            'ğŸ˜ŠğŸ˜€ğŸ˜„': 'happy',
            'ğŸ˜¢ğŸ˜­ğŸ˜”': 'sad',
            'ğŸ˜¡ğŸ˜ ğŸ’¢': 'angry',
            'ğŸ˜•ğŸ˜µğŸ¤”': 'confused',
            'ğŸ‰ğŸŠâœ¨': 'excited',
            'ğŸ˜¤ğŸ˜©ğŸ˜«': 'frustrated'
        }
        
        for emojis, emotion in emoji_emotions.items():
            if any(emoji in text for emoji in emojis):
                emotion_scores[emotion] += 2
                
        # ëŠë‚Œí‘œì™€ ë¬¼ìŒí‘œ ê°œìˆ˜ë¡œ ê°ì • ê°•ë„ íŒŒì•…
        exclamation_count = text.count('!')
        question_count = text.count('?')
        
        if exclamation_count > 2:
            emotion_scores['excited'] += 1
        if question_count > 2:
            emotion_scores['confused'] += 1
            
        if emotion_scores:
            return max(emotion_scores.items(), key=lambda x: x[1])[0]
            
        return 'neutral'
        
    def _detect_formality(self, text: str) -> str:
        """ê²©ì‹ ìˆ˜ì¤€ ê°ì§€ (ê°œì„ ëœ ë²„ì „)"""
        # ì¡´ëŒ“ë§ íŒ¨í„´
        formal_patterns = ['ìŠµë‹ˆë‹¤', 'ë‹ˆê¹Œ', 'ì„¸ìš”', 'ì‹­ì‹œì˜¤', 'ë“œë¦½ë‹ˆë‹¤', 'ì…ë‹ˆë‹¤']
        polite_patterns = ['ìš”', 'ì˜ˆìš”', 'ì´ì—ìš”', 'ë„¤ìš”', 'êµ°ìš”', 'ì£ ']
        casual_patterns = ['ì•¼', 'ì–´', 'ì§€', 'ì•„', 'ë‹ˆ', 'ëƒ', 'ë˜']
        
        formal_count = sum(1 for pattern in formal_patterns if pattern in text)
        polite_count = sum(1 for pattern in polite_patterns if pattern in text)
        casual_count = sum(1 for pattern in casual_patterns if text.endswith(pattern))
        
        # í˜¸ì¹­ ì²´í¬
        if any(honorific in text for honorific in ['ë‹˜', 'ì„ ìƒë‹˜', 'êµìˆ˜ë‹˜']):
            formal_count += 2
            
        # ê°€ì¤‘ì¹˜ ê³„ì‚°
        if formal_count > 0:
            return 'formal'
        elif polite_count > casual_count:
            return 'polite'
        elif casual_count > 0:
            return 'casual'
        else:
            return self.user_profile.get('formality_preference', 'polite')
            
    def _extract_entities(self, text: str) -> Dict[str, List[str]]:
        """ê°œì²´ëª… ì¶”ì¶œ"""
        entities = {
            'files': [],
            'classes': [],
            'methods': [],
            'unity_objects': [],
            'paths': []
        }
        
        # íŒŒì¼ëª… íŒ¨í„´
        file_pattern = r'[\w\-]+\.(cs|unity|prefab|mat|png|jpg|txt|json|xml)'
        entities['files'] = re.findall(file_pattern, text, re.IGNORECASE)
        
        # í´ë˜ìŠ¤ëª… íŒ¨í„´ (PascalCase)
        class_pattern = r'\b[A-Z][a-zA-Z0-9]+(?:[A-Z][a-zA-Z0-9]+)*\b'
        potential_classes = re.findall(class_pattern, text)
        entities['classes'] = [c for c in potential_classes if len(c) > 3]
        
        # Unity ì˜¤ë¸Œì íŠ¸
        unity_objects = ['GameObject', 'Transform', 'Rigidbody', 'Collider', 
                        'Camera', 'Light', 'Canvas', 'Button', 'Text']
        entities['unity_objects'] = [obj for obj in unity_objects if obj in text]
        
        # ê²½ë¡œ íŒ¨í„´
        path_pattern = r'(?:[A-Za-z]:\\|\\\\|/)?(?:[^<>:"|?*\n]+[/\\])+[^<>:"|?*\n]*'
        entities['paths'] = re.findall(path_pattern, text)
        
        return entities
        
    def _extract_keywords(self, text: str) -> List[str]:
        """í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        # ë¶ˆìš©ì–´ ì œê±°
        stopwords = ['ì€', 'ëŠ”', 'ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì—', 'ì—ì„œ', 'ìœ¼ë¡œ', 'ì™€', 'ê³¼', 'ì˜', 'ë„']
        
        # ë‹¨ì–´ ë¶„ë¦¬ (ê°„ë‹¨í•œ ë°©ì‹)
        words = re.findall(r'[ê°€-í£]+|[A-Za-z]+|\d+', text)
        
        # í‚¤ì›Œë“œ í•„í„°ë§
        keywords = []
        for word in words:
            if len(word) > 1 and word not in stopwords:
                # ê¸°ìˆ  ìš©ì–´ ìš°ì„ ìˆœìœ„
                is_technical = False
                for terms in self.advanced_patterns['technical_terms'].values():
                    if word in terms:
                        is_technical = True
                        break
                        
                if is_technical or len(word) > 2:
                    keywords.append(word)
                    
        return list(set(keywords))[:10]  # ìƒìœ„ 10ê°œ
        
    def _assess_complexity(self, text: str) -> str:
        """ì§ˆë¬¸/ìš”ì²­ì˜ ë³µì¡ë„ í‰ê°€"""
        # ë³µì¡ë„ ì§€í‘œ
        word_count = len(text.split())
        technical_term_count = 0
        
        for terms in self.advanced_patterns['technical_terms'].values():
            technical_term_count += sum(1 for term in terms if term in text)
            
        # ë³µì¡ë„ íŒë‹¨
        if word_count > 20 or technical_term_count > 3:
            return 'complex'
        elif word_count > 10 or technical_term_count > 1:
            return 'moderate'
        else:
            return 'simple'
            
    def _check_context_dependency(self, text: str) -> bool:
        """ë¬¸ë§¥ ì˜ì¡´ì„± ì²´í¬"""
        context_indicators = ['ê·¸ê±°', 'ê·¸ê²ƒ', 'ì´ê±°', 'ì´ê²ƒ', 'ì €ê±°', 'ì €ê²ƒ', 
                             'ê±°ê¸°', 'ì—¬ê¸°', 'ê·¸ëŸ°', 'ì´ëŸ°', 'ì €ëŸ°', 'ìœ„ì—', 'ì•„ë˜']
        
        return any(indicator in text for indicator in context_indicators)
        
    def _build_context(self) -> Dict:
        """ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ êµ¬ì¶•"""
        context = {
            'recent_topics': [],
            'recent_intents': [],
            'user_mood_trend': [],
            'pending_tasks': self.conversation_state['pending_tasks'],
            'time_since_last': (datetime.now() - self.conversation_state['last_interaction']).seconds
        }
        
        # ìµœê·¼ 5ê°œ ëŒ€í™” ë¶„ì„
        for conv in self.conversation_history[-5:]:
            if conv['type'] == 'user':
                analysis = conv.get('analysis', {})
                context['recent_topics'].append(analysis.get('topic', 'general'))
                context['recent_intents'].append(analysis.get('intent', 'statement'))
                context['user_mood_trend'].append(analysis.get('emotion', 'neutral'))
                
        return context
        
    def _determine_response_strategy(self, analysis: Dict, context: Dict) -> str:
        """ì‘ë‹µ ì „ëµ ê²°ì •"""
        intent = analysis['intent']
        emotion = analysis['emotion']
        complexity = analysis['complexity']
        
        # ê°ì • ìš°ì„  ëŒ€ì‘
        if emotion in ['frustrated', 'angry', 'sad']:
            return 'empathetic'
        elif emotion in ['happy', 'excited']:
            return 'enthusiastic'
            
        # ì˜ë„ë³„ ì „ëµ
        if intent == 'question':
            if complexity == 'complex':
                return 'detailed_explanation'
            else:
                return 'concise_answer'
        elif intent == 'request':
            return 'action_oriented'
        elif intent == 'greeting':
            return 'friendly_greeting'
        elif intent == 'appreciation':
            return 'humble_acknowledgment'
            
        return 'conversational'
        
    def _generate_base_response(self, analysis: Dict, strategy: str) -> str:
        """ê¸°ë³¸ ì‘ë‹µ ìƒì„±"""
        intent = analysis['intent']
        topic = analysis['topic']
        
        # ì „ëµë³„ ì‘ë‹µ ìƒì„±
        if strategy == 'empathetic':
            responses = self.response_templates['empathy'].get(analysis['emotion'], 
                       self.response_templates['empathy']['frustration'])
            base = random.choice(responses)
            
        elif strategy == 'detailed_explanation':
            base = "ìì„¸íˆ ì„¤ëª…ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
            
        elif strategy == 'action_oriented':
            base = "ë°”ë¡œ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤!"
            
        elif strategy == 'friendly_greeting':
            formality = analysis['formality']
            greetings = self.response_templates['greeting'].get(formality, 
                        self.response_templates['greeting']['polite'])
            base = random.choice(greetings)
            
        else:
            # ì¼ë°˜ì ì¸ ì‘ë‹µ
            base = random.choice(self.response_templates['understanding'])
            
        return base
        
    def _personalize_response(self, response: str, analysis: Dict) -> str:
        """ì‘ë‹µ ê°œì¸í™”"""
        # ê²©ì‹ ìˆ˜ì¤€ ë§ì¶”ê¸°
        formality = analysis['formality']
        
        if formality == 'casual':
            response = response.replace('ìŠµë‹ˆë‹¤', 'ì–´')
            response = response.replace('ì„¸ìš”', 'ë´')
            response = response.replace('ì´ì—ìš”', 'ì•¼')
        elif formality == 'formal':
            response = response.replace('í•´ìš”', 'í•©ë‹ˆë‹¤')
            response = response.replace('ì´ì—ìš”', 'ì…ë‹ˆë‹¤')
            
        # ì‚¬ìš©ì ì„ í˜¸ë„ ë°˜ì˜
        if self.user_profile['expertise_level'] == 'beginner':
            response += "\në” ì‰½ê²Œ ì„¤ëª…ì´ í•„ìš”í•˜ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”!"
        elif self.user_profile['expertise_level'] == 'expert':
            response = response.replace('ê¸°ë³¸', 'ê³ ê¸‰')
            
        return response
        
    def _enhance_response(self, response: str, analysis: Dict) -> str:
        """ì‘ë‹µ í–¥ìƒ"""
        topic = analysis['topic']
        entities = analysis['entities']
        
        # ì£¼ì œë³„ ì¶”ê°€ ì •ë³´
        if topic == 'unity' and entities['unity_objects']:
            response += f"\nğŸ’¡ {', '.join(entities['unity_objects'])}ì— ëŒ€í•´ ë” ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”?"
            
        elif topic == 'error':
            response += "\nğŸ”§ ì—ëŸ¬ í•´ê²°ì„ ìœ„í•œ ì²´í¬ë¦¬ìŠ¤íŠ¸:\n"
            response += "1. ì—ëŸ¬ ë©”ì‹œì§€ ì „ì²´ë¥¼ í™•ì¸í•˜ì…¨ë‚˜ìš”?\n"
            response += "2. ê´€ë ¨ ì½”ë“œ ë¶€ë¶„ì„ ì‚´í´ë³´ì…¨ë‚˜ìš”?\n"
            response += "3. Unity ì½˜ì†”ì— ë‹¤ë¥¸ ê²½ê³ ëŠ” ì—†ë‚˜ìš”?"
            
        # íŒŒì¼ì´ ì–¸ê¸‰ëœ ê²½ìš°
        if entities['files']:
            response += f"\nğŸ“ ì–¸ê¸‰í•˜ì‹  íŒŒì¼: {', '.join(entities['files'])}"
            
        return response
        
    def _update_user_profile(self, analysis: Dict):
        """ì‚¬ìš©ì í”„ë¡œí•„ ì—…ë°ì´íŠ¸"""
        # ìƒí˜¸ì‘ìš© íšŸìˆ˜ ì¦ê°€
        self.user_profile['interaction_count'] += 1
        
        # ì„ í˜¸ ê²©ì‹ ì—…ë°ì´íŠ¸
        if self.user_profile['interaction_count'] > 5:
            self.user_profile['formality_preference'] = analysis['formality']
            
        # ì„ í˜¸ ì£¼ì œ ì¶”ê°€
        topic = analysis['topic']
        if topic != 'general' and topic not in self.user_profile['preferred_topics']:
            self.user_profile['preferred_topics'].append(topic)
            
        # ì „ë¬¸ì„± ìˆ˜ì¤€ ì¶”ì •
        if analysis['complexity'] == 'complex' and len(analysis['entities']['classes']) > 2:
            self.user_profile['expertise_level'] = 'expert'
        elif analysis['complexity'] == 'simple' and analysis['emotion'] == 'confused':
            self.user_profile['expertise_level'] = 'beginner'
            
    def _save_conversation(self, analysis: Dict, response: str):
        """ëŒ€í™” ì €ì¥"""
        cursor = self.conn.cursor()
        cursor.execute('''
            INSERT INTO conversations (user_input, ai_response, intent, topic, emotion, formality)
            VALUES (?, ?, ?, ?, ?, ?)
        ''', (
            analysis['raw_input'],
            response,
            analysis['intent'],
            analysis['topic'],
            analysis['emotion'],
            analysis['formality']
        ))
        self.conn.commit()
        
        # ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
        self.conversation_history.append({
            'timestamp': datetime.now(),
            'type': 'ai',
            'content': response
        })
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        self.conversation_state['last_interaction'] = datetime.now()
        self.conversation_state['current_topic'] = analysis['topic']
        
    def get_conversation_summary(self) -> str:
        """ëŒ€í™” ìš”ì•½"""
        if not self.conversation_history:
            return "ì•„ì§ ëŒ€í™” ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤."
            
        summary = f"ğŸ—£ï¸ ëŒ€í™” ìš”ì•½ (ì´ {len(self.conversation_history)}ê°œ ë©”ì‹œì§€)\n"
        summary += f"ì£¼ìš” ì£¼ì œ: {', '.join(set(self.user_profile['preferred_topics']))}\n"
        summary += f"ì‚¬ìš©ì ì „ë¬¸ì„±: {self.user_profile['expertise_level']}\n"
        summary += f"ì„ í˜¸ ê²©ì‹: {self.user_profile['formality_preference']}\n"
        
        return summary
        
    def learn_from_feedback(self, user_feedback: str, was_helpful: bool):
        """ì‚¬ìš©ì í”¼ë“œë°±ìœ¼ë¡œë¶€í„° í•™ìŠµ"""
        # í”¼ë“œë°± ë¶„ì„
        if was_helpful:
            # ì„±ê³µì ì¸ íŒ¨í„´ ê°•í™”
            if self.conversation_history:
                last_user = None
                last_ai = None
                
                for conv in reversed(self.conversation_history):
                    if conv['type'] == 'ai' and last_ai is None:
                        last_ai = conv
                    elif conv['type'] == 'user' and last_user is None:
                        last_user = conv
                        
                    if last_user and last_ai:
                        break
                        
                if last_user:
                    # íŒ¨í„´ í•™ìŠµ
                    cursor = self.conn.cursor()
                    pattern = last_user.get('analysis', {}).get('normalized', '')
                    intent = last_user.get('analysis', {}).get('intent', '')
                    
                    cursor.execute('''
                        INSERT INTO learned_patterns (pattern, intent, frequency)
                        VALUES (?, ?, 1)
                        ON CONFLICT(pattern) DO UPDATE SET
                        frequency = frequency + 1,
                        last_used = CURRENT_TIMESTAMP
                    ''', (pattern, intent))
                    self.conn.commit()
                    
        logger.info(f"í”¼ë“œë°± í•™ìŠµ ì™„ë£Œ: helpful={was_helpful}")


# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_korean_ai():
    """í•œêµ­ì–´ AI í…ŒìŠ¤íŠ¸"""
    ai = AdvancedKoreanAI()
    
    test_inputs = [
        "ì•ˆë…•í•˜ì„¸ìš”! ìœ ë‹ˆí‹° ê°œë°œ ë„ì™€ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”?",
        "PlayerController ìŠ¤í¬ë¦½íŠ¸ì—ì„œ NullReferenceException ì—ëŸ¬ê°€ ë‚˜ìš” ã… ã… ",
        "GameObjectë¥¼ ë™ì ìœ¼ë¡œ ìƒì„±í•˜ëŠ” ë°©ë²• ì¢€ ì•Œë ¤ì¤˜",
        "ì™€ ì§„ì§œ ê°ì‚¬í•©ë‹ˆë‹¤! ë•ë¶„ì— í•´ê²°í–ˆì–´ìš”!!",
        "ê·¼ë° ì´ê±° ì„±ëŠ¥ì€ ê´œì°®ì„ê¹Œìš”?",
        "ì•„ ê·¸ë¦¬ê³  ì½”ë£¨í‹´ì´ë‘ async/await ì¤‘ì— ë­ê°€ ë” ì¢‹ì•„?"
    ]
    
    print("ğŸ¤– ChatGPT ìˆ˜ì¤€ í•œêµ­ì–´ AI í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    for user_input in test_inputs:
        print(f"\nğŸ‘¤ ì‚¬ìš©ì: {user_input}")
        
        # ì…ë ¥ ë¶„ì„
        analysis = ai.analyze_input(user_input)
        print(f"ğŸ“Š ë¶„ì„: {analysis['intent']} / {analysis['topic']} / {analysis['emotion']} / {analysis['formality']}")
        
        # ì‘ë‹µ ìƒì„±
        response = ai.generate_response(analysis)
        print(f"ğŸ¤– AI: {response}")
        
        time.sleep(1)  # ëŒ€í™” íë¦„ì„ ìœ„í•œ ì§§ì€ ëŒ€ê¸°
        
    # ëŒ€í™” ìš”ì•½
    print("\n" + "=" * 60)
    print(ai.get_conversation_summary())


if __name__ == "__main__":
    import time
    test_korean_ai()