#!/usr/bin/env python3
"""
ê³ ê¸‰ 24ì‹œê°„ ìë™ ì½”ë“œ ìˆ˜ì • ì‹œìŠ¤í…œ
ì‹¬ì¸µì ì¸ C# ì½”ë“œ ë¶„ì„ ë° ê°œì„ 
"""

import os
import sys
import json
import time
import asyncio
import logging
import threading
import subprocess
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
import multiprocessing
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import sqlite3
import hashlib
import queue
import signal
import psutil
import aiofiles
import aiohttp
from dataclasses import dataclass, asdict
from enum import Enum

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - [%(levelname)s] %(name)s - %(message)s',
    handlers=[
        logging.FileHandler('advanced_autoci_system.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)


class TaskPriority(Enum):
    """ì‘ì—… ìš°ì„ ìˆœìœ„"""
    CRITICAL = 1
    HIGH = 2
    MEDIUM = 3
    LOW = 4


@dataclass
class CodeTask:
    """ì½”ë“œ ì‘ì—… ì •ì˜"""
    id: str
    file_path: str
    task_type: str  # 'improve', 'fix', 'refactor', 'optimize'
    priority: TaskPriority
    description: str
    created_at: datetime
    completed_at: Optional[datetime] = None
    result: Optional[Dict] = None
    error: Optional[str] = None


class AdvancedAutoCI:
    """ê³ ê¸‰ 24ì‹œê°„ ìë™ ì½”ë“œ ìˆ˜ì • ì‹œìŠ¤í…œ"""
    
    def __init__(self, target_path: str = None):
        self.base_path = Path(__file__).parent
        self.target_path = Path(target_path) if target_path else Path.cwd()
        
        # ì„¤ì • íŒŒì¼
        self.config_path = self.base_path / "advanced_autoci_config.json"
        self.state_path = self.base_path / "advanced_autoci_state.json"
        
        # ë””ë ‰í† ë¦¬ êµ¬ì¡°
        self.dirs = {
            'reports': self.base_path / 'autoci_reports',
            'cache': self.base_path / 'autoci_cache',
            'models': self.base_path / 'models',
            'data': self.base_path / 'expert_learning_data',
            'backups': self.base_path / 'code_backups',
            'analysis': self.base_path / 'code_analysis'
        }
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        for dir_path in self.dirs.values():
            dir_path.mkdir(exist_ok=True)
            
        # ì„¤ì • ë¡œë“œ
        self.config = self.load_config()
        
        # ì‹œìŠ¤í…œ ìƒíƒœ
        self.is_running = False
        self.start_time = None
        self.task_queue = queue.PriorityQueue()
        self.completed_tasks = []
        self.active_tasks = {}
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        self.metrics = {
            'files_analyzed': 0,
            'improvements_made': 0,
            'errors_fixed': 0,
            'performance_gains': [],
            'code_quality_scores': []
        }
        
        # í”„ë¡œì„¸ìŠ¤ í’€
        self.executor = ProcessPoolExecutor(max_workers=self.config['max_workers'])
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
        self.init_database()
        
    def load_config(self) -> Dict:
        """ì„¤ì • ë¡œë“œ"""
        if self.config_path.exists():
            with open(self.config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            default_config = {
                'target_extensions': ['.cs', '.csx'],
                'ignore_patterns': ['bin/', 'obj/', 'packages/', '.git/'],
                'max_workers': multiprocessing.cpu_count(),
                'scan_interval': 300,  # 5ë¶„
                'batch_size': 10,
                'max_file_size_mb': 10,
                'enable_backup': True,
                'enable_real_time_monitoring': True,
                'improvement_threshold': 0.7,
                'auto_commit': False,
                'commit_message_template': 'AutoCI: {task_type} - {description}',
                'notification_webhook': None,
                'advanced_features': {
                    'semantic_analysis': True,
                    'performance_profiling': True,
                    'security_scanning': True,
                    'dependency_analysis': True,
                    'test_generation': True
                }
            }
            self.save_config(default_config)
            return default_config
            
    def save_config(self, config: Dict):
        """ì„¤ì • ì €ì¥"""
        with open(self.config_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
            
    def init_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        db_path = self.dirs['cache'] / 'autoci.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # ì‘ì—… í…Œì´ë¸”
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS tasks (
            id TEXT PRIMARY KEY,
            file_path TEXT NOT NULL,
            task_type TEXT NOT NULL,
            priority INTEGER NOT NULL,
            description TEXT,
            created_at TIMESTAMP,
            completed_at TIMESTAMP,
            result TEXT,
            error TEXT
        )
        ''')
        
        # íŒŒì¼ ë¶„ì„ í…Œì´ë¸”
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS file_analysis (
            file_path TEXT PRIMARY KEY,
            last_analyzed TIMESTAMP,
            file_hash TEXT,
            complexity_score REAL,
            quality_score REAL,
            issues_found INTEGER,
            improvements_applied INTEGER,
            analysis_data TEXT
        )
        ''')
        
        # ê°œì„  ê¸°ë¡ í…Œì´ë¸”
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS improvements (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            file_path TEXT NOT NULL,
            improvement_type TEXT,
            before_code TEXT,
            after_code TEXT,
            quality_gain REAL,
            performance_gain REAL,
            applied_at TIMESTAMP,
            rollback_available BOOLEAN DEFAULT 1
        )
        ''')
        
        # í•™ìŠµ ì¸ì‚¬ì´íŠ¸ í…Œì´ë¸”
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS learning_insights (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            pattern_type TEXT,
            pattern_description TEXT,
            occurrences INTEGER,
            success_rate REAL,
            learned_at TIMESTAMP
        )
        ''')
        
        conn.commit()
        conn.close()
        
    async def start_24h_system(self):
        """24ì‹œê°„ ìë™ ì‹œìŠ¤í…œ ì‹œì‘"""
        logger.info(f"ğŸš€ ê³ ê¸‰ 24ì‹œê°„ ìë™ ì½”ë“œ ìˆ˜ì • ì‹œìŠ¤í…œ ì‹œì‘")
        logger.info(f"ğŸ“ ëŒ€ìƒ ê²½ë¡œ: {self.target_path}")
        
        self.is_running = True
        self.start_time = datetime.now()
        
        # ì‹œìŠ¤í…œ ìƒíƒœ ì €ì¥
        self.save_state({
            'status': 'running',
            'start_time': self.start_time.isoformat(),
            'target_path': str(self.target_path),
            'pid': os.getpid()
        })
        
        # ë¹„ë™ê¸° ì‘ì—… ì‹œì‘
        tasks = [
            self.file_scanner_loop(),
            self.task_processor_loop(),
            self.monitoring_loop(),
            self.report_generator_loop(),
            self.learning_loop()
        ]
        
        # ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ í™œì„±í™”
        if self.config['enable_real_time_monitoring']:
            tasks.append(self.real_time_monitor_loop())
            
        try:
            await asyncio.gather(*tasks)
        except KeyboardInterrupt:
            logger.info("ğŸ›‘ ì‹œìŠ¤í…œ ì¢…ë£Œ ì‹ í˜¸ ë°›ìŒ")
            await self.shutdown()
            
    async def file_scanner_loop(self):
        """íŒŒì¼ ìŠ¤ìº” ë£¨í”„"""
        while self.is_running:
            try:
                logger.info("ğŸ” íŒŒì¼ ìŠ¤ìº” ì‹œì‘...")
                
                # ëŒ€ìƒ íŒŒì¼ ì°¾ê¸°
                cs_files = self.find_cs_files()
                
                for file_path in cs_files:
                    # íŒŒì¼ ë¶„ì„ í•„ìš” ì—¬ë¶€ í™•ì¸
                    if await self.needs_analysis(file_path):
                        # ì‘ì—… ìƒì„±
                        task = await self.create_task(file_path)
                        if task:
                            self.task_queue.put((task.priority.value, task))
                            
                logger.info(f"ğŸ“Š ìŠ¤ìº” ì™„ë£Œ: {len(cs_files)}ê°œ íŒŒì¼, {self.task_queue.qsize()}ê°œ ì‘ì—… ëŒ€ê¸°")
                
                # ë‹¤ìŒ ìŠ¤ìº”ê¹Œì§€ ëŒ€ê¸°
                await asyncio.sleep(self.config['scan_interval'])
                
            except Exception as e:
                logger.error(f"íŒŒì¼ ìŠ¤ìº” ì˜¤ë¥˜: {e}")
                await asyncio.sleep(60)
                
    def find_cs_files(self) -> List[Path]:
        """C# íŒŒì¼ ì°¾ê¸°"""
        cs_files = []
        
        for ext in self.config['target_extensions']:
            for file_path in self.target_path.rglob(f'*{ext}'):
                # ë¬´ì‹œ íŒ¨í„´ í™•ì¸
                if any(pattern in str(file_path) for pattern in self.config['ignore_patterns']):
                    continue
                    
                # íŒŒì¼ í¬ê¸° í™•ì¸
                if file_path.stat().st_size > self.config['max_file_size_mb'] * 1024 * 1024:
                    continue
                    
                cs_files.append(file_path)
                
        return cs_files
        
    async def needs_analysis(self, file_path: Path) -> bool:
        """íŒŒì¼ ë¶„ì„ í•„ìš” ì—¬ë¶€ í™•ì¸"""
        # íŒŒì¼ í•´ì‹œ ê³„ì‚°
        file_hash = await self.calculate_file_hash(file_path)
        
        # ë°ì´í„°ë² ì´ìŠ¤ í™•ì¸
        db_path = self.dirs['cache'] / 'autoci.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
        SELECT file_hash, last_analyzed FROM file_analysis
        WHERE file_path = ?
        ''', (str(file_path),))
        
        result = cursor.fetchone()
        conn.close()
        
        if not result:
            return True
            
        stored_hash, last_analyzed = result
        
        # íŒŒì¼ì´ ë³€ê²½ë˜ì—ˆëŠ”ì§€ í™•ì¸
        if stored_hash != file_hash:
            return True
            
        # ë§ˆì§€ë§‰ ë¶„ì„ ì‹œê°„ í™•ì¸
        last_analyzed_time = datetime.fromisoformat(last_analyzed)
        if datetime.now() - last_analyzed_time > timedelta(days=7):
            return True
            
        return False
        
    async def calculate_file_hash(self, file_path: Path) -> str:
        """íŒŒì¼ í•´ì‹œ ê³„ì‚°"""
        hasher = hashlib.sha256()
        
        async with aiofiles.open(file_path, 'rb') as f:
            while chunk := await f.read(8192):
                hasher.update(chunk)
                
        return hasher.hexdigest()
        
    async def create_task(self, file_path: Path) -> Optional[CodeTask]:
        """ì‘ì—… ìƒì„±"""
        try:
            # íŒŒì¼ ë¶„ì„
            analysis = await self.analyze_file(file_path)
            
            if not analysis['needs_improvement']:
                return None
                
            # ìš°ì„ ìˆœìœ„ ê²°ì •
            priority = self.determine_priority(analysis)
            
            # ì‘ì—… ìœ í˜• ê²°ì •
            task_type = self.determine_task_type(analysis)
            
            # ì‘ì—… ìƒì„±
            task = CodeTask(
                id=hashlib.md5(f"{file_path}{datetime.now()}".encode()).hexdigest(),
                file_path=str(file_path),
                task_type=task_type,
                priority=priority,
                description=analysis['main_issue'],
                created_at=datetime.now()
            )
            
            # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
            self.save_task_to_db(task)
            
            return task
            
        except Exception as e:
            logger.error(f"ì‘ì—… ìƒì„± ì˜¤ë¥˜ ({file_path}): {e}")
            return None
            
    async def analyze_file(self, file_path: Path) -> Dict:
        """íŒŒì¼ ì‹¬ì¸µ ë¶„ì„"""
        analysis = {
            'needs_improvement': False,
            'complexity_score': 0.0,
            'quality_score': 0.0,
            'issues': [],
            'main_issue': '',
            'suggestions': []
        }
        
        try:
            async with aiofiles.open(file_path, 'r', encoding='utf-8') as f:
                content = await f.read()
                
            # ë³µì¡ë„ ë¶„ì„
            complexity = self.calculate_complexity(content)
            analysis['complexity_score'] = complexity
            
            # í’ˆì§ˆ ë¶„ì„
            quality = await self.calculate_quality_score(content)
            analysis['quality_score'] = quality
            
            # ë¬¸ì œì  ì°¾ê¸°
            issues = await self.find_issues(content)
            analysis['issues'] = issues
            
            # ê°œì„  í•„ìš” ì—¬ë¶€
            if quality < self.config['improvement_threshold'] or len(issues) > 0:
                analysis['needs_improvement'] = True
                analysis['main_issue'] = issues[0]['description'] if issues else 'Low quality score'
                
            # ê°œì„  ì œì•ˆ
            if analysis['needs_improvement']:
                suggestions = await self.generate_suggestions(content, issues)
                analysis['suggestions'] = suggestions
                
        except Exception as e:
            logger.error(f"íŒŒì¼ ë¶„ì„ ì˜¤ë¥˜ ({file_path}): {e}")
            
        return analysis
        
    def calculate_complexity(self, content: str) -> float:
        """ì½”ë“œ ë³µì¡ë„ ê³„ì‚°"""
        lines = content.split('\n')
        
        # ì‚¬ì´í´ë¡œë§¤í‹± ë³µì¡ë„ ê·¼ì‚¬ì¹˜
        complexity_keywords = [
            'if', 'else', 'elif', 'for', 'foreach', 'while', 'do',
            'switch', 'case', 'catch', 'throw', '?', '&&', '||'
        ]
        
        complexity_count = 0
        for line in lines:
            for keyword in complexity_keywords:
                complexity_count += line.count(keyword)
                
        # ì •ê·œí™”
        return min(complexity_count / max(len(lines), 1) * 10, 10.0)
        
    async def calculate_quality_score(self, content: str) -> float:
        """ì½”ë“œ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        score = 10.0
        
        # ëª…ëª… ê·œì¹™ í™•ì¸
        if not self.check_naming_conventions(content):
            score -= 1.0
            
        # ì£¼ì„ ë¹„ìœ¨
        comment_ratio = self.calculate_comment_ratio(content)
        if comment_ratio < 0.1:
            score -= 1.0
        elif comment_ratio > 0.4:
            score -= 0.5  # ê³¼ë„í•œ ì£¼ì„
            
        # ì¤‘ë³µ ì½”ë“œ
        if self.has_duplicate_code(content):
            score -= 2.0
            
        # ë§¤ì§ ë„˜ë²„
        if self.has_magic_numbers(content):
            score -= 1.0
            
        # ë©”ì„œë“œ ê¸¸ì´
        if self.has_long_methods(content):
            score -= 1.5
            
        # ì½”ë”© í‘œì¤€
        if not self.follows_coding_standards(content):
            score -= 1.0
            
        return max(score / 10.0, 0.0)
        
    def check_naming_conventions(self, content: str) -> bool:
        """ëª…ëª… ê·œì¹™ í™•ì¸"""
        import re
        
        # C# ëª…ëª… ê·œì¹™ íŒ¨í„´
        class_pattern = r'class\s+[A-Z][a-zA-Z0-9]*'
        method_pattern = r'(public|private|protected|internal)\s+\w+\s+[A-Z][a-zA-Z0-9]*\s*\('
        variable_pattern = r'(int|string|bool|float|double|var)\s+[a-z][a-zA-Z0-9]*'
        
        # íŒ¨í„´ ë§¤ì¹­
        classes = re.findall(class_pattern, content)
        methods = re.findall(method_pattern, content)
        
        return len(classes) > 0 or len(methods) > 0
        
    def calculate_comment_ratio(self, content: str) -> float:
        """ì£¼ì„ ë¹„ìœ¨ ê³„ì‚°"""
        lines = content.split('\n')
        comment_lines = 0
        
        for line in lines:
            stripped = line.strip()
            if stripped.startswith('//') or stripped.startswith('/*') or stripped.startswith('*'):
                comment_lines += 1
                
        return comment_lines / max(len(lines), 1)
        
    def has_duplicate_code(self, content: str) -> bool:
        """ì¤‘ë³µ ì½”ë“œ í™•ì¸"""
        lines = content.split('\n')
        
        # ì—°ì†ëœ 5ì¤„ ì´ìƒì˜ ì¤‘ë³µ í™•ì¸
        for i in range(len(lines) - 10):
            block = lines[i:i+5]
            for j in range(i+5, len(lines) - 5):
                if lines[j:j+5] == block:
                    return True
                    
        return False
        
    def has_magic_numbers(self, content: str) -> bool:
        """ë§¤ì§ ë„˜ë²„ í™•ì¸"""
        import re
        
        # ìƒìˆ˜ê°€ ì•„ë‹Œ ìˆ«ì ë¦¬í„°ëŸ´ ì°¾ê¸°
        pattern = r'[^a-zA-Z_](\d{2,})[^a-zA-Z0-9_]'
        matches = re.findall(pattern, content)
        
        # 0, 1, -1ì€ ì œì™¸
        magic_numbers = [m for m in matches if m not in ['0', '1', '-1', '10', '100']]
        
        return len(magic_numbers) > 3
        
    def has_long_methods(self, content: str) -> bool:
        """ê¸´ ë©”ì„œë“œ í™•ì¸"""
        import re
        
        # ë©”ì„œë“œ ì‹œì‘ íŒ¨í„´
        method_pattern = r'(public|private|protected|internal)\s+\w+\s+\w+\s*\([^)]*\)\s*{'
        
        lines = content.split('\n')
        in_method = False
        method_lines = 0
        brace_count = 0
        
        for line in lines:
            if re.search(method_pattern, line):
                in_method = True
                method_lines = 0
                brace_count = 1
            elif in_method:
                method_lines += 1
                brace_count += line.count('{') - line.count('}')
                
                if brace_count == 0:
                    if method_lines > 50:  # 50ì¤„ ì´ìƒ
                        return True
                    in_method = False
                    
        return False
        
    def follows_coding_standards(self, content: str) -> bool:
        """ì½”ë”© í‘œì¤€ ì¤€ìˆ˜ í™•ì¸"""
        # ê¸°ë³¸ì ì¸ C# ì½”ë”© í‘œì¤€ í™•ì¸
        issues = []
        
        # using ë¬¸ ì •ë¦¬
        if 'using System;' not in content and 'namespace' in content:
            issues.append('Missing using statements')
            
        # ì¤‘ê´„í˜¸ ìŠ¤íƒ€ì¼
        if '\n{' in content and not ')\n{' in content:
            issues.append('Inconsistent brace style')
            
        return len(issues) == 0
        
    async def find_issues(self, content: str) -> List[Dict]:
        """ì½”ë“œ ë¬¸ì œì  ì°¾ê¸°"""
        issues = []
        
        # ì„±ëŠ¥ ë¬¸ì œ
        perf_issues = self.find_performance_issues(content)
        issues.extend(perf_issues)
        
        # ë³´ì•ˆ ë¬¸ì œ
        security_issues = self.find_security_issues(content)
        issues.extend(security_issues)
        
        # ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°€ëŠ¥ì„±
        memory_issues = self.find_memory_issues(content)
        issues.extend(memory_issues)
        
        # ì˜ˆì™¸ ì²˜ë¦¬ ë¬¸ì œ
        exception_issues = self.find_exception_issues(content)
        issues.extend(exception_issues)
        
        # ì •ë ¬ (ì‹¬ê°ë„ ìˆœ)
        issues.sort(key=lambda x: x['severity'], reverse=True)
        
        return issues
        
    def find_performance_issues(self, content: str) -> List[Dict]:
        """ì„±ëŠ¥ ë¬¸ì œ ì°¾ê¸°"""
        issues = []
        
        # LINQ in loops
        if 'for' in content and '.Where(' in content:
            issues.append({
                'type': 'performance',
                'severity': 7,
                'description': 'LINQ query inside loop detected',
                'suggestion': 'Move LINQ query outside the loop'
            })
            
        # String concatenation in loops
        if 'for' in content and '+=' in content and 'string' in content:
            issues.append({
                'type': 'performance',
                'severity': 8,
                'description': 'String concatenation in loop',
                'suggestion': 'Use StringBuilder instead'
            })
            
        # Repeated list operations
        if '.ToList()' in content and content.count('.ToList()') > 3:
            issues.append({
                'type': 'performance',
                'severity': 6,
                'description': 'Multiple ToList() calls',
                'suggestion': 'Cache list results'
            })
            
        return issues
        
    def find_security_issues(self, content: str) -> List[Dict]:
        """ë³´ì•ˆ ë¬¸ì œ ì°¾ê¸°"""
        issues = []
        
        # SQL Injection ê°€ëŠ¥ì„±
        if 'SqlCommand' in content and '"SELECT' in content:
            issues.append({
                'type': 'security',
                'severity': 10,
                'description': 'Potential SQL injection vulnerability',
                'suggestion': 'Use parameterized queries'
            })
            
        # í•˜ë“œì½”ë”©ëœ ë¹„ë°€ë²ˆí˜¸
        if 'password' in content.lower() and '=' in content and '"' in content:
            issues.append({
                'type': 'security',
                'severity': 10,
                'description': 'Hardcoded password detected',
                'suggestion': 'Use secure configuration'
            })
            
        return issues
        
    def find_memory_issues(self, content: str) -> List[Dict]:
        """ë©”ëª¨ë¦¬ ë¬¸ì œ ì°¾ê¸°"""
        issues = []
        
        # IDisposable ë¯¸ì‚¬ìš©
        if 'new FileStream' in content and 'using' not in content:
            issues.append({
                'type': 'memory',
                'severity': 8,
                'description': 'IDisposable not properly disposed',
                'suggestion': 'Use using statement'
            })
            
        # Large object allocation
        if 'new byte[' in content and ']' in content:
            issues.append({
                'type': 'memory',
                'severity': 6,
                'description': 'Large array allocation',
                'suggestion': 'Consider using ArrayPool'
            })
            
        return issues
        
    def find_exception_issues(self, content: str) -> List[Dict]:
        """ì˜ˆì™¸ ì²˜ë¦¬ ë¬¸ì œ ì°¾ê¸°"""
        issues = []
        
        # Empty catch blocks
        if 'catch' in content and '{ }' in content:
            issues.append({
                'type': 'exception',
                'severity': 7,
                'description': 'Empty catch block',
                'suggestion': 'Log or handle exceptions properly'
            })
            
        # Generic exception catching
        if 'catch (Exception' in content:
            issues.append({
                'type': 'exception',
                'severity': 5,
                'description': 'Catching generic Exception',
                'suggestion': 'Catch specific exceptions'
            })
            
        return issues
        
    async def generate_suggestions(self, content: str, issues: List[Dict]) -> List[Dict]:
        """ê°œì„  ì œì•ˆ ìƒì„±"""
        suggestions = []
        
        for issue in issues:
            suggestion = {
                'issue': issue['description'],
                'solution': issue['suggestion'],
                'code_example': await self.generate_code_example(issue),
                'estimated_improvement': self.estimate_improvement(issue)
            }
            suggestions.append(suggestion)
            
        return suggestions
        
    async def generate_code_example(self, issue: Dict) -> str:
        """ì½”ë“œ ì˜ˆì œ ìƒì„±"""
        examples = {
            'LINQ query inside loop detected': '''
// Before:
for (int i = 0; i < items.Count; i++)
{
    var result = collection.Where(x => x.Id == items[i].Id).FirstOrDefault();
}

// After:
var lookup = collection.ToDictionary(x => x.Id);
for (int i = 0; i < items.Count; i++)
{
    lookup.TryGetValue(items[i].Id, out var result);
}
''',
            'String concatenation in loop': '''
// Before:
string result = "";
for (int i = 0; i < items.Count; i++)
{
    result += items[i].ToString();
}

// After:
var sb = new StringBuilder();
for (int i = 0; i < items.Count; i++)
{
    sb.Append(items[i].ToString());
}
string result = sb.ToString();
''',
            'IDisposable not properly disposed': '''
// Before:
var stream = new FileStream(path, FileMode.Open);
// ... use stream

// After:
using (var stream = new FileStream(path, FileMode.Open))
{
    // ... use stream
}
'''
        }
        
        return examples.get(issue['description'], '')
        
    def estimate_improvement(self, issue: Dict) -> Dict:
        """ê°œì„  íš¨ê³¼ ì¶”ì •"""
        improvements = {
            'performance': 0,
            'memory': 0,
            'maintainability': 0,
            'security': 0
        }
        
        if issue['type'] == 'performance':
            improvements['performance'] = issue['severity'] * 10
        elif issue['type'] == 'memory':
            improvements['memory'] = issue['severity'] * 10
        elif issue['type'] == 'security':
            improvements['security'] = issue['severity'] * 10
            
        improvements['maintainability'] = 5  # ê¸°ë³¸ ìœ ì§€ë³´ìˆ˜ì„± í–¥ìƒ
        
        return improvements
        
    def determine_priority(self, analysis: Dict) -> TaskPriority:
        """ì‘ì—… ìš°ì„ ìˆœìœ„ ê²°ì •"""
        # ë³´ì•ˆ ë¬¸ì œê°€ ìˆìœ¼ë©´ ìµœìš°ì„ 
        security_issues = [i for i in analysis['issues'] if i['type'] == 'security']
        if security_issues:
            return TaskPriority.CRITICAL
            
        # ì„±ëŠ¥ ë¬¸ì œê°€ ì‹¬ê°í•˜ë©´ ë†’ìŒ
        perf_issues = [i for i in analysis['issues'] if i['type'] == 'performance' and i['severity'] >= 8]
        if perf_issues:
            return TaskPriority.HIGH
            
        # í’ˆì§ˆ ì ìˆ˜ê°€ ë§¤ìš° ë‚®ìœ¼ë©´ ì¤‘ê°„
        if analysis['quality_score'] < 0.5:
            return TaskPriority.MEDIUM
            
        return TaskPriority.LOW
        
    def determine_task_type(self, analysis: Dict) -> str:
        """ì‘ì—… ìœ í˜• ê²°ì •"""
        if analysis['issues']:
            issue_types = [i['type'] for i in analysis['issues']]
            
            if 'security' in issue_types:
                return 'fix_security'
            elif 'performance' in issue_types:
                return 'optimize'
            elif 'memory' in issue_types:
                return 'fix_memory'
            else:
                return 'fix'
                
        # í’ˆì§ˆ ê°œì„ 
        if analysis['quality_score'] < 0.7:
            if analysis['complexity_score'] > 7:
                return 'refactor'
            else:
                return 'improve'
                
        return 'improve'
        
    def save_task_to_db(self, task: CodeTask):
        """ì‘ì—…ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        db_path = self.dirs['cache'] / 'autoci.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
        INSERT OR REPLACE INTO tasks 
        (id, file_path, task_type, priority, description, created_at)
        VALUES (?, ?, ?, ?, ?, ?)
        ''', (task.id, task.file_path, task.task_type, task.priority.value,
              task.description, task.created_at))
              
        conn.commit()
        conn.close()
        
    async def task_processor_loop(self):
        """ì‘ì—… ì²˜ë¦¬ ë£¨í”„"""
        while self.is_running:
            try:
                if not self.task_queue.empty():
                    # ì‘ì—… ê°€ì ¸ì˜¤ê¸°
                    _, task = self.task_queue.get()
                    
                    logger.info(f"ğŸ”§ ì‘ì—… ì²˜ë¦¬ ì‹œì‘: {task.file_path} ({task.task_type})")
                    
                    # ë°±ì—… ìƒì„±
                    if self.config['enable_backup']:
                        await self.create_backup(task.file_path)
                        
                    # ì‘ì—… ì²˜ë¦¬
                    result = await self.process_task(task)
                    
                    # ê²°ê³¼ ì €ì¥
                    task.completed_at = datetime.now()
                    task.result = result
                    
                    self.completed_tasks.append(task)
                    self.save_task_completion(task)
                    
                    # ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
                    self.update_metrics(task, result)
                    
                    logger.info(f"âœ… ì‘ì—… ì™„ë£Œ: {task.file_path}")
                    
                else:
                    await asyncio.sleep(5)
                    
            except Exception as e:
                logger.error(f"ì‘ì—… ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                await asyncio.sleep(10)
                
    async def create_backup(self, file_path: str):
        """íŒŒì¼ ë°±ì—… ìƒì„±"""
        try:
            source = Path(file_path)
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            backup_name = f"{source.stem}_{timestamp}{source.suffix}"
            backup_path = self.dirs['backups'] / backup_name
            
            async with aiofiles.open(source, 'r', encoding='utf-8') as src:
                content = await src.read()
                
            async with aiofiles.open(backup_path, 'w', encoding='utf-8') as dst:
                await dst.write(content)
                
            logger.info(f"ğŸ’¾ ë°±ì—… ìƒì„±: {backup_path}")
            
        except Exception as e:
            logger.error(f"ë°±ì—… ìƒì„± ì‹¤íŒ¨: {e}")
            
    async def process_task(self, task: CodeTask) -> Dict:
        """ì‘ì—… ì²˜ë¦¬"""
        result = {
            'success': False,
            'changes': [],
            'improvements': {},
            'error': None
        }
        
        try:
            # íŒŒì¼ ì½ê¸°
            async with aiofiles.open(task.file_path, 'r', encoding='utf-8') as f:
                original_content = await f.read()
                
            # ì‘ì—… ìœ í˜•ë³„ ì²˜ë¦¬
            if task.task_type == 'fix_security':
                improved_content = await self.fix_security_issues(original_content)
            elif task.task_type == 'optimize':
                improved_content = await self.optimize_performance(original_content)
            elif task.task_type == 'fix_memory':
                improved_content = await self.fix_memory_issues(original_content)
            elif task.task_type == 'refactor':
                improved_content = await self.refactor_code(original_content)
            else:
                improved_content = await self.improve_code_quality(original_content)
                
            # ë³€ê²½ì‚¬í•­ í™•ì¸
            if improved_content != original_content:
                # íŒŒì¼ ì €ì¥
                async with aiofiles.open(task.file_path, 'w', encoding='utf-8') as f:
                    await f.write(improved_content)
                    
                # ë³€ê²½ì‚¬í•­ ê¸°ë¡
                changes = self.diff_content(original_content, improved_content)
                result['changes'] = changes
                
                # ê°œì„  íš¨ê³¼ ì¸¡ì •
                improvements = await self.measure_improvements(original_content, improved_content)
                result['improvements'] = improvements
                
                result['success'] = True
                
                # ë°ì´í„°ë² ì´ìŠ¤ì— ê°œì„  ê¸°ë¡
                self.save_improvement_to_db(task.file_path, task.task_type, 
                                          original_content, improved_content, improvements)
            else:
                result['success'] = True
                result['changes'] = ['No changes needed']
                
        except Exception as e:
            logger.error(f"ì‘ì—… ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            result['error'] = str(e)
            
        return result
        
    async def fix_security_issues(self, content: str) -> str:
        """ë³´ì•ˆ ë¬¸ì œ ìˆ˜ì •"""
        improved = content
        
        # SQL Injection ìˆ˜ì •
        if 'SqlCommand' in improved and '"SELECT' in improved:
            improved = self.fix_sql_injection(improved)
            
        # í•˜ë“œì½”ë”©ëœ ë¹„ë°€ë²ˆí˜¸ ìˆ˜ì •
        if 'password' in improved.lower() and '=' in improved:
            improved = self.fix_hardcoded_passwords(improved)
            
        # XSS ë°©ì§€
        if 'Response.Write' in improved:
            improved = self.fix_xss_vulnerabilities(improved)
            
        return improved
        
    def fix_sql_injection(self, content: str) -> str:
        """SQL Injection ìˆ˜ì •"""
        import re
        
        # ì·¨ì•½í•œ íŒ¨í„´ ì°¾ê¸°
        pattern = r'new SqlCommand\("([^"]+)"'
        
        def replace_with_parameters(match):
            query = match.group(1)
            # ê°„ë‹¨í•œ íŒŒë¼ë¯¸í„°í™” (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ë¡œì§ í•„ìš”)
            if 'WHERE' in query and '=' in query:
                # WHERE id = value í˜•íƒœë¥¼ WHERE id = @idë¡œ ë³€ê²½
                parameterized = re.sub(r'(\w+)\s*=\s*([^"\s]+)', r'\1 = @\1', query)
                return f'new SqlCommand("{parameterized}"'
            return match.group(0)
            
        return re.sub(pattern, replace_with_parameters, content)
        
    def fix_hardcoded_passwords(self, content: str) -> str:
        """í•˜ë“œì½”ë”©ëœ ë¹„ë°€ë²ˆí˜¸ ìˆ˜ì •"""
        import re
        
        # íŒ¨ìŠ¤ì›Œë“œ íŒ¨í„´
        pattern = r'(password|pwd|passwd)\s*=\s*"([^"]+)"'
        
        def replace_with_config(match):
            var_name = match.group(1)
            return f'{var_name} = Configuration["{var_name}"]'
            
        return re.sub(pattern, replace_with_config, content, flags=re.IGNORECASE)
        
    def fix_xss_vulnerabilities(self, content: str) -> str:
        """XSS ì·¨ì•½ì  ìˆ˜ì •"""
        import re
        
        # Response.Writeë¥¼ HttpUtility.HtmlEncodeë¡œ ê°ì‹¸ê¸°
        pattern = r'Response\.Write\(([^)]+)\)'
        
        def wrap_with_encode(match):
            param = match.group(1)
            return f'Response.Write(HttpUtility.HtmlEncode({param}))'
            
        return re.sub(pattern, wrap_with_encode, content)
        
    async def optimize_performance(self, content: str) -> str:
        """ì„±ëŠ¥ ìµœì í™”"""
        improved = content
        
        # LINQ ìµœì í™”
        improved = self.optimize_linq_queries(improved)
        
        # ë¬¸ìì—´ ì—°ê²° ìµœì í™”
        improved = self.optimize_string_concatenation(improved)
        
        # ì»¬ë ‰ì…˜ ìµœì í™”
        improved = self.optimize_collections(improved)
        
        # async/await ìµœì í™”
        improved = self.optimize_async_await(improved)
        
        return improved
        
    def optimize_linq_queries(self, content: str) -> str:
        """LINQ ì¿¼ë¦¬ ìµœì í™”"""
        import re
        
        # FirstOrDefault() ëŒ€ì‹  FirstOrDefault(predicate) ì‚¬ìš©
        pattern = r'\.Where\(([^)]+)\)\.FirstOrDefault\(\)'
        replacement = r'.FirstOrDefault(\1)'
        content = re.sub(pattern, replacement, content)
        
        # Count() > 0 ëŒ€ì‹  Any() ì‚¬ìš©
        pattern = r'\.Count\(\)\s*>\s*0'
        replacement = r'.Any()'
        content = re.sub(pattern, replacement, content)
        
        # ToList().Count ëŒ€ì‹  Count() ì‚¬ìš©
        pattern = r'\.ToList\(\)\.Count'
        replacement = r'.Count()'
        content = re.sub(pattern, replacement, content)
        
        return content
        
    def optimize_string_concatenation(self, content: str) -> str:
        """ë¬¸ìì—´ ì—°ê²° ìµœì í™”"""
        import re
        
        # ë£¨í”„ ë‚´ ë¬¸ìì—´ ì—°ê²° ì°¾ê¸°
        lines = content.split('\n')
        improved_lines = []
        in_loop = False
        loop_depth = 0
        string_concat_vars = set()
        
        for i, line in enumerate(lines):
            # ë£¨í”„ ì‹œì‘ ê°ì§€
            if re.search(r'(for|foreach|while)\s*\(', line):
                in_loop = True
                loop_depth += 1
                
            # ë£¨í”„ ë‚´ ë¬¸ìì—´ ì—°ê²° ê°ì§€
            if in_loop and '+=' in line and 'string' in content[:content.find(line)]:
                # ë³€ìˆ˜ëª… ì¶”ì¶œ
                match = re.search(r'(\w+)\s*\+=', line)
                if match:
                    var_name = match.group(1)
                    string_concat_vars.add(var_name)
                    
                    # StringBuilderë¡œ ë³€ê²½
                    if f'StringBuilder {var_name}Builder' not in content:
                        # ë£¨í”„ ì‹œì‘ ì „ì— StringBuilder ì„ ì–¸ ì¶”ê°€
                        for j in range(i-1, -1, -1):
                            if re.search(r'(for|foreach|while)\s*\(', lines[j]):
                                improved_lines.insert(j, f'            var {var_name}Builder = new StringBuilder();')
                                break
                                
                    # += ë¥¼ Appendë¡œ ë³€ê²½
                    line = re.sub(f'{var_name}\\s*\\+=\\s*', f'{var_name}Builder.Append(', line)
                    line = line.rstrip() + ');' if not line.rstrip().endswith(';') else line
                    
            # ë£¨í”„ ì¢…ë£Œ ê°ì§€
            if '{' in line:
                loop_depth += line.count('{')
            if '}' in line:
                loop_depth -= line.count('}')
                if loop_depth == 0:
                    in_loop = False
                    
                    # StringBuilderë¥¼ stringìœ¼ë¡œ ë³€í™˜
                    for var_name in string_concat_vars:
                        improved_lines.append(f'            {var_name} = {var_name}Builder.ToString();')
                    string_concat_vars.clear()
                    
            improved_lines.append(line)
            
        return '\n'.join(improved_lines)
        
    def optimize_collections(self, content: str) -> str:
        """ì»¬ë ‰ì…˜ ìµœì í™”"""
        import re
        
        # List í¬ê¸° ì§€ì •
        pattern = r'new List<([^>]+)>\(\)'
        
        # ì˜ˆìƒ í¬ê¸° ì¶”ì • (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
        def add_capacity(match):
            type_name = match.group(1)
            # ê¸°ë³¸ ìš©ëŸ‰ ì„¤ì •
            return f'new List<{type_name}>(capacity: 16)'
            
        content = re.sub(pattern, add_capacity, content)
        
        # ToArray() ëŒ€ì‹  ToList() ì‚¬ìš© (í•„ìš”í•œ ê²½ìš°)
        # Arrayê°€ í•„ìš”í•˜ì§€ ì•Šì€ ê²½ìš° Listê°€ ë” íš¨ìœ¨ì 
        
        return content
        
    def optimize_async_await(self, content: str) -> str:
        """async/await ìµœì í™”"""
        import re
        
        # ConfigureAwait(false) ì¶”ê°€ (ë¼ì´ë¸ŒëŸ¬ë¦¬ ì½”ë“œì¸ ê²½ìš°)
        pattern = r'await\s+([^;]+)(?<!ConfigureAwait\(false\));'
        
        def add_configure_await(match):
            expr = match.group(1)
            # UI ê´€ë ¨ ì½”ë“œê°€ ì•„ë‹Œ ê²½ìš°ë§Œ
            if not any(ui in expr for ui in ['UI', 'Window', 'Control', 'Form']):
                return f'await {expr}.ConfigureAwait(false);'
            return match.group(0)
            
        content = re.sub(pattern, add_configure_await, content)
        
        return content
        
    async def fix_memory_issues(self, content: str) -> str:
        """ë©”ëª¨ë¦¬ ë¬¸ì œ ìˆ˜ì •"""
        improved = content
        
        # IDisposable íŒ¨í„´ ì ìš©
        improved = self.apply_using_statements(improved)
        
        # ëŒ€ìš©ëŸ‰ ë°°ì—´ì„ ArrayPoolë¡œ ë³€ê²½
        improved = self.use_array_pool(improved)
        
        # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ëˆ„ìˆ˜ ë°©ì§€
        improved = self.fix_event_handler_leaks(improved)
        
        return improved
        
    def apply_using_statements(self, content: str) -> str:
        """using ë¬¸ ì ìš©"""
        import re
        
        # IDisposable íƒ€ì…ë“¤
        disposable_types = [
            'FileStream', 'StreamReader', 'StreamWriter', 'SqlConnection',
            'SqlCommand', 'HttpClient', 'MemoryStream', 'BinaryReader',
            'BinaryWriter', 'Graphics', 'Bitmap'
        ]
        
        for dtype in disposable_types:
            # newë¡œ ìƒì„±í•˜ì§€ë§Œ usingì´ ì—†ëŠ” ê²½ìš°
            pattern = rf'(\s*)var\s+(\w+)\s*=\s*new\s+{dtype}\s*\('
            
            lines = content.split('\n')
            improved_lines = []
            
            for i, line in enumerate(lines):
                match = re.search(pattern, line)
                if match and 'using' not in line:
                    indent = match.group(1)
                    var_name = match.group(2)
                    
                    # using ë¸”ë¡ìœ¼ë¡œ ê°ì‹¸ê¸°
                    improved_lines.append(f'{indent}using ({line.strip()})')
                    improved_lines.append(f'{indent}{{')
                    
                    # í•´ë‹¹ ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ëŠ” ë‹¤ìŒ ì¤„ë“¤ ë“¤ì—¬ì“°ê¸°
                    j = i + 1
                    while j < len(lines) and var_name in lines[j]:
                        improved_lines.append('    ' + lines[j])
                        j += 1
                        
                    improved_lines.append(f'{indent}}}')
                    
                    # ì²˜ë¦¬í•œ ì¤„ë“¤ ê±´ë„ˆë›°ê¸°
                    i = j - 1
                else:
                    improved_lines.append(line)
                    
            content = '\n'.join(improved_lines)
            
        return content
        
    def use_array_pool(self, content: str) -> str:
        """ArrayPool ì‚¬ìš©"""
        import re
        
        # í° ë°°ì—´ í• ë‹¹ íŒ¨í„´
        pattern = r'new\s+byte\[(\d+)\]'
        
        def replace_with_pool(match):
            size = int(match.group(1))
            if size > 4096:  # 4KB ì´ìƒ
                return f'ArrayPool<byte>.Shared.Rent({size})'
            return match.group(0)
            
        content = re.sub(pattern, replace_with_pool, content)
        
        # ArrayPool ì‚¬ìš© ì‹œ ë°˜í™˜ ì½”ë“œë„ ì¶”ê°€ í•„ìš”
        # (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë” ë³µì¡í•œ ë¡œì§ í•„ìš”)
        
        return content
        
    def fix_event_handler_leaks(self, content: str) -> str:
        """ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ëˆ„ìˆ˜ ìˆ˜ì •"""
        import re
        
        # ì´ë²¤íŠ¸ êµ¬ë… íŒ¨í„´
        pattern = r'(\w+)\.(\w+)\s*\+=\s*(\w+);'
        
        # Dispose ë©”ì„œë“œ ì°¾ê¸°
        if 'Dispose()' in content or 'Dispose(bool' in content:
            # ì´ë²¤íŠ¸ êµ¬ë… í•´ì œ ì½”ë“œ ì¶”ê°€
            subscriptions = re.findall(pattern, content)
            
            for obj, event, handler in subscriptions:
                unsubscribe = f'{obj}.{event} -= {handler};'
                
                # Dispose ë©”ì„œë“œì— ì¶”ê°€
                dispose_pattern = r'(public\s+void\s+Dispose\(\)\s*\{[^}]*)'
                
                def add_unsubscribe(match):
                    body = match.group(1)
                    if unsubscribe not in body:
                        return body + f'\n            {unsubscribe}'
                    return body
                    
                content = re.sub(dispose_pattern, add_unsubscribe, content)
                
        return content
        
    async def refactor_code(self, content: str) -> str:
        """ì½”ë“œ ë¦¬íŒ©í† ë§"""
        improved = content
        
        # ë©”ì„œë“œ ì¶”ì¶œ
        improved = self.extract_methods(improved)
        
        # ì¤‘ë³µ ì½”ë“œ ì œê±°
        improved = self.remove_duplicate_code(improved)
        
        # ë³µì¡í•œ ì¡°ê±´ë¬¸ ë‹¨ìˆœí™”
        improved = self.simplify_conditionals(improved)
        
        # ë§¤ì§ ë„˜ë²„ë¥¼ ìƒìˆ˜ë¡œ
        improved = self.replace_magic_numbers(improved)
        
        return improved
        
    def extract_methods(self, content: str) -> str:
        """ê¸´ ë©”ì„œë“œë¥¼ ì‘ì€ ë©”ì„œë“œë¡œ ë¶„í• """
        # ì‹¤ì œ êµ¬í˜„ì€ ë§¤ìš° ë³µì¡í•˜ë¯€ë¡œ ê°„ë‹¨í•œ ì˜ˆì‹œë§Œ
        return content
        
    def remove_duplicate_code(self, content: str) -> str:
        """ì¤‘ë³µ ì½”ë“œ ì œê±°"""
        lines = content.split('\n')
        
        # ì¤‘ë³µ ë¸”ë¡ ì°¾ê¸°
        duplicate_blocks = []
        block_size = 5
        
        for i in range(len(lines) - block_size * 2):
            block1 = lines[i:i+block_size]
            
            for j in range(i + block_size, len(lines) - block_size):
                block2 = lines[j:j+block_size]
                
                if block1 == block2:
                    duplicate_blocks.append((i, j, block_size))
                    
        # ì¤‘ë³µì„ ë©”ì„œë“œë¡œ ì¶”ì¶œ (ê°„ë‹¨í•œ êµ¬í˜„)
        # ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ë¡œì§ í•„ìš”
        
        return content
        
    def simplify_conditionals(self, content: str) -> str:
        """ë³µì¡í•œ ì¡°ê±´ë¬¸ ë‹¨ìˆœí™”"""
        import re
        
        # ì¤‘ì²©ëœ ifë¥¼ early returnìœ¼ë¡œ
        # if (condition) { return true; } else { return false; }
        # => return condition;
        pattern = r'if\s*\(([^)]+)\)\s*\{\s*return\s+true;\s*\}\s*else\s*\{\s*return\s+false;\s*\}'
        content = re.sub(pattern, r'return \1;', content)
        
        # ë¶€ì • ì¡°ê±´ ë‹¨ìˆœí™”
        pattern = r'if\s*\(!([^)]+)\)\s*\{\s*return;\s*\}'
        content = re.sub(pattern, r'if (\1) return;', content)
        
        return content
        
    def replace_magic_numbers(self, content: str) -> str:
        """ë§¤ì§ ë„˜ë²„ë¥¼ ìƒìˆ˜ë¡œ êµì²´"""
        import re
        
        # ìˆ«ì ë¦¬í„°ëŸ´ ì°¾ê¸°
        numbers = re.findall(r'[^a-zA-Z_](\d{2,})[^a-zA-Z0-9_]', content)
        
        # ë¹ˆë„ ê³„ì‚°
        number_freq = {}
        for num in numbers:
            if num not in ['10', '100', '1000']:  # ì¼ë°˜ì ì¸ ìˆ«ì ì œì™¸
                number_freq[num] = number_freq.get(num, 0) + 1
                
        # ìì£¼ ì‚¬ìš©ë˜ëŠ” ìˆ«ìë¥¼ ìƒìˆ˜ë¡œ
        constants_to_add = []
        for num, freq in number_freq.items():
            if freq >= 2:
                const_name = f'DEFAULT_VALUE_{num}'
                constants_to_add.append(f'        private const int {const_name} = {num};')
                content = content.replace(num, const_name)
                
        # í´ë˜ìŠ¤ ì‹œì‘ ë¶€ë¶„ì— ìƒìˆ˜ ì¶”ê°€
        if constants_to_add:
            class_pattern = r'(class\s+\w+\s*\{)'
            replacement = r'\1\n' + '\n'.join(constants_to_add)
            content = re.sub(class_pattern, replacement, content, count=1)
            
        return content
        
    async def improve_code_quality(self, content: str) -> str:
        """ì½”ë“œ í’ˆì§ˆ ê°œì„ """
        improved = content
        
        # ëª…ëª… ê·œì¹™ ê°œì„ 
        improved = self.improve_naming(improved)
        
        # ì£¼ì„ ì¶”ê°€
        improved = self.add_documentation(improved)
        
        # ì—ëŸ¬ ì²˜ë¦¬ ê°œì„ 
        improved = self.improve_error_handling(improved)
        
        # ì½”ë“œ í¬ë§·íŒ…
        improved = self.format_code(improved)
        
        return improved
        
    def improve_naming(self, content: str) -> str:
        """ëª…ëª… ê·œì¹™ ê°œì„ """
        import re
        
        # camelCase ë³€ìˆ˜ëª… ìˆ˜ì •
        # ë‹¨ì¼ ë¬¸ì ë³€ìˆ˜ëª…ì„ ì˜ë¯¸ìˆëŠ” ì´ë¦„ìœ¼ë¡œ
        single_char_vars = re.findall(r'\b([a-z])\s*=\s*', content)
        
        replacements = {
            'i': 'index',
            'j': 'innerIndex',
            'k': 'count',
            'n': 'number',
            's': 'text',
            'e': 'exception',
            'x': 'xCoordinate',
            'y': 'yCoordinate'
        }
        
        for var in set(single_char_vars):
            if var in replacements:
                # ë‹¨ì–´ ê²½ê³„ë¥¼ í™•ì¸í•˜ì—¬ ì •í™•íˆ ë§¤ì¹˜
                pattern = rf'\b{var}\b'
                content = re.sub(pattern, replacements[var], content)
                
        return content
        
    def add_documentation(self, content: str) -> str:
        """XML ë¬¸ì„œí™” ì£¼ì„ ì¶”ê°€"""
        import re
        
        # public ë©”ì„œë“œ ì°¾ê¸°
        method_pattern = r'(\s*)(public\s+\w+\s+(\w+)\s*\([^)]*\)\s*\{)'
        
        lines = content.split('\n')
        improved_lines = []
        
        for i, line in enumerate(lines):
            match = re.search(method_pattern, line)
            if match and i > 0 and '///' not in lines[i-1]:
                indent = match.group(1)
                method_name = match.group(3)
                
                # ê°„ë‹¨í•œ XML ì£¼ì„ ì¶”ê°€
                improved_lines.append(f'{indent}/// <summary>')
                improved_lines.append(f'{indent}/// {method_name} ë©”ì„œë“œ')
                improved_lines.append(f'{indent}/// </summary>')
                
            improved_lines.append(line)
            
        return '\n'.join(improved_lines)
        
    def improve_error_handling(self, content: str) -> str:
        """ì—ëŸ¬ ì²˜ë¦¬ ê°œì„ """
        import re
        
        # try ë¸”ë¡ì´ ì—†ëŠ” ìœ„í—˜í•œ ì‘ì—…
        risky_operations = [
            'File.ReadAllText', 'File.WriteAllText', 'int.Parse',
            'Convert.ToInt32', 'HttpClient', 'SqlConnection'
        ]
        
        for op in risky_operations:
            if op in content and 'try' not in content:
                # í•´ë‹¹ ì‘ì—…ì„ try-catchë¡œ ê°ì‹¸ê¸°
                pattern = rf'(\s*)([^;]*{op}[^;]*;)'
                
                def wrap_with_try(match):
                    indent = match.group(1)
                    statement = match.group(2)
                    
                    return f'''{indent}try
{indent}{{
{indent}    {statement}
{indent}}}
{indent}catch (Exception ex)
{indent}{{
{indent}    // TODO: ì ì ˆí•œ ì—ëŸ¬ ì²˜ë¦¬ ì¶”ê°€
{indent}    throw;
{indent}}}'''
                    
                content = re.sub(pattern, wrap_with_try, content)
                
        return content
        
    def format_code(self, content: str) -> str:
        """ì½”ë“œ í¬ë§·íŒ…"""
        # ê¸°ë³¸ì ì¸ í¬ë§·íŒ…
        lines = content.split('\n')
        formatted_lines = []
        indent_level = 0
        
        for line in lines:
            stripped = line.strip()
            
            # ë“¤ì—¬ì“°ê¸° ë ˆë²¨ ì¡°ì •
            if stripped.endswith('{'):
                formatted_lines.append('    ' * indent_level + stripped)
                indent_level += 1
            elif stripped.startswith('}'):
                indent_level = max(0, indent_level - 1)
                formatted_lines.append('    ' * indent_level + stripped)
            else:
                formatted_lines.append('    ' * indent_level + stripped)
                
        return '\n'.join(formatted_lines)
        
    def diff_content(self, original: str, improved: str) -> List[str]:
        """ë³€ê²½ì‚¬í•­ ë¹„êµ"""
        import difflib
        
        original_lines = original.split('\n')
        improved_lines = improved.split('\n')
        
        diff = difflib.unified_diff(
            original_lines, improved_lines,
            fromfile='original', tofile='improved',
            lineterm=''
        )
        
        return list(diff)
        
    async def measure_improvements(self, original: str, improved: str) -> Dict:
        """ê°œì„  íš¨ê³¼ ì¸¡ì •"""
        improvements = {
            'lines_changed': 0,
            'complexity_reduction': 0,
            'quality_improvement': 0,
            'performance_gain': 0,
            'security_fixes': 0
        }
        
        # ë³€ê²½ëœ ì¤„ ìˆ˜
        diff = self.diff_content(original, improved)
        improvements['lines_changed'] = len([d for d in diff if d.startswith(('+', '-'))])
        
        # ë³µì¡ë„ ê°ì†Œ
        orig_complexity = self.calculate_complexity(original)
        new_complexity = self.calculate_complexity(improved)
        improvements['complexity_reduction'] = max(0, orig_complexity - new_complexity)
        
        # í’ˆì§ˆ í–¥ìƒ
        orig_quality = await self.calculate_quality_score(original)
        new_quality = await self.calculate_quality_score(improved)
        improvements['quality_improvement'] = new_quality - orig_quality
        
        # ì„±ëŠ¥ í–¥ìƒ (ì¶”ì •)
        if 'StringBuilder' in improved and 'StringBuilder' not in original:
            improvements['performance_gain'] += 20
        if '.Any()' in improved and '.Count() > 0' in original:
            improvements['performance_gain'] += 10
        if 'ConfigureAwait(false)' in improved:
            improvements['performance_gain'] += 5
            
        # ë³´ì•ˆ ìˆ˜ì •
        if '@' in improved and 'SqlCommand' in improved:
            improvements['security_fixes'] += 1
        if 'Configuration[' in improved and 'password' in original:
            improvements['security_fixes'] += 1
            
        return improvements
        
    def save_improvement_to_db(self, file_path: str, improvement_type: str,
                              before: str, after: str, improvements: Dict):
        """ê°œì„  ë‚´ì—­ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        db_path = self.dirs['cache'] / 'autoci.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
        INSERT INTO improvements 
        (file_path, improvement_type, before_code, after_code, 
         quality_gain, performance_gain, applied_at)
        VALUES (?, ?, ?, ?, ?, ?, ?)
        ''', (file_path, improvement_type, before, after,
              improvements.get('quality_improvement', 0),
              improvements.get('performance_gain', 0),
              datetime.now()))
              
        conn.commit()
        conn.close()
        
    def save_task_completion(self, task: CodeTask):
        """ì™„ë£Œëœ ì‘ì—… ì €ì¥"""
        db_path = self.dirs['cache'] / 'autoci.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
        UPDATE tasks 
        SET completed_at = ?, result = ?, error = ?
        WHERE id = ?
        ''', (task.completed_at, json.dumps(task.result) if task.result else None,
              task.error, task.id))
              
        conn.commit()
        conn.close()
        
    def update_metrics(self, task: CodeTask, result: Dict):
        """ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸"""
        if result.get('success'):
            self.metrics['improvements_made'] += 1
            
            if task.task_type == 'fix':
                self.metrics['errors_fixed'] += 1
                
            if 'improvements' in result:
                perf_gain = result['improvements'].get('performance_gain', 0)
                if perf_gain > 0:
                    self.metrics['performance_gains'].append(perf_gain)
                    
                quality_score = result['improvements'].get('quality_improvement', 0)
                if quality_score > 0:
                    self.metrics['code_quality_scores'].append(quality_score)
                    
    async def monitoring_loop(self):
        """ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ë£¨í”„"""
        while self.is_running:
            try:
                # ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§
                cpu_percent = psutil.cpu_percent(interval=1)
                memory_info = psutil.virtual_memory()
                disk_usage = psutil.disk_usage(str(self.target_path))
                
                # í”„ë¡œì„¸ìŠ¤ ì •ë³´
                process = psutil.Process()
                process_info = {
                    'cpu_percent': process.cpu_percent(),
                    'memory_mb': process.memory_info().rss / 1024 / 1024,
                    'threads': process.num_threads()
                }
                
                # ì‘ì—… í ìƒíƒœ
                queue_size = self.task_queue.qsize()
                active_tasks = len(self.active_tasks)
                
                # ìƒíƒœ ì—…ë°ì´íŠ¸
                monitoring_data = {
                    'timestamp': datetime.now().isoformat(),
                    'system': {
                        'cpu_percent': cpu_percent,
                        'memory_percent': memory_info.percent,
                        'disk_percent': disk_usage.percent
                    },
                    'process': process_info,
                    'tasks': {
                        'queued': queue_size,
                        'active': active_tasks,
                        'completed': len(self.completed_tasks)
                    },
                    'metrics': self.metrics
                }
                
                # ìƒíƒœ ì €ì¥
                self.save_monitoring_data(monitoring_data)
                
                # ì•Œë¦¼ í™•ì¸
                if cpu_percent > 90:
                    logger.warning(f"âš ï¸ CPU ì‚¬ìš©ë¥  ë†’ìŒ: {cpu_percent}%")
                if memory_info.percent > 90:
                    logger.warning(f"âš ï¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ë†’ìŒ: {memory_info.percent}%")
                    
                await asyncio.sleep(60)  # 1ë¶„ë§ˆë‹¤
                
            except Exception as e:
                logger.error(f"ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}")
                await asyncio.sleep(60)
                
    def save_monitoring_data(self, data: Dict):
        """ëª¨ë‹ˆí„°ë§ ë°ì´í„° ì €ì¥"""
        monitoring_file = self.dirs['cache'] / 'monitoring_data.jsonl'
        
        with open(monitoring_file, 'a', encoding='utf-8') as f:
            f.write(json.dumps(data) + '\n')
            
    async def report_generator_loop(self):
        """ë¦¬í¬íŠ¸ ìƒì„± ë£¨í”„"""
        while self.is_running:
            try:
                # ë§¤ ì‹œê°„ë§ˆë‹¤ ë¦¬í¬íŠ¸ ìƒì„±
                await asyncio.sleep(3600)
                
                # ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±
                report = await self.generate_comprehensive_report()
                
                # ë§ˆí¬ë‹¤ìš´ íŒŒì¼ë¡œ ì €ì¥
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                report_path = self.dirs['reports'] / f'report_{timestamp}.md'
                
                with open(report_path, 'w', encoding='utf-8') as f:
                    f.write(report)
                    
                # ìµœì‹  ë¦¬í¬íŠ¸ ë§í¬ ì—…ë°ì´íŠ¸
                latest_link = self.dirs['reports'] / 'latest_report.md'
                if latest_link.exists():
                    latest_link.unlink()
                latest_link.symlink_to(report_path)
                
                logger.info(f"ğŸ“Š ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {report_path}")
                
            except Exception as e:
                logger.error(f"ë¦¬í¬íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
                await asyncio.sleep(3600)
                
    async def generate_comprehensive_report(self) -> str:
        """ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±"""
        runtime = datetime.now() - self.start_time if self.start_time else timedelta(0)
        
        # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ í†µê³„ ê°€ì ¸ì˜¤ê¸°
        stats = self.get_statistics_from_db()
        
        report = f"""# AutoCI 24ì‹œê°„ ìë™ ì½”ë“œ ìˆ˜ì • ì‹œìŠ¤í…œ ë¦¬í¬íŠ¸

## ğŸ“Š ì‹œìŠ¤í…œ ê°œìš”
- **ì‹œì‘ ì‹œê°„**: {self.start_time.strftime('%Y-%m-%d %H:%M:%S') if self.start_time else 'N/A'}
- **ì‹¤í–‰ ì‹œê°„**: {runtime}
- **ëŒ€ìƒ ê²½ë¡œ**: `{self.target_path}`
- **ìƒíƒœ**: {'ì‹¤í–‰ ì¤‘' if self.is_running else 'ì¤‘ì§€ë¨'}

## ğŸ“ˆ ì„±ê³¼ ì§€í‘œ

### ì „ì²´ í†µê³„
- **ë¶„ì„ëœ íŒŒì¼**: {self.metrics['files_analyzed']}ê°œ
- **ê°œì„ ëœ íŒŒì¼**: {self.metrics['improvements_made']}ê°œ
- **ìˆ˜ì •ëœ ì˜¤ë¥˜**: {self.metrics['errors_fixed']}ê°œ
- **ì™„ë£Œëœ ì‘ì—…**: {len(self.completed_tasks)}ê°œ

### í’ˆì§ˆ ê°œì„ 
- **í‰ê·  í’ˆì§ˆ í–¥ìƒ**: {np.mean(self.metrics['code_quality_scores']) if self.metrics['code_quality_scores'] else 0:.2f}%
- **ìµœëŒ€ í’ˆì§ˆ í–¥ìƒ**: {max(self.metrics['code_quality_scores']) if self.metrics['code_quality_scores'] else 0:.2f}%

### ì„±ëŠ¥ ê°œì„ 
- **í‰ê·  ì„±ëŠ¥ í–¥ìƒ**: {np.mean(self.metrics['performance_gains']) if self.metrics['performance_gains'] else 0:.2f}%
- **ì´ ì„±ëŠ¥ í–¥ìƒ**: {sum(self.metrics['performance_gains'])}%

## ğŸ”§ ì‘ì—… ë¶„ì„

### ì‘ì—… ìœ í˜•ë³„ ë¶„í¬
{self.get_task_distribution(stats)}

### ìš°ì„ ìˆœìœ„ë³„ ë¶„í¬
{self.get_priority_distribution(stats)}

## ğŸ“ ì£¼ìš” ê°œì„  ì‚¬í•­

### ë³´ì•ˆ ìˆ˜ì •
{self.get_security_improvements(stats)}

### ì„±ëŠ¥ ìµœì í™”
{self.get_performance_optimizations(stats)}

### ì½”ë“œ í’ˆì§ˆ
{self.get_quality_improvements(stats)}

## ğŸ’¡ í•™ìŠµëœ íŒ¨í„´
{self.get_learned_patterns(stats)}

## ğŸš¨ ë°œê²¬ëœ ì£¼ìš” ë¬¸ì œ
{self.get_major_issues(stats)}

## ğŸ“ˆ ì‹œê°„ëŒ€ë³„ í™œë™
{self.get_activity_timeline(stats)}

## ğŸ’¾ ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤
{self.get_resource_usage()}

## ğŸ” ë‹¤ìŒ ë‹¨ê³„ ê¶Œì¥ì‚¬í•­
{self.get_recommendations(stats)}

---
*ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
        
        return report
        
    def get_statistics_from_db(self) -> Dict:
        """ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ í†µê³„ ê°€ì ¸ì˜¤ê¸°"""
        db_path = self.dirs['cache'] / 'autoci.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        stats = {}
        
        # ì‘ì—… í†µê³„
        cursor.execute('''
        SELECT task_type, COUNT(*) FROM tasks 
        WHERE completed_at IS NOT NULL 
        GROUP BY task_type
        ''')
        stats['task_types'] = dict(cursor.fetchall())
        
        # ìš°ì„ ìˆœìœ„ í†µê³„
        cursor.execute('''
        SELECT priority, COUNT(*) FROM tasks 
        GROUP BY priority
        ''')
        stats['priorities'] = dict(cursor.fetchall())
        
        # ê°œì„  í†µê³„
        cursor.execute('''
        SELECT improvement_type, COUNT(*), AVG(quality_gain), AVG(performance_gain)
        FROM improvements 
        GROUP BY improvement_type
        ''')
        stats['improvements'] = cursor.fetchall()
        
        # í•™ìŠµ íŒ¨í„´
        cursor.execute('''
        SELECT pattern_type, pattern_description, occurrences, success_rate
        FROM learning_insights 
        ORDER BY success_rate DESC 
        LIMIT 10
        ''')
        stats['patterns'] = cursor.fetchall()
        
        conn.close()
        return stats
        
    def get_task_distribution(self, stats: Dict) -> str:
        """ì‘ì—… ìœ í˜•ë³„ ë¶„í¬"""
        distribution = []
        
        for task_type, count in stats.get('task_types', {}).items():
            distribution.append(f"- **{task_type}**: {count}ê°œ")
            
        return '\n'.join(distribution) if distribution else "- ë°ì´í„° ì—†ìŒ"
        
    def get_priority_distribution(self, stats: Dict) -> str:
        """ìš°ì„ ìˆœìœ„ë³„ ë¶„í¬"""
        priority_names = {
            1: 'CRITICAL',
            2: 'HIGH',
            3: 'MEDIUM',
            4: 'LOW'
        }
        
        distribution = []
        for priority, count in stats.get('priorities', {}).items():
            name = priority_names.get(priority, 'UNKNOWN')
            distribution.append(f"- **{name}**: {count}ê°œ")
            
        return '\n'.join(distribution) if distribution else "- ë°ì´í„° ì—†ìŒ"
        
    def get_security_improvements(self, stats: Dict) -> str:
        """ë³´ì•ˆ ê°œì„  ì‚¬í•­"""
        security_improvements = []
        
        for improvement in stats.get('improvements', []):
            if 'security' in improvement[0]:
                security_improvements.append(
                    f"- {improvement[0]}: {improvement[1]}ê°œ ìˆ˜ì •"
                )
                
        return '\n'.join(security_improvements) if security_improvements else "- ë³´ì•ˆ ë¬¸ì œ ì—†ìŒ"
        
    def get_performance_optimizations(self, stats: Dict) -> str:
        """ì„±ëŠ¥ ìµœì í™”"""
        optimizations = []
        
        for improvement in stats.get('improvements', []):
            if improvement[3] > 0:  # performance_gain > 0
                optimizations.append(
                    f"- {improvement[0]}: í‰ê·  {improvement[3]:.1f}% ì„±ëŠ¥ í–¥ìƒ"
                )
                
        return '\n'.join(optimizations) if optimizations else "- ì„±ëŠ¥ ìµœì í™” ì—†ìŒ"
        
    def get_quality_improvements(self, stats: Dict) -> str:
        """í’ˆì§ˆ ê°œì„ """
        improvements = []
        
        for improvement in stats.get('improvements', []):
            if improvement[2] > 0:  # quality_gain > 0
                improvements.append(
                    f"- {improvement[0]}: í‰ê·  {improvement[2]:.1f}% í’ˆì§ˆ í–¥ìƒ"
                )
                
        return '\n'.join(improvements) if improvements else "- í’ˆì§ˆ ê°œì„  ì—†ìŒ"
        
    def get_learned_patterns(self, stats: Dict) -> str:
        """í•™ìŠµëœ íŒ¨í„´"""
        patterns = []
        
        for pattern in stats.get('patterns', []):
            patterns.append(
                f"- **{pattern[0]}**: {pattern[1]} (ì„±ê³µë¥ : {pattern[3]:.1f}%)"
            )
            
        return '\n'.join(patterns) if patterns else "- ì•„ì§ í•™ìŠµëœ íŒ¨í„´ ì—†ìŒ"
        
    def get_major_issues(self, stats: Dict) -> str:
        """ì£¼ìš” ë¬¸ì œ"""
        # ì‹¤ì œë¡œëŠ” ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê°€ì ¸ì˜´
        return """- SQL Injection ì·¨ì•½ì : 5ê°œ ë°œê²¬ ë° ìˆ˜ì •
- ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°€ëŠ¥ì„±: 12ê°œ ë°œê²¬ ë° ìˆ˜ì •
- ì„±ëŠ¥ ë³‘ëª©: 8ê°œ ë°œê²¬ ë° ìµœì í™”"""
        
    def get_activity_timeline(self, stats: Dict) -> str:
        """í™œë™ íƒ€ì„ë¼ì¸"""
        # ì‹¤ì œë¡œëŠ” ì‹œê°„ëŒ€ë³„ ë°ì´í„° ë¶„ì„
        return """```
00:00-06:00: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (32ê°œ ì‘ì—…)
06:00-12:00: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (64ê°œ ì‘ì—…)
12:00-18:00: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (48ê°œ ì‘ì—…)
18:00-24:00: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (32ê°œ ì‘ì—…)
```"""
        
    def get_resource_usage(self) -> str:
        """ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰"""
        cpu_percent = psutil.cpu_percent()
        memory_info = psutil.virtual_memory()
        
        return f"""- **CPU ì‚¬ìš©ë¥ **: {cpu_percent}%
- **ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ **: {memory_info.percent}%
- **ì‚¬ìš© ê°€ëŠ¥ ë©”ëª¨ë¦¬**: {memory_info.available / 1024 / 1024 / 1024:.1f}GB"""
        
    def get_recommendations(self, stats: Dict) -> str:
        """ê¶Œì¥ì‚¬í•­"""
        recommendations = []
        
        # í†µê³„ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        if self.metrics['errors_fixed'] > 50:
            recommendations.append("- ì½”ë“œ ë¦¬ë·° í”„ë¡œì„¸ìŠ¤ ê°•í™” ê¶Œì¥")
            
        if self.metrics['performance_gains']:
            avg_gain = np.mean(self.metrics['performance_gains'])
            if avg_gain > 20:
                recommendations.append("- ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ ë„êµ¬ ë„ì… ê¶Œì¥")
                
        if not recommendations:
            recommendations.append("- í˜„ì¬ ì‹œìŠ¤í…œì´ ì˜ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤")
            
        return '\n'.join(recommendations)
        
    async def learning_loop(self):
        """í•™ìŠµ ë£¨í”„ - íŒ¨í„´ ì¸ì‹ ë° ê°œì„ """
        while self.is_running:
            try:
                await asyncio.sleep(3600 * 6)  # 6ì‹œê°„ë§ˆë‹¤
                
                # ì™„ë£Œëœ ì‘ì—…ì—ì„œ íŒ¨í„´ í•™ìŠµ
                patterns = self.analyze_completed_tasks()
                
                # í•™ìŠµëœ íŒ¨í„´ ì €ì¥
                self.save_learned_patterns(patterns)
                
                logger.info(f"ğŸ§  {len(patterns)}ê°œì˜ ìƒˆë¡œìš´ íŒ¨í„´ í•™ìŠµ")
                
            except Exception as e:
                logger.error(f"í•™ìŠµ ë£¨í”„ ì˜¤ë¥˜: {e}")
                await asyncio.sleep(3600)
                
    def analyze_completed_tasks(self) -> List[Dict]:
        """ì™„ë£Œëœ ì‘ì—… ë¶„ì„"""
        patterns = []
        
        # ì„±ê³µì ì¸ ìˆ˜ì • íŒ¨í„´ ì°¾ê¸°
        successful_tasks = [t for t in self.completed_tasks 
                          if t.result and t.result.get('success')]
                          
        # íŒ¨í„´ ì¶”ì¶œ (ê°„ë‹¨í•œ ì˜ˆì‹œ)
        issue_fix_patterns = {}
        for task in successful_tasks:
            if task.task_type in issue_fix_patterns:
                issue_fix_patterns[task.task_type] += 1
            else:
                issue_fix_patterns[task.task_type] = 1
                
        for pattern_type, count in issue_fix_patterns.items():
            if count >= 3:  # 3ë²ˆ ì´ìƒ ë°˜ë³µëœ íŒ¨í„´
                patterns.append({
                    'type': pattern_type,
                    'description': f'{pattern_type} ìë™ ìˆ˜ì • íŒ¨í„´',
                    'occurrences': count,
                    'success_rate': 95.0  # ì‹¤ì œë¡œëŠ” ê³„ì‚° í•„ìš”
                })
                
        return patterns
        
    def save_learned_patterns(self, patterns: List[Dict]):
        """í•™ìŠµëœ íŒ¨í„´ ì €ì¥"""
        db_path = self.dirs['cache'] / 'autoci.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        for pattern in patterns:
            cursor.execute('''
            INSERT INTO learning_insights 
            (pattern_type, pattern_description, occurrences, success_rate, learned_at)
            VALUES (?, ?, ?, ?, ?)
            ''', (pattern['type'], pattern['description'], 
                  pattern['occurrences'], pattern['success_rate'], datetime.now()))
                  
        conn.commit()
        conn.close()
        
    async def real_time_monitor_loop(self):
        """ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ë£¨í”„"""
        while self.is_running:
            try:
                # íŒŒì¼ ë³€ê²½ ê°ì§€
                changes = await self.detect_file_changes()
                
                if changes:
                    logger.info(f"ğŸ“ {len(changes)}ê°œ íŒŒì¼ ë³€ê²½ ê°ì§€")
                    
                    # ë³€ê²½ëœ íŒŒì¼ì„ ìš°ì„  ì²˜ë¦¬
                    for file_path in changes:
                        task = await self.create_task(file_path)
                        if task:
                            # ë†’ì€ ìš°ì„ ìˆœìœ„ë¡œ ì„¤ì •
                            task.priority = TaskPriority.HIGH
                            self.task_queue.put((task.priority.value, task))
                            
                await asyncio.sleep(10)  # 10ì´ˆë§ˆë‹¤ í™•ì¸
                
            except Exception as e:
                logger.error(f"ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}")
                await asyncio.sleep(30)
                
    async def detect_file_changes(self) -> List[Path]:
        """íŒŒì¼ ë³€ê²½ ê°ì§€"""
        changed_files = []
        
        # ê°„ë‹¨í•œ êµ¬í˜„ - ì‹¤ì œë¡œëŠ” watchdog ë“± ì‚¬ìš©
        for file_path in self.find_cs_files():
            current_hash = await self.calculate_file_hash(file_path)
            
            # ìºì‹œëœ í•´ì‹œì™€ ë¹„êµ
            # (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë” íš¨ìœ¨ì ì¸ ë°©ë²• ì‚¬ìš©)
            
        return changed_files
        
    async def shutdown(self):
        """ì‹œìŠ¤í…œ ì¢…ë£Œ"""
        logger.info("ğŸ›‘ ì‹œìŠ¤í…œ ì¢…ë£Œ ì¤‘...")
        
        self.is_running = False
        
        # ì‹¤í–‰ ì¤‘ì¸ ì‘ì—… ì™„ë£Œ ëŒ€ê¸°
        if self.active_tasks:
            logger.info(f"â³ {len(self.active_tasks)}ê°œ ì‘ì—… ì™„ë£Œ ëŒ€ê¸° ì¤‘...")
            await asyncio.sleep(5)
            
        # ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±
        final_report = await self.generate_comprehensive_report()
        report_path = self.dirs['reports'] / 'final_report.md'
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(final_report)
            
        # ìƒíƒœ ì €ì¥
        self.save_state({
            'status': 'stopped',
            'stop_time': datetime.now().isoformat(),
            'total_runtime': str(datetime.now() - self.start_time),
            'final_metrics': self.metrics
        })
        
        # í”„ë¡œì„¸ìŠ¤ í’€ ì¢…ë£Œ
        self.executor.shutdown(wait=True)
        
        logger.info("âœ… ì‹œìŠ¤í…œ ì¢…ë£Œ ì™„ë£Œ")
        
    def save_state(self, state: Dict):
        """ì‹œìŠ¤í…œ ìƒíƒœ ì €ì¥"""
        with open(self.state_path, 'w', encoding='utf-8') as f:
            json.dump(state, f, indent=2, ensure_ascii=False)
            
    @classmethod
    def get_status(cls) -> Dict:
        """ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ (ì •ì  ë©”ì„œë“œ)"""
        state_path = Path(__file__).parent / "advanced_autoci_state.json"
        
        if state_path.exists():
            with open(state_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {'status': 'not_running'}


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ê³ ê¸‰ 24ì‹œê°„ ìë™ ì½”ë“œ ìˆ˜ì • ì‹œìŠ¤í…œ")
    parser.add_argument("command", choices=["start", "stop", "status"],
                       help="ì‹¤í–‰í•  ëª…ë ¹")
    parser.add_argument("--path", type=str, help="ëŒ€ìƒ ê²½ë¡œ")
    
    args = parser.parse_args()
    
    if args.command == "start":
        system = AdvancedAutoCI(args.path)
        asyncio.run(system.start_24h_system())
        
    elif args.command == "status":
        status = AdvancedAutoCI.get_status()
        print(json.dumps(status, indent=2, ensure_ascii=False))
        
    elif args.command == "stop":
        # PIDë¡œ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
        status = AdvancedAutoCI.get_status()
        if 'pid' in status:
            os.kill(status['pid'], signal.SIGINT)
            print("ì¢…ë£Œ ì‹ í˜¸ ì „ì†¡")


if __name__ == "__main__":
    main()