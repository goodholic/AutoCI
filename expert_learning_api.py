#!/usr/bin/env python3
"""
C# ì „ë¬¸ê°€ í•™ìŠµ ì‹œìŠ¤í…œ Web API
ì‹¤ì‹œê°„ í•™ìŠµ ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§ ë° ì œì–´
"""

from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
import json
import asyncio
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional
import logging
from pydantic import BaseModel
import subprocess
import psutil

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="C# Expert Learning API",
    description="24ì‹œê°„ C# ì „ë¬¸ê°€ í•™ìŠµ ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ë° ì œì–´ API",
    version="1.0.0"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ì „ì—­ ìƒíƒœ ê´€ë¦¬
class LearningSystemState:
    def __init__(self):
        self.is_running = False
        self.start_time = None
        self.crawler_process = None
        self.server_process = None
        self.current_phase = "ëŒ€ê¸° ì¤‘"
        self.last_update = datetime.now()
        self.collected_data_count = 0
        self.improvements_count = 0
        self.training_cycles = 0
        self.current_model_score = 0.0
        
learning_state = LearningSystemState()

# Pydantic ëª¨ë¸
class LearningConfig(BaseModel):
    github_stars_threshold: int = 1000
    stackoverflow_score_threshold: int = 50
    code_quality_threshold: float = 0.7
    max_files_per_repo: int = 100
    crawl_interval_hours: int = 4
    auto_improvement: bool = True

class ImprovementRequest(BaseModel):
    code: str
    language: str = "csharp"
    context: Optional[str] = None

class TrainingStatus(BaseModel):
    is_running: bool
    current_phase: str
    uptime_hours: float
    collected_data_count: int
    improvements_count: int
    training_cycles: int
    current_model_score: float
    memory_usage_gb: float
    cpu_usage_percent: float

# API ì—”ë“œí¬ì¸íŠ¸
@app.get("/")
async def root():
    """API ë£¨íŠ¸"""
    return {
        "message": "C# Expert Learning System API",
        "status": "active",
        "version": "1.0.0",
        "endpoints": {
            "status": "/api/status",
            "start": "/api/start",
            "stop": "/api/stop",
            "stats": "/api/stats",
            "logs": "/api/logs",
            "config": "/api/config",
            "improve": "/api/improve"
        }
    }

@app.get("/api/status", response_model=TrainingStatus)
async def get_status():
    """í˜„ì¬ í•™ìŠµ ì‹œìŠ¤í…œ ìƒíƒœ"""
    uptime = 0
    if learning_state.is_running and learning_state.start_time:
        uptime = (datetime.now() - learning_state.start_time).total_seconds() / 3600
    
    # ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰
    memory = psutil.virtual_memory()
    cpu_percent = psutil.cpu_percent(interval=1)
    
    return TrainingStatus(
        is_running=learning_state.is_running,
        current_phase=learning_state.current_phase,
        uptime_hours=round(uptime, 2),
        collected_data_count=learning_state.collected_data_count,
        improvements_count=learning_state.improvements_count,
        training_cycles=learning_state.training_cycles,
        current_model_score=learning_state.current_model_score,
        memory_usage_gb=round(memory.used / (1024**3), 2),
        cpu_usage_percent=cpu_percent
    )

@app.post("/api/start")
async def start_learning(background_tasks: BackgroundTasks):
    """í•™ìŠµ ì‹œìŠ¤í…œ ì‹œì‘"""
    if learning_state.is_running:
        raise HTTPException(status_code=400, detail="í•™ìŠµ ì‹œìŠ¤í…œì´ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤")
    
    # ë°±ê·¸ë¼ìš´ë“œì—ì„œ í•™ìŠµ ì‹œì‘
    background_tasks.add_task(start_learning_system)
    
    return {
        "status": "started",
        "message": "C# ì „ë¬¸ê°€ í•™ìŠµ ì‹œìŠ¤í…œì„ ì‹œì‘í•©ë‹ˆë‹¤",
        "timestamp": datetime.now().isoformat()
    }

@app.post("/api/stop")
async def stop_learning():
    """í•™ìŠµ ì‹œìŠ¤í…œ ì¤‘ì§€"""
    if not learning_state.is_running:
        raise HTTPException(status_code=400, detail="í•™ìŠµ ì‹œìŠ¤í…œì´ ì‹¤í–‰ ì¤‘ì´ì§€ ì•ŠìŠµë‹ˆë‹¤")
    
    # í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
    if learning_state.crawler_process:
        learning_state.crawler_process.terminate()
    if learning_state.server_process:
        learning_state.server_process.terminate()
    
    learning_state.is_running = False
    learning_state.current_phase = "ì¤‘ì§€ë¨"
    
    return {
        "status": "stopped",
        "message": "í•™ìŠµ ì‹œìŠ¤í…œì„ ì¤‘ì§€í–ˆìŠµë‹ˆë‹¤",
        "timestamp": datetime.now().isoformat()
    }

@app.get("/api/stats")
async def get_statistics():
    """í•™ìŠµ í†µê³„ ì¡°íšŒ"""
    stats_file = Path("learning_stats.json")
    
    if not stats_file.exists():
        return {
            "total_data_collected": 0,
            "total_training_hours": 0,
            "model_improvements": [],
            "last_update": None
        }
    
    with open(stats_file, 'r', encoding='utf-8') as f:
        stats = json.load(f)
    
    # ìµœê·¼ 7ì¼ê°„ì˜ í†µê³„ ì¶”ê°€
    recent_stats = calculate_recent_stats(stats)
    stats["recent_7_days"] = recent_stats
    
    return stats

@app.get("/api/logs")
async def get_logs(lines: int = 100):
    """ìµœê·¼ ë¡œê·¸ ì¡°íšŒ"""
    log_file = Path("csharp_expert_learning.log")
    
    if not log_file.exists():
        return {"logs": [], "message": "ë¡œê·¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤"}
    
    with open(log_file, 'r', encoding='utf-8') as f:
        all_lines = f.readlines()
    
    recent_lines = all_lines[-lines:] if len(all_lines) > lines else all_lines
    
    # ë¡œê·¸ íŒŒì‹±
    parsed_logs = []
    for line in recent_lines:
        try:
            parts = line.strip().split(' - ', 3)
            if len(parts) >= 4:
                parsed_logs.append({
                    "timestamp": parts[0],
                    "logger": parts[1],
                    "level": parts[2],
                    "message": parts[3]
                })
            else:
                parsed_logs.append({"raw": line.strip()})
        except:
            parsed_logs.append({"raw": line.strip()})
    
    return {
        "logs": parsed_logs,
        "total_lines": len(all_lines),
        "returned_lines": len(parsed_logs)
    }

@app.get("/api/config")
async def get_config():
    """í˜„ì¬ ì„¤ì • ì¡°íšŒ"""
    config_file = Path("expert_learning_config.json")
    
    if not config_file.exists():
        raise HTTPException(status_code=404, detail="ì„¤ì • íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
    
    with open(config_file, 'r', encoding='utf-8') as f:
        config = json.load(f)
    
    return config

@app.put("/api/config")
async def update_config(config: LearningConfig):
    """ì„¤ì • ì—…ë°ì´íŠ¸"""
    config_file = Path("expert_learning_config.json")
    
    # ê¸°ì¡´ ì„¤ì • ë¡œë“œ
    if config_file.exists():
        with open(config_file, 'r', encoding='utf-8') as f:
            current_config = json.load(f)
    else:
        current_config = {}
    
    # í¬ë¡¤ëŸ¬ ì„¤ì • ì—…ë°ì´íŠ¸
    current_config["crawler_config"] = {
        "github_stars_threshold": config.github_stars_threshold,
        "stackoverflow_score_threshold": config.stackoverflow_score_threshold,
        "code_quality_threshold": config.code_quality_threshold,
        "max_files_per_repo": config.max_files_per_repo,
        "crawl_interval_hours": config.crawl_interval_hours
    }
    
    current_config["improvement_config"]["auto_fix"] = config.auto_improvement
    
    # ì €ì¥
    with open(config_file, 'w', encoding='utf-8') as f:
        json.dump(current_config, f, indent=2, ensure_ascii=False)
    
    return {
        "status": "updated",
        "message": "ì„¤ì •ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤",
        "config": current_config
    }

@app.post("/api/improve")
async def improve_code(request: ImprovementRequest):
    """ì½”ë“œ ê°œì„  ìš”ì²­"""
    if not learning_state.is_running:
        raise HTTPException(
            status_code=503, 
            detail="í•™ìŠµ ì‹œìŠ¤í…œì´ ì‹¤í–‰ ì¤‘ì´ì§€ ì•ŠìŠµë‹ˆë‹¤. ë¨¼ì € ì‹œìŠ¤í…œì„ ì‹œì‘í•˜ì„¸ìš”."
        )
    
    # AI ì„œë²„ì— ê°œì„  ìš”ì²­
    try:
        import aiohttp
        async with aiohttp.ClientSession() as session:
            async with session.post(
                "http://localhost:8000/improve",
                json={
                    "code": request.code,
                    "language": request.language,
                    "context": request.context
                }
            ) as response:
                if response.status == 200:
                    result = await response.json()
                    
                    # ê°œì„  íšŸìˆ˜ ì¦ê°€
                    learning_state.improvements_count += 1
                    
                    return {
                        "improved_code": result.get("improved_code"),
                        "suggestions": result.get("suggestions", []),
                        "quality_score": result.get("quality_score", 0),
                        "timestamp": datetime.now().isoformat()
                    }
                else:
                    raise HTTPException(
                        status_code=response.status,
                        detail="AI ì„œë²„ì—ì„œ ì½”ë“œ ê°œì„ ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤"
                    )
    except aiohttp.ClientError as e:
        raise HTTPException(
            status_code=503,
            detail=f"AI ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}"
        )

@app.get("/api/training-data")
async def get_training_data():
    """ìˆ˜ì§‘ëœ í•™ìŠµ ë°ì´í„° ì •ë³´"""
    data_dir = Path("expert_training_data")
    
    if not data_dir.exists():
        return {"sources": {}, "total": 0}
    
    sources = {}
    total_count = 0
    
    # ê° ì†ŒìŠ¤ë³„ ë°ì´í„° ì¹´ìš´íŠ¸
    for source_file in data_dir.glob("*.json"):
        try:
            with open(source_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                count = len(data) if isinstance(data, list) else 0
                sources[source_file.stem] = count
                total_count += count
        except:
            sources[source_file.stem] = 0
    
    return {
        "sources": sources,
        "total": total_count,
        "last_update": datetime.now().isoformat()
    }

@app.get("/api/improvements")
async def get_improvements():
    """ìµœê·¼ ì½”ë“œ ê°œì„  ë‚´ì—­"""
    improvements_dir = Path("expert_training_data/improvements")
    
    if not improvements_dir.exists():
        return {"improvements": [], "total": 0}
    
    improvements = []
    
    # ìµœê·¼ 10ê°œ ê°œì„  íŒŒì¼
    for imp_file in sorted(improvements_dir.glob("*_improvements.md"), 
                          key=lambda x: x.stat().st_mtime, 
                          reverse=True)[:10]:
        try:
            with open(imp_file, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # ê°„ë‹¨í•œ íŒŒì‹±
            improvements.append({
                "file": imp_file.stem.replace("_improvements", ""),
                "timestamp": datetime.fromtimestamp(imp_file.stat().st_mtime).isoformat(),
                "preview": content[:200] + "..." if len(content) > 200 else content
            })
        except:
            pass
    
    return {
        "improvements": improvements,
        "total": len(list(improvements_dir.glob("*_improvements.md")))
    }

@app.get("/api/model-info")
async def get_model_info():
    """ëª¨ë¸ ì •ë³´ ì¡°íšŒ"""
    model_path = Path("CodeLlama-7b-Instruct-hf")
    
    if not model_path.exists():
        return {
            "status": "not_found",
            "message": "ëª¨ë¸ì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
        }
    
    # ëª¨ë¸ í¬ê¸° ê³„ì‚°
    total_size = sum(f.stat().st_size for f in model_path.rglob("*") if f.is_file())
    
    return {
        "status": "installed",
        "model_name": "CodeLlama-7b-Instruct-hf",
        "size_gb": round(total_size / (1024**3), 2),
        "path": str(model_path),
        "files_count": len(list(model_path.rglob("*")))
    }

# ì •ì  íŒŒì¼ ì„œë¹™ (ëŒ€ì‹œë³´ë“œ)
app.mount("/dashboard", StaticFiles(directory=".", html=True), name="dashboard")

# í—¬í¼ í•¨ìˆ˜ë“¤
def calculate_recent_stats(stats: Dict) -> Dict:
    """ìµœê·¼ 7ì¼ê°„ì˜ í†µê³„ ê³„ì‚°"""
    recent = {
        "data_collected": 0,
        "improvements": 0,
        "training_hours": 0,
        "avg_quality_score": 0
    }
    
    # ì‹¤ì œ êµ¬í˜„ì€ íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜ìœ¼ë¡œ ê³„ì‚°
    # ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œ ë°ì´í„°
    recent["data_collected"] = stats.get("total_data_collected", 0) // 7
    recent["training_hours"] = stats.get("total_training_hours", 0) / 7
    
    return recent

async def start_learning_system():
    """í•™ìŠµ ì‹œìŠ¤í…œ ì‹œì‘ (ë°±ê·¸ë¼ìš´ë“œ)"""
    try:
        learning_state.is_running = True
        learning_state.start_time = datetime.now()
        learning_state.current_phase = "ì‹œì‘ ì¤‘..."
        
        # í¬ë¡¤ëŸ¬ í”„ë¡œì„¸ìŠ¤ ì‹œì‘
        learning_state.crawler_process = subprocess.Popen(
            ["python", "csharp_expert_crawler.py"],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE
        )
        
        # AI ì„œë²„ í”„ë¡œì„¸ìŠ¤ ì‹œì‘ (ìˆëŠ” ê²½ìš°)
        enhanced_server = Path("MyAIWebApp/Models/enhanced_server.py")
        if enhanced_server.exists():
            learning_state.server_process = subprocess.Popen(
                ["python", "-m", "uvicorn", "enhanced_server:app", 
                 "--host", "0.0.0.0", "--port", "8000"],
                cwd="MyAIWebApp/Models",
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE
            )
        
        learning_state.current_phase = "ì‹¤í–‰ ì¤‘"
        
        # ì£¼ê¸°ì ìœ¼ë¡œ ìƒíƒœ ì—…ë°ì´íŠ¸
        while learning_state.is_running:
            await update_learning_state()
            await asyncio.sleep(30)  # 30ì´ˆë§ˆë‹¤ ì—…ë°ì´íŠ¸
            
    except Exception as e:
        logger.error(f"í•™ìŠµ ì‹œìŠ¤í…œ ì‹œì‘ ì˜¤ë¥˜: {e}")
        learning_state.is_running = False
        learning_state.current_phase = f"ì˜¤ë¥˜: {str(e)}"

async def update_learning_state():
    """í•™ìŠµ ìƒíƒœ ì—…ë°ì´íŠ¸"""
    # í†µê³„ íŒŒì¼ì—ì„œ ìµœì‹  ì •ë³´ ì½ê¸°
    stats_file = Path("learning_stats.json")
    if stats_file.exists():
        try:
            with open(stats_file, 'r', encoding='utf-8') as f:
                stats = json.load(f)
                
            learning_state.collected_data_count = stats.get("total_data_collected", 0)
            learning_state.training_cycles = len(stats.get("model_improvements", []))
            
            if stats.get("model_improvements"):
                latest = stats["model_improvements"][-1]
                learning_state.current_model_score = latest.get("score_change", 0)
        except:
            pass
    
    # í˜„ì¬ ì§„í–‰ ë‹¨ê³„ ì¶”ì •
    now = datetime.now()
    hours_since_start = (now - learning_state.start_time).total_seconds() / 3600
    
    if hours_since_start < 4:
        learning_state.current_phase = "ë°ì´í„° ìˆ˜ì§‘ ì¤‘..."
    elif hours_since_start < 5:
        learning_state.current_phase = "ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘..."
    elif hours_since_start < 11:
        learning_state.current_phase = "ëª¨ë¸ í•™ìŠµ ì¤‘..."
    elif hours_since_start < 12:
        learning_state.current_phase = "ëª¨ë¸ í‰ê°€ ì¤‘..."
    else:
        learning_state.current_phase = "ì½”ë“œ ê°œì„  ì„œë¹„ìŠ¤ ì‹¤í–‰ ì¤‘..."

# ì‹¤í–‰
if __name__ == "__main__":
    import uvicorn
    logger.info("ğŸš€ C# Expert Learning API ì‹œì‘...")
    uvicorn.run(app, host="0.0.0.0", port=8080)