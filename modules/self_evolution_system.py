#!/usr/bin/env python3
"""
AutoCI ìê°€ ì§„í™” ì‹œìŠ¤í…œ (Self-Evolution System)
ì‚¬ìš©ì ì§ˆë¬¸ì„ í†µí•´ ìŠ¤ìŠ¤ë¡œ í•™ìŠµí•˜ê³  ë°œì „í•˜ëŠ” ì§‘ë‹¨ ì§€ì„± ì‹œìŠ¤í…œ
"""

import os
import sys
import json
import time
import hashlib
import asyncio
import logging
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, asdict
from collections import defaultdict
import numpy as np
from concurrent.futures import ThreadPoolExecutor

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('self_evolution.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

@dataclass
class UserQuestion:
    """ì‚¬ìš©ì ì§ˆë¬¸ ë°ì´í„°"""
    question_id: str
    user_id: str  # ìµëª…í™”ëœ ì‚¬ìš©ì ID
    timestamp: datetime
    question: str
    context: Dict[str, Any]  # í”„ë¡œì íŠ¸ íƒ€ì…, ì–¸ì–´, ì—”ì§„ ë²„ì „ ë“±
    category: Optional[str] = None  # ìë™ ë¶„ë¥˜ëœ ì¹´í…Œê³ ë¦¬
    tags: List[str] = None  # ìë™ íƒœê¹…
    
@dataclass
class AIResponse:
    """AI ì‘ë‹µ ë°ì´í„°"""
    response_id: str
    question_id: str
    timestamp: datetime
    response: str
    confidence_score: float  # AIì˜ ìì‹ ê° ì ìˆ˜
    model_used: str
    generation_time: float  # ì‘ë‹µ ìƒì„± ì‹œê°„
    
@dataclass
class UserFeedback:
    """ì‚¬ìš©ì í”¼ë“œë°± ë°ì´í„°"""
    feedback_id: str
    response_id: str
    timestamp: datetime
    is_helpful: bool  # ë„ì›€ì´ ë˜ì—ˆëŠ”ì§€
    rating: Optional[int] = None  # 1-5 ì ìˆ˜
    comment: Optional[str] = None  # ì¶”ê°€ ì˜ê²¬
    
@dataclass
class SelfEvaluation:
    """ìê°€ í‰ê°€ ë°ì´í„°"""
    evaluation_id: str
    response_id: str
    timestamp: datetime
    accuracy_score: float  # ì •í™•ë„ ì ìˆ˜
    completeness_score: float  # ì™„ì„±ë„ ì ìˆ˜
    relevance_score: float  # ê´€ë ¨ì„± ì ìˆ˜
    technical_score: float  # ê¸°ìˆ ì  ì •í™•ì„±
    improvement_suggestions: List[str]  # ê°œì„  ì œì•ˆ
    
@dataclass
class EvolutionInsight:
    """ì§„í™” ì¸ì‚¬ì´íŠ¸"""
    insight_id: str
    timestamp: datetime
    pattern_type: str  # ë°œê²¬ëœ íŒ¨í„´ íƒ€ì…
    pattern_data: Dict[str, Any]
    confidence: float
    impact_score: float  # ì˜ˆìƒ ì˜í–¥ë„
    implementation_ready: bool

class SelfEvolutionSystem:
    """AutoCI ìê°€ ì§„í™” ì‹œìŠ¤í…œ"""
    
    def __init__(self, data_dir: str = "./evolution_data"):
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(exist_ok=True)
        
        # ë°ì´í„° ì €ì¥ ë””ë ‰í† ë¦¬
        self.questions_dir = self.data_dir / "questions"
        self.responses_dir = self.data_dir / "responses"
        self.feedback_dir = self.data_dir / "feedback"
        self.evaluations_dir = self.data_dir / "evaluations"
        self.insights_dir = self.data_dir / "insights"
        self.knowledge_dir = self.data_dir / "collective_knowledge"
        
        # ëª¨ë“  ë””ë ‰í† ë¦¬ ìƒì„±
        for dir_path in [self.questions_dir, self.responses_dir, 
                        self.feedback_dir, self.evaluations_dir,
                        self.insights_dir, self.knowledge_dir]:
            dir_path.mkdir(exist_ok=True)
        
        # ì§‘ë‹¨ ì§€ì„± ë°ì´í„°ë² ì´ìŠ¤
        self.collective_knowledge = self._load_collective_knowledge()
        
        # ì§„í™” ë©”íŠ¸ë¦­ìŠ¤
        self.evolution_metrics = {
            "total_questions": 0,
            "total_responses": 0,
            "average_accuracy": 0.0,
            "learning_rate": 0.0,
            "knowledge_domains": defaultdict(int),
            "common_issues": defaultdict(int),
            "successful_patterns": [],
            "improvement_areas": []
        }
        
        # ìê°€ í‰ê°€ ëª¨ë¸ (ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ + í†µê³„)
        self.evaluation_criteria = {
            "code_quality": ["syntax", "style", "efficiency", "readability"],
            "answer_quality": ["completeness", "accuracy", "clarity", "usefulness"],
            "technical_accuracy": ["correct_api", "best_practices", "security", "performance"]
        }
        
        # ì§„í™” ì•Œê³ ë¦¬ì¦˜ íŒŒë¼ë¯¸í„°
        self.evolution_params = {
            "learning_rate": 0.01,
            "min_confidence_threshold": 0.7,
            "pattern_detection_threshold": 5,  # ìµœì†Œ ë°œìƒ íšŸìˆ˜
            "evolution_cycle": 100  # ì§„í™” ì£¼ê¸° (ì§ˆë¬¸ ìˆ˜)
        }
        
        logger.info("ìê°€ ì§„í™” ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def _load_collective_knowledge(self) -> Dict[str, Any]:
        """ì§‘ë‹¨ ì§€ì„± ì§€ì‹ ë² ì´ìŠ¤ ë¡œë“œ"""
        knowledge_file = self.knowledge_dir / "knowledge_base.json"
        if knowledge_file.exists():
            with open(knowledge_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        
        # ì´ˆê¸° ì§€ì‹ ë² ì´ìŠ¤
        return {
            "patterns": {},  # ë°œê²¬ëœ íŒ¨í„´ë“¤
            "solutions": {},  # ê²€ì¦ëœ ì†”ë£¨ì…˜ë“¤
            "common_questions": {},  # ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ë“¤
            "best_practices": {},  # ëª¨ë²” ì‚¬ë¡€ë“¤
            "error_solutions": {},  # ì˜¤ë¥˜ í•´ê²°ë²•ë“¤
            "optimization_tips": {},  # ìµœì í™” íŒë“¤
            "version": "1.0",
            "last_updated": datetime.now().isoformat()
        }
    
    async def process_user_question(self, question: str, context: Dict[str, Any]) -> Tuple[str, str]:
        """ì‚¬ìš©ì ì§ˆë¬¸ ì²˜ë¦¬ ë° ì‘ë‹µ ìƒì„±"""
        # 1. ì§ˆë¬¸ ê¸°ë¡
        question_obj = UserQuestion(
            question_id=self._generate_id("Q"),
            user_id=context.get("user_id", "anonymous"),
            timestamp=datetime.now(),
            question=question,
            context=context,
            category=self._categorize_question(question),
            tags=self._extract_tags(question)
        )
        
        # ì§ˆë¬¸ ì €ì¥
        await self._save_question(question_obj)
        
        # 2. ì§‘ë‹¨ ì§€ì„±ì—ì„œ ìœ ì‚¬ ì§ˆë¬¸ ê²€ìƒ‰
        similar_questions = await self._find_similar_questions(question)
        
        # 3. AI ì‘ë‹µ ìƒì„± (ì§‘ë‹¨ ì§€ì„± í™œìš©)
        response = await self._generate_response(question, context, similar_questions)
        
        # 4. ìê°€ í‰ê°€
        evaluation = await self._self_evaluate(question_obj, response)
        
        # 5. ì§‘ë‹¨ ì§€ì„± ì—…ë°ì´íŠ¸
        await self._update_collective_knowledge(question_obj, response, evaluation)
        
        return response.response, response.response_id
    
    def _generate_id(self, prefix: str) -> str:
        """ê³ ìœ  ID ìƒì„±"""
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S%f")
        random_part = hashlib.md5(os.urandom(16)).hexdigest()[:8]
        return f"{prefix}_{timestamp}_{random_part}"
    
    def _categorize_question(self, question: str) -> str:
        """ì§ˆë¬¸ ìë™ ë¶„ë¥˜"""
        question_lower = question.lower()
        
        # ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œ ë§¤í•‘
        categories = {
            "godot_engine": ["godot", "ì—”ì§„", "ì”¬", "ë…¸ë“œ", "gdscript"],
            "csharp": ["c#", "csharp", "ì”¨ìƒµ", "í´ë˜ìŠ¤", "ë©”ì„œë“œ"],
            "networking": ["ë„¤íŠ¸ì›Œí¬", "ë©€í‹°í”Œë ˆì´ì–´", "ì„œë²„", "í´ë¼ì´ì–¸íŠ¸", "ë™ê¸°í™”"],
            "nakama": ["nakama", "ë‚˜ì¹´ë§ˆ", "ë§¤ì¹˜ë©”ì´í‚¹", "ë¦¬ë”ë³´ë“œ"],
            "ai_integration": ["ai", "ì¸ê³µì§€ëŠ¥", "llm", "ëª¨ë¸"],
            "optimization": ["ìµœì í™”", "ì„±ëŠ¥", "ë©”ëª¨ë¦¬", "ì†ë„"],
            "debugging": ["ì˜¤ë¥˜", "ì—ëŸ¬", "ë²„ê·¸", "ë””ë²„ê·¸", "ë¬¸ì œ"],
            "deployment": ["ë°°í¬", "ë¹Œë“œ", "export", "ë¦´ë¦¬ì¦ˆ"]
        }
        
        for category, keywords in categories.items():
            if any(keyword in question_lower for keyword in keywords):
                return category
        
        return "general"
    
    def _extract_tags(self, question: str) -> List[str]:
        """ì§ˆë¬¸ì—ì„œ íƒœê·¸ ì¶”ì¶œ"""
        tags = []
        
        # ê¸°ìˆ  ìŠ¤íƒ íƒœê·¸
        tech_tags = {
            "godot4": ["godot 4", "ê³ ë„ 4"],
            "csharp": ["c#", "csharp"],
            "gdscript": ["gdscript", "gdìŠ¤í¬ë¦½íŠ¸"],
            "multiplayer": ["ë©€í‹°í”Œë ˆì´ì–´", "multiplayer", "ë„¤íŠ¸ì›Œí¬"],
            "mobile": ["ëª¨ë°”ì¼", "ì•ˆë“œë¡œì´ë“œ", "ios"],
            "vr": ["vr", "ê°€ìƒí˜„ì‹¤"],
            "2d": ["2d", "2ë””"],
            "3d": ["3d", "3ë””"]
        }
        
        question_lower = question.lower()
        for tag, keywords in tech_tags.items():
            if any(keyword in question_lower for keyword in keywords):
                tags.append(tag)
        
        return tags
    
    async def _find_similar_questions(self, question: str) -> List[Dict[str, Any]]:
        """ìœ ì‚¬ ì§ˆë¬¸ ê²€ìƒ‰"""
        similar = []
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ìœ ì‚¬ë„ ê²€ìƒ‰
        keywords = set(question.lower().split())
        
        # ê¸°ì¡´ ì§ˆë¬¸ë“¤ê³¼ ë¹„êµ
        for q_file in self.questions_dir.glob("*.json"):
            with open(q_file, 'r', encoding='utf-8') as f:
                q_data = json.load(f)
                
            q_keywords = set(q_data['question'].lower().split())
            similarity = len(keywords & q_keywords) / len(keywords | q_keywords)
            
            if similarity > 0.3:  # 30% ì´ìƒ ìœ ì‚¬ë„
                similar.append({
                    "question": q_data['question'],
                    "response_id": q_data.get('best_response_id'),
                    "similarity": similarity,
                    "rating": q_data.get('average_rating', 0)
                })
        
        # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        similar.sort(key=lambda x: x['similarity'], reverse=True)
        return similar[:5]  # ìƒìœ„ 5ê°œ
    
    async def _generate_response(self, question: str, context: Dict[str, Any], 
                               similar_questions: List[Dict[str, Any]]) -> AIResponse:
        """AI ì‘ë‹µ ìƒì„± (ì§‘ë‹¨ ì§€ì„± í™œìš©)"""
        start_time = time.time()
        
        # ì§‘ë‹¨ ì§€ì„±ì—ì„œ ê´€ë ¨ ì •ë³´ ìˆ˜ì§‘
        collective_context = self._gather_collective_context(question, similar_questions)
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""
ì§ˆë¬¸: {question}

í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸: {json.dumps(context, ensure_ascii=False)}

ìœ ì‚¬ ì§ˆë¬¸ ë° ë‹µë³€:
{self._format_similar_questions(similar_questions)}

ì§‘ë‹¨ ì§€ì„± ì •ë³´:
{json.dumps(collective_context, ensure_ascii=False)}

ìœ„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
"""
        
        # ì‹¤ì œ AI ëª¨ë¸ í˜¸ì¶œ (ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜)
        # TODO: ì‹¤ì œ LLM í†µí•©
        response_text = await self._call_ai_model(prompt)
        
        # ì‘ë‹µ ê°ì²´ ìƒì„±
        response = AIResponse(
            response_id=self._generate_id("R"),
            question_id=question,  # ì‹¤ì œë¡œëŠ” question_obj.question_id
            timestamp=datetime.now(),
            response=response_text,
            confidence_score=self._calculate_confidence(response_text, collective_context),
            model_used="autoci-evolution-1.0",
            generation_time=time.time() - start_time
        )
        
        # ì‘ë‹µ ì €ì¥
        await self._save_response(response)
        
        return response
    
    def _gather_collective_context(self, question: str, similar_questions: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ì§‘ë‹¨ ì§€ì„±ì—ì„œ ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘"""
        context = {
            "relevant_patterns": [],
            "proven_solutions": [],
            "common_pitfalls": [],
            "best_practices": []
        }
        
        # ì§ˆë¬¸ ì¹´í…Œê³ ë¦¬ì— ë”°ë¥¸ ê´€ë ¨ ì •ë³´ ìˆ˜ì§‘
        category = self._categorize_question(question)
        
        if category in self.collective_knowledge.get("patterns", {}):
            context["relevant_patterns"] = self.collective_knowledge["patterns"][category][:3]
        
        if category in self.collective_knowledge.get("solutions", {}):
            context["proven_solutions"] = self.collective_knowledge["solutions"][category][:3]
        
        # ìœ ì‚¬ ì§ˆë¬¸ë“¤ì˜ ì„±ê³µì ì¸ ë‹µë³€ ì°¸ê³ 
        for sim_q in similar_questions:
            if sim_q.get("rating", 0) >= 4:  # ë†’ì€ í‰ì ì˜ ë‹µë³€
                context["proven_solutions"].append({
                    "question": sim_q["question"],
                    "rating": sim_q["rating"]
                })
        
        return context
    
    def _format_similar_questions(self, similar_questions: List[Dict[str, Any]]) -> str:
        """ìœ ì‚¬ ì§ˆë¬¸ í¬ë§·íŒ…"""
        if not similar_questions:
            return "ìœ ì‚¬í•œ ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤."
        
        formatted = []
        for i, sq in enumerate(similar_questions[:3], 1):
            formatted.append(f"{i}. ì§ˆë¬¸: {sq['question']}")
            formatted.append(f"   ìœ ì‚¬ë„: {sq['similarity']:.1%}")
            if sq.get('rating'):
                formatted.append(f"   í‰ì : {sq['rating']}/5")
            formatted.append("")
        
        return "\n".join(formatted)
    
    async def _call_ai_model(self, prompt: str) -> str:
        """AI ëª¨ë¸ í˜¸ì¶œ (ì‹œë®¬ë ˆì´ì…˜)"""
        # TODO: ì‹¤ì œ LLM í†µí•©
        # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ í…œí”Œë¦¿ ì‘ë‹µ ìƒì„±
        
        await asyncio.sleep(0.5)  # AI ì²˜ë¦¬ ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜
        
        # ì‹¤ì œë¡œëŠ” LLMì´ ìƒì„±í•  ì‘ë‹µ
        response = f"""
í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì…ë‹ˆë‹¤.

[ì§‘ë‹¨ ì§€ì„± ê¸°ë°˜ ë‹µë³€]
AutoCIê°€ ë‹¤ë¥¸ ì‚¬ìš©ìë“¤ì˜ ìœ ì‚¬í•œ ì§ˆë¬¸ê³¼ ê²€ì¦ëœ ì†”ë£¨ì…˜ì„ ë¶„ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤.

1. ì£¼ìš” í•´ê²° ë°©ë²•:
   - ì²« ë²ˆì§¸ ì ‘ê·¼ë²•
   - ë‘ ë²ˆì§¸ ì ‘ê·¼ë²•

2. ì£¼ì˜ ì‚¬í•­:
   - ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œ
   - í•´ê²° ë°©ë²•

3. ì¶”ê°€ íŒ:
   - ìµœì í™” ë°©ë²•
   - ëª¨ë²” ì‚¬ë¡€

ì´ ë‹µë³€ì€ AutoCIì˜ ìê°€ í•™ìŠµ ì‹œìŠ¤í…œì„ í†µí•´ ì§€ì†ì ìœ¼ë¡œ ê°œì„ ë©ë‹ˆë‹¤.
"""
        
        return response
    
    def _calculate_confidence(self, response: str, context: Dict[str, Any]) -> float:
        """ì‘ë‹µ ì‹ ë¢°ë„ ê³„ì‚°"""
        confidence = 0.5  # ê¸°ë³¸ ì‹ ë¢°ë„
        
        # ì§‘ë‹¨ ì§€ì„± ì •ë³´ í™œìš©ë„ì— ë”°ë¼ ì‹ ë¢°ë„ ì¦ê°€
        if context.get("proven_solutions"):
            confidence += 0.2
        
        if context.get("relevant_patterns"):
            confidence += 0.15
        
        # ì‘ë‹µ ê¸¸ì´ì™€ êµ¬ì¡°ì— ë”°ë¥¸ ë³´ì •
        if len(response) > 100:
            confidence += 0.1
        
        if any(keyword in response for keyword in ["í•´ê²°", "ë°©ë²•", "ì½”ë“œ", "ì˜ˆì œ"]):
            confidence += 0.05
        
        return min(confidence, 1.0)
    
    async def _self_evaluate(self, question: UserQuestion, response: AIResponse) -> SelfEvaluation:
        """ìê°€ í‰ê°€ ìˆ˜í–‰"""
        scores = {
            "accuracy": 0.0,
            "completeness": 0.0,
            "relevance": 0.0,
            "technical": 0.0
        }
        
        improvements = []
        
        # 1. ì •í™•ë„ í‰ê°€
        scores["accuracy"] = self._evaluate_accuracy(question, response)
        
        # 2. ì™„ì„±ë„ í‰ê°€
        scores["completeness"] = self._evaluate_completeness(response.response)
        
        # 3. ê´€ë ¨ì„± í‰ê°€
        scores["relevance"] = self._evaluate_relevance(question.question, response.response)
        
        # 4. ê¸°ìˆ ì  ì •í™•ì„± í‰ê°€
        scores["technical"] = self._evaluate_technical_accuracy(response.response, question.category)
        
        # ê°œì„  ì œì•ˆ ìƒì„±
        if scores["accuracy"] < 0.7:
            improvements.append("ì •í™•ë„ í–¥ìƒ: ë” ë§ì€ ê²€ì¦ëœ ë°ì´í„° í•„ìš”")
        
        if scores["completeness"] < 0.7:
            improvements.append("ì™„ì„±ë„ í–¥ìƒ: ë” ìƒì„¸í•œ ì„¤ëª…ê³¼ ì˜ˆì œ ì¶”ê°€")
        
        if scores["relevance"] < 0.7:
            improvements.append("ê´€ë ¨ì„± í–¥ìƒ: ì§ˆë¬¸ ì˜ë„ íŒŒì•… ê°œì„  í•„ìš”")
        
        # í‰ê°€ ê°ì²´ ìƒì„±
        evaluation = SelfEvaluation(
            evaluation_id=self._generate_id("E"),
            response_id=response.response_id,
            timestamp=datetime.now(),
            accuracy_score=scores["accuracy"],
            completeness_score=scores["completeness"],
            relevance_score=scores["relevance"],
            technical_score=scores["technical"],
            improvement_suggestions=improvements
        )
        
        # í‰ê°€ ì €ì¥
        await self._save_evaluation(evaluation)
        
        return evaluation
    
    def _evaluate_accuracy(self, question: UserQuestion, response: AIResponse) -> float:
        """ì •í™•ë„ í‰ê°€"""
        score = 0.5  # ê¸°ë³¸ ì ìˆ˜
        
        # ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œ ì²´í¬
        category_keywords = {
            "godot_engine": ["Node", "Scene", "Signal", "export"],
            "csharp": ["class", "method", "namespace", "using"],
            "networking": ["RPC", "MultiplayerAPI", "peer", "sync"],
        }
        
        if question.category in category_keywords:
            keywords = category_keywords[question.category]
            found = sum(1 for kw in keywords if kw.lower() in response.response.lower())
            score += (found / len(keywords)) * 0.3
        
        # ì‘ë‹µ ì‹ ë¢°ë„ ë°˜ì˜
        score += response.confidence_score * 0.2
        
        return min(score, 1.0)
    
    def _evaluate_completeness(self, response_text: str) -> float:
        """ì™„ì„±ë„ í‰ê°€"""
        score = 0.0
        
        # êµ¬ì¡°ì  ìš”ì†Œ ì²´í¬
        if "í•´ê²°" in response_text or "ë°©ë²•" in response_text:
            score += 0.3
        
        if "ì˜ˆì œ" in response_text or "ì½”ë“œ" in response_text:
            score += 0.3
        
        if "ì£¼ì˜" in response_text or "ì°¸ê³ " in response_text:
            score += 0.2
        
        # ê¸¸ì´ ì²´í¬
        if len(response_text) > 200:
            score += 0.2
        
        return min(score, 1.0)
    
    def _evaluate_relevance(self, question: str, response: str) -> float:
        """ê´€ë ¨ì„± í‰ê°€"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­
        q_keywords = set(question.lower().split())
        r_keywords = set(response.lower().split())
        
        if not q_keywords:
            return 0.5
        
        overlap = len(q_keywords & r_keywords) / len(q_keywords)
        return min(overlap * 1.5, 1.0)  # 1.5ë°° ë¶€ìŠ¤íŠ¸
    
    def _evaluate_technical_accuracy(self, response: str, category: str) -> float:
        """ê¸°ìˆ ì  ì •í™•ì„± í‰ê°€"""
        score = 0.6  # ê¸°ë³¸ ì ìˆ˜
        
        # ì¹´í…Œê³ ë¦¬ë³„ ê¸°ìˆ  ìš©ì–´ ì •í™•ì„± ì²´í¬
        technical_terms = {
            "godot_engine": {
                "correct": ["Node2D", "Node3D", "_ready", "_process"],
                "incorrect": ["GameObject", "Update", "Start"]  # Unity ìš©ì–´
            },
            "csharp": {
                "correct": ["public", "private", "class", "interface"],
                "incorrect": ["function", "var", "let"]  # JS ìš©ì–´
            }
        }
        
        if category in technical_terms:
            terms = technical_terms[category]
            
            # ì˜¬ë°”ë¥¸ ìš©ì–´ ì‚¬ìš©
            for term in terms["correct"]:
                if term in response:
                    score += 0.1
            
            # ì˜ëª»ëœ ìš©ì–´ ì‚¬ìš© ê°ì 
            for term in terms["incorrect"]:
                if term in response:
                    score -= 0.15
        
        return max(0.0, min(score, 1.0))
    
    async def _update_collective_knowledge(self, question: UserQuestion, 
                                         response: AIResponse, 
                                         evaluation: SelfEvaluation):
        """ì§‘ë‹¨ ì§€ì„± ì§€ì‹ ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸"""
        # ì§ˆë¬¸ íŒ¨í„´ ì—…ë°ì´íŠ¸
        if question.category not in self.collective_knowledge["patterns"]:
            self.collective_knowledge["patterns"][question.category] = []
        
        # ë†’ì€ ì ìˆ˜ì˜ ì‘ë‹µì€ ì§€ì‹ ë² ì´ìŠ¤ì— ì¶”ê°€
        avg_score = (evaluation.accuracy_score + evaluation.completeness_score + 
                    evaluation.relevance_score + evaluation.technical_score) / 4
        
        if avg_score >= 0.8:  # 80% ì´ìƒì˜ ì ìˆ˜
            pattern = {
                "question_pattern": question.question,
                "response_template": response.response,
                "score": avg_score,
                "usage_count": 1,
                "last_used": datetime.now().isoformat()
            }
            
            self.collective_knowledge["patterns"][question.category].append(pattern)
            
            # ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ ì—…ë°ì´íŠ¸
            q_hash = hashlib.md5(question.question.encode()).hexdigest()
            if q_hash not in self.collective_knowledge["common_questions"]:
                self.collective_knowledge["common_questions"][q_hash] = {
                    "question": question.question,
                    "count": 0,
                    "best_response": None,
                    "average_score": 0.0
                }
            
            self.collective_knowledge["common_questions"][q_hash]["count"] += 1
            
            if avg_score > self.collective_knowledge["common_questions"][q_hash]["average_score"]:
                self.collective_knowledge["common_questions"][q_hash]["best_response"] = response.response
                self.collective_knowledge["common_questions"][q_hash]["average_score"] = avg_score
        
        # ì§„í™” ë©”íŠ¸ë¦­ìŠ¤ ì—…ë°ì´íŠ¸
        self.evolution_metrics["total_questions"] += 1
        self.evolution_metrics["total_responses"] += 1
        self.evolution_metrics["knowledge_domains"][question.category] += 1
        
        # ì£¼ê¸°ì ìœ¼ë¡œ ì§„í™” ì‚¬ì´í´ ì‹¤í–‰
        if self.evolution_metrics["total_questions"] % self.evolution_params["evolution_cycle"] == 0:
            await self._run_evolution_cycle()
        
        # ì§€ì‹ ë² ì´ìŠ¤ ì €ì¥
        await self._save_collective_knowledge()
    
    async def _run_evolution_cycle(self):
        """ì§„í™” ì‚¬ì´í´ ì‹¤í–‰"""
        logger.info("ì§„í™” ì‚¬ì´í´ ì‹œì‘...")
        
        # 1. íŒ¨í„´ ë¶„ì„
        insights = await self._analyze_patterns()
        
        # 2. ê°œì„  ì˜ì—­ ì‹ë³„
        improvements = await self._identify_improvements()
        
        # 3. ìƒˆë¡œìš´ ì¸ì‚¬ì´íŠ¸ ìƒì„±
        for insight in insights:
            if insight.confidence >= self.evolution_params["min_confidence_threshold"]:
                await self._save_insight(insight)
                
                # ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ëŠ” ì¦‰ì‹œ ì ìš©
                if insight.implementation_ready:
                    await self._implement_insight(insight)
        
        # 4. í•™ìŠµë¥  ì¡°ì •
        self._adjust_learning_rate()
        
        logger.info(f"ì§„í™” ì‚¬ì´í´ ì™„ë£Œ: {len(insights)} ê°œì˜ ìƒˆë¡œìš´ ì¸ì‚¬ì´íŠ¸ ë°œê²¬")
    
    async def _analyze_patterns(self) -> List[EvolutionInsight]:
        """íŒ¨í„´ ë¶„ì„ ë° ì¸ì‚¬ì´íŠ¸ ë„ì¶œ"""
        insights = []
        
        # ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ ë¶„ì„
        for q_hash, q_data in self.collective_knowledge["common_questions"].items():
            if q_data["count"] >= self.evolution_params["pattern_detection_threshold"]:
                insight = EvolutionInsight(
                    insight_id=self._generate_id("I"),
                    timestamp=datetime.now(),
                    pattern_type="frequent_question",
                    pattern_data={
                        "question": q_data["question"],
                        "frequency": q_data["count"],
                        "best_response": q_data["best_response"]
                    },
                    confidence=min(q_data["count"] / 100, 1.0),
                    impact_score=q_data["count"] / self.evolution_metrics["total_questions"],
                    implementation_ready=True
                )
                insights.append(insight)
        
        # ì¹´í…Œê³ ë¦¬ë³„ íŠ¸ë Œë“œ ë¶„ì„
        total_questions = self.evolution_metrics["total_questions"]
        for category, count in self.evolution_metrics["knowledge_domains"].items():
            if count / total_questions > 0.1:  # 10% ì´ìƒì˜ ì§ˆë¬¸
                insight = EvolutionInsight(
                    insight_id=self._generate_id("I"),
                    timestamp=datetime.now(),
                    pattern_type="category_trend",
                    pattern_data={
                        "category": category,
                        "percentage": count / total_questions,
                        "growth_rate": self._calculate_growth_rate(category)
                    },
                    confidence=0.9,
                    impact_score=count / total_questions,
                    implementation_ready=False
                )
                insights.append(insight)
        
        return insights
    
    async def _identify_improvements(self) -> List[Dict[str, Any]]:
        """ê°œì„  ì˜ì—­ ì‹ë³„"""
        improvements = []
        
        # ë‚®ì€ ì ìˆ˜ ì‘ë‹µ ë¶„ì„
        low_score_patterns = defaultdict(list)
        
        for eval_file in self.evaluations_dir.glob("*.json"):
            with open(eval_file, 'r', encoding='utf-8') as f:
                eval_data = json.load(f)
            
            avg_score = (eval_data["accuracy_score"] + eval_data["completeness_score"] + 
                        eval_data["relevance_score"] + eval_data["technical_score"]) / 4
            
            if avg_score < 0.6:  # 60% ë¯¸ë§Œ
                for suggestion in eval_data["improvement_suggestions"]:
                    low_score_patterns[suggestion].append(eval_data["response_id"])
        
        # ê°œì„  ìš°ì„ ìˆœìœ„ ê²°ì •
        for suggestion, response_ids in low_score_patterns.items():
            if len(response_ids) >= 3:  # 3ê°œ ì´ìƒ ë°œìƒ
                improvements.append({
                    "area": suggestion,
                    "frequency": len(response_ids),
                    "priority": "high" if len(response_ids) >= 10 else "medium",
                    "affected_responses": response_ids[:5]  # ìƒ˜í”Œ
                })
        
        self.evolution_metrics["improvement_areas"] = improvements
        return improvements
    
    def _calculate_growth_rate(self, category: str) -> float:
        """ì¹´í…Œê³ ë¦¬ ì„±ì¥ë¥  ê³„ì‚°"""
        # ê°„ë‹¨í•œ êµ¬í˜„: ìµœê·¼ ì§ˆë¬¸ ë¹„ìœ¨ ê³„ì‚°
        recent_count = 0
        total_recent = 0
        
        # ìµœê·¼ 100ê°œ ì§ˆë¬¸ ì¤‘ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ ë¹„ìœ¨
        recent_files = sorted(self.questions_dir.glob("*.json"), 
                            key=lambda x: x.stat().st_mtime, 
                            reverse=True)[:100]
        
        for q_file in recent_files:
            with open(q_file, 'r', encoding='utf-8') as f:
                q_data = json.load(f)
            
            total_recent += 1
            if q_data.get("category") == category:
                recent_count += 1
        
        if total_recent == 0:
            return 0.0
        
        recent_ratio = recent_count / total_recent
        overall_ratio = self.evolution_metrics["knowledge_domains"][category] / self.evolution_metrics["total_questions"]
        
        return (recent_ratio - overall_ratio) / (overall_ratio + 0.001)  # ì„±ì¥ë¥ 
    
    def _adjust_learning_rate(self):
        """í•™ìŠµë¥  ë™ì  ì¡°ì •"""
        # í‰ê·  ì ìˆ˜ê°€ ë†’ìœ¼ë©´ í•™ìŠµë¥  ê°ì†Œ, ë‚®ìœ¼ë©´ ì¦ê°€
        recent_scores = []
        
        for eval_file in sorted(self.evaluations_dir.glob("*.json"), 
                               key=lambda x: x.stat().st_mtime, 
                               reverse=True)[:50]:
            with open(eval_file, 'r', encoding='utf-8') as f:
                eval_data = json.load(f)
            
            avg_score = (eval_data["accuracy_score"] + eval_data["completeness_score"] + 
                        eval_data["relevance_score"] + eval_data["technical_score"]) / 4
            recent_scores.append(avg_score)
        
        if recent_scores:
            avg_recent_score = sum(recent_scores) / len(recent_scores)
            
            if avg_recent_score > 0.8:  # ì„±ëŠ¥ ì¢‹ìŒ
                self.evolution_params["learning_rate"] *= 0.95
            elif avg_recent_score < 0.6:  # ì„±ëŠ¥ ë‚˜ì¨
                self.evolution_params["learning_rate"] *= 1.05
            
            # í•™ìŠµë¥  ë²”ìœ„ ì œí•œ
            self.evolution_params["learning_rate"] = max(0.001, 
                                                       min(0.1, self.evolution_params["learning_rate"]))
            
            self.evolution_metrics["learning_rate"] = self.evolution_params["learning_rate"]
            self.evolution_metrics["average_accuracy"] = avg_recent_score
    
    async def _implement_insight(self, insight: EvolutionInsight):
        """ì¸ì‚¬ì´íŠ¸ ìë™ êµ¬í˜„"""
        if insight.pattern_type == "frequent_question":
            # ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ì€ ë¹ ë¥¸ ì‘ë‹µ ìºì‹œì— ì¶”ê°€
            q_data = insight.pattern_data
            
            if "solutions" not in self.collective_knowledge:
                self.collective_knowledge["solutions"] = {}
            
            # ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ
            category = self._categorize_question(q_data["question"])
            
            if category not in self.collective_knowledge["solutions"]:
                self.collective_knowledge["solutions"][category] = []
            
            # ê²€ì¦ëœ ì†”ë£¨ì…˜ìœ¼ë¡œ ì¶”ê°€
            self.collective_knowledge["solutions"][category].append({
                "question": q_data["question"],
                "solution": q_data["best_response"],
                "usage_count": q_data["frequency"],
                "confidence": insight.confidence,
                "added_date": datetime.now().isoformat()
            })
            
            logger.info(f"ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ ì†”ë£¨ì…˜ ì¶”ê°€: {q_data['question'][:50]}...")
    
    async def receive_user_feedback(self, response_id: str, is_helpful: bool, 
                                   rating: Optional[int] = None, 
                                   comment: Optional[str] = None):
        """ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì‹ """
        feedback = UserFeedback(
            feedback_id=self._generate_id("F"),
            response_id=response_id,
            timestamp=datetime.now(),
            is_helpful=is_helpful,
            rating=rating,
            comment=comment
        )
        
        # í”¼ë“œë°± ì €ì¥
        await self._save_feedback(feedback)
        
        # í”¼ë“œë°± ê¸°ë°˜ í•™ìŠµ
        await self._learn_from_feedback(feedback)
    
    async def _learn_from_feedback(self, feedback: UserFeedback):
        """í”¼ë“œë°±ìœ¼ë¡œë¶€í„° í•™ìŠµ"""
        # ì‘ë‹µ ì •ë³´ ë¡œë“œ
        response_file = self.responses_dir / f"{feedback.response_id}.json"
        if not response_file.exists():
            return
        
        with open(response_file, 'r', encoding='utf-8') as f:
            response_data = json.load(f)
        
        # ê¸ì •ì  í”¼ë“œë°±ì€ íŒ¨í„´ ê°•í™”
        if feedback.is_helpful and (feedback.rating is None or feedback.rating >= 4):
            # í•´ë‹¹ ì‘ë‹µ íŒ¨í„´ ê°•í™”
            category = self._categorize_question(response_data.get("question", ""))
            
            if category in self.collective_knowledge["patterns"]:
                for pattern in self.collective_knowledge["patterns"][category]:
                    if pattern["response_template"] == response_data["response"]:
                        pattern["usage_count"] += 1
                        pattern["last_used"] = datetime.now().isoformat()
                        break
        
        # ë¶€ì •ì  í”¼ë“œë°±ì€ ê°œì„  í•„ìš” ì˜ì—­ìœ¼ë¡œ ë§ˆí‚¹
        elif not feedback.is_helpful or (feedback.rating and feedback.rating <= 2):
            if feedback.comment:
                # ì½”ë©˜íŠ¸ ë¶„ì„í•˜ì—¬ ê°œì„ ì  ì¶”ì¶œ
                self.evolution_metrics["improvement_areas"].append({
                    "response_id": feedback.response_id,
                    "feedback": feedback.comment,
                    "timestamp": feedback.timestamp.isoformat()
                })
        
        # ì§€ì‹ ë² ì´ìŠ¤ ì €ì¥
        await self._save_collective_knowledge()
    
    async def get_evolution_status(self) -> Dict[str, Any]:
        """ì§„í™” ìƒíƒœ ì¡°íšŒ"""
        # ìµœê·¼ ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
        recent_performance = await self._calculate_recent_performance()
        
        return {
            "metrics": self.evolution_metrics,
            "recent_performance": recent_performance,
            "knowledge_domains": dict(self.evolution_metrics["knowledge_domains"]),
            "top_questions": self._get_top_questions(),
            "improvement_areas": self.evolution_metrics["improvement_areas"][:5],
            "evolution_stage": self._determine_evolution_stage(),
            "collective_knowledge_size": self._calculate_knowledge_size()
        }
    
    async def _calculate_recent_performance(self) -> Dict[str, float]:
        """ìµœê·¼ ì„±ëŠ¥ ê³„ì‚°"""
        recent_evals = []
        
        for eval_file in sorted(self.evaluations_dir.glob("*.json"), 
                               key=lambda x: x.stat().st_mtime, 
                               reverse=True)[:100]:
            with open(eval_file, 'r', encoding='utf-8') as f:
                eval_data = json.load(f)
            
            recent_evals.append({
                "accuracy": eval_data["accuracy_score"],
                "completeness": eval_data["completeness_score"],
                "relevance": eval_data["relevance_score"],
                "technical": eval_data["technical_score"]
            })
        
        if not recent_evals:
            return {"accuracy": 0, "completeness": 0, "relevance": 0, "technical": 0}
        
        # í‰ê·  ê³„ì‚°
        performance = {
            "accuracy": sum(e["accuracy"] for e in recent_evals) / len(recent_evals),
            "completeness": sum(e["completeness"] for e in recent_evals) / len(recent_evals),
            "relevance": sum(e["relevance"] for e in recent_evals) / len(recent_evals),
            "technical": sum(e["technical"] for e in recent_evals) / len(recent_evals)
        }
        
        return performance
    
    def _get_top_questions(self, limit: int = 10) -> List[Dict[str, Any]]:
        """ê°€ì¥ ë§ì´ ë¬»ëŠ” ì§ˆë¬¸ë“¤"""
        top_questions = []
        
        for q_hash, q_data in self.collective_knowledge["common_questions"].items():
            top_questions.append({
                "question": q_data["question"],
                "count": q_data["count"],
                "average_score": q_data["average_score"]
            })
        
        # ë¹ˆë„ìˆœ ì •ë ¬
        top_questions.sort(key=lambda x: x["count"], reverse=True)
        
        return top_questions[:limit]
    
    def _determine_evolution_stage(self) -> str:
        """ì§„í™” ë‹¨ê³„ ê²°ì •"""
        total_q = self.evolution_metrics["total_questions"]
        avg_acc = self.evolution_metrics["average_accuracy"]
        
        if total_q < 100:
            return "ì´ˆê¸° í•™ìŠµ ë‹¨ê³„"
        elif total_q < 1000:
            if avg_acc > 0.7:
                return "ë¹ ë¥¸ ì„±ì¥ ë‹¨ê³„"
            else:
                return "ê¸°ì´ˆ í•™ìŠµ ë‹¨ê³„"
        elif total_q < 10000:
            if avg_acc > 0.8:
                return "ì§€ì‹ í™•ì¥ ë‹¨ê³„"
            else:
                return "ì§€ì‹ ê°œì„  ë‹¨ê³„"
        else:
            if avg_acc > 0.85:
                return "ì „ë¬¸ê°€ ë‹¨ê³„"
            elif avg_acc > 0.75:
                return "ìˆ™ë ¨ ë‹¨ê³„"
            else:
                return "ì§€ì† ê°œì„  ë‹¨ê³„"
    
    def _calculate_knowledge_size(self) -> Dict[str, int]:
        """ì§€ì‹ ë² ì´ìŠ¤ í¬ê¸° ê³„ì‚°"""
        size = {
            "patterns": sum(len(patterns) for patterns in self.collective_knowledge["patterns"].values()),
            "solutions": sum(len(sols) for sols in self.collective_knowledge.get("solutions", {}).values()),
            "common_questions": len(self.collective_knowledge["common_questions"]),
            "best_practices": len(self.collective_knowledge.get("best_practices", {})),
            "total_insights": len(list(self.insights_dir.glob("*.json")))
        }
        
        size["total"] = sum(size.values())
        
        return size
    
    # ë°ì´í„° ì €ì¥ ë©”ì„œë“œë“¤
    async def _save_question(self, question: UserQuestion):
        """ì§ˆë¬¸ ì €ì¥"""
        file_path = self.questions_dir / f"{question.question_id}.json"
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(asdict(question), f, ensure_ascii=False, indent=2, default=str)
    
    async def _save_response(self, response: AIResponse):
        """ì‘ë‹µ ì €ì¥"""
        file_path = self.responses_dir / f"{response.response_id}.json"
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(asdict(response), f, ensure_ascii=False, indent=2, default=str)
    
    async def _save_feedback(self, feedback: UserFeedback):
        """í”¼ë“œë°± ì €ì¥"""
        file_path = self.feedback_dir / f"{feedback.feedback_id}.json"
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(asdict(feedback), f, ensure_ascii=False, indent=2, default=str)
    
    async def _save_evaluation(self, evaluation: SelfEvaluation):
        """í‰ê°€ ì €ì¥"""
        file_path = self.evaluations_dir / f"{evaluation.evaluation_id}.json"
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(asdict(evaluation), f, ensure_ascii=False, indent=2, default=str)
    
    async def _save_insight(self, insight: EvolutionInsight):
        """ì¸ì‚¬ì´íŠ¸ ì €ì¥"""
        file_path = self.insights_dir / f"{insight.insight_id}.json"
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(asdict(insight), f, ensure_ascii=False, indent=2, default=str)
    
    async def _save_collective_knowledge(self):
        """ì§‘ë‹¨ ì§€ì„± ì €ì¥"""
        self.collective_knowledge["last_updated"] = datetime.now().isoformat()
        
        file_path = self.knowledge_dir / "knowledge_base.json"
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(self.collective_knowledge, f, ensure_ascii=False, indent=2)
        
        # ë°±ì—… ìƒì„±
        backup_path = self.knowledge_dir / f"knowledge_base_backup_{datetime.now().strftime('%Y%m%d')}.json"
        with open(backup_path, 'w', encoding='utf-8') as f:
            json.dump(self.collective_knowledge, f, ensure_ascii=False, indent=2)


    async def collect_experiences(self) -> List[Dict[str, Any]]:
        """ê²½í—˜ ë°ì´í„° ìˆ˜ì§‘ (í•™ìŠµì„ ìœ„í•œ ì§ˆë¬¸-ë‹µë³€ ìŒ)"""
        experiences = []
        
        # ì €ì¥ëœ ì§ˆë¬¸-ì‘ë‹µ ìŒì—ì„œ í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘
        for q_file in self.questions_dir.glob("*.json"):
            try:
                with open(q_file, 'r', encoding='utf-8') as f:
                    question_data = json.load(f)
                
                # í•´ë‹¹ ì§ˆë¬¸ì˜ ì‘ë‹µ ì°¾ê¸°
                response_id = question_data.get('best_response_id')
                if response_id:
                    response_file = self.responses_dir / f"{response_id}.json"
                    if response_file.exists():
                        with open(response_file, 'r', encoding='utf-8') as f:
                            response_data = json.load(f)
                        
                        # í‰ê°€ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                        eval_file = self.evaluations_dir / f"eval_{response_id}.json"
                        eval_data = {}
                        if eval_file.exists():
                            with open(eval_file, 'r', encoding='utf-8') as f:
                                eval_data = json.load(f)
                        
                        # ê²½í—˜ ë°ì´í„° êµ¬ì„±
                        experience = {
                            'question': question_data['question'],
                            'answer': response_data['response'],
                            'category': question_data.get('category', 'general'),
                            'tags': question_data.get('tags', []),
                            'quality_score': eval_data.get('total_score', 0.5),
                            'topic': question_data.get('category', 'general'),
                            'timestamp': question_data.get('timestamp'),
                            'context': question_data.get('context', {})
                        }
                        
                        experiences.append(experience)
                        
            except Exception as e:
                logger.error(f"ê²½í—˜ ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
                continue
        
        # ê²½í—˜ì´ ì—†ìœ¼ë©´ ìƒ˜í”Œ ë°ì´í„° ìƒì„±
        if not experiences:
            experiences = self._generate_sample_experiences()
        
        logger.info(f"ìˆ˜ì§‘ëœ ê²½í—˜ ë°ì´í„°: {len(experiences)}ê°œ")
        return experiences
    
    def _generate_sample_experiences(self) -> List[Dict[str, Any]]:
        """ìƒ˜í”Œ ê²½í—˜ ë°ì´í„° ìƒì„±"""
        return [
            {
                'question': 'C#ì—ì„œ Godot ë…¸ë“œë¥¼ ë™ì ìœ¼ë¡œ ìƒì„±í•˜ëŠ” ë°©ë²•ì€?',
                'answer': '''Godotì—ì„œ C#ì„ ì‚¬ìš©í•˜ì—¬ ë…¸ë“œë¥¼ ë™ì ìœ¼ë¡œ ìƒì„±í•˜ëŠ” ë°©ë²•:

```csharp
// ìƒˆ ë…¸ë“œ ìƒì„±
var newNode = new Node2D();
newNode.Name = "DynamicNode";

// ì†ì„± ì„¤ì •
newNode.Position = new Vector2(100, 100);

// í˜„ì¬ ì”¬ì— ì¶”ê°€
AddChild(newNode);

// íŠ¹ì • íƒ€ì…ì˜ ë…¸ë“œ ìƒì„±
var sprite = new Sprite2D();
sprite.Texture = GD.Load<Texture2D>("res://icon.png");
newNode.AddChild(sprite);
```''',
                'category': 'csharp',
                'tags': ['godot4', 'csharp', 'nodes'],
                'quality_score': 0.85,
                'topic': 'C# í”„ë¡œê·¸ë˜ë°',
                'timestamp': datetime.now().isoformat(),
                'context': {'godot_version': '4.2', 'language': 'csharp'}
            },
            {
                'question': 'ë³€í˜•ëœ Godotì—ì„œ Socket.IOë¥¼ í†µí•œ ì‹¤ì‹œê°„ í†µì‹  êµ¬í˜„ ë°©ë²•ì€?',
                'answer': '''Socket.IOë¥¼ ì‚¬ìš©í•œ ì‹¤ì‹œê°„ í†µì‹  êµ¬í˜„:

1. ì„œë²„ ì¸¡ (Node.js + Socket.IO):
```javascript
const io = require('socket.io')(3000);

io.on('connection', (socket) => {
    console.log('Client connected:', socket.id);
    
    socket.on('game_action', (data) => {
        // ëª¨ë“  í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ë¸Œë¡œë“œìºìŠ¤íŠ¸
        io.emit('game_update', data);
    });
});
```

2. í´ë¼ì´ì–¸íŠ¸ ì¸¡ (Godot C#):
```csharp
public partial class NetworkManager : Node
{
    private SocketIOClient.SocketIO socket;
    
    public override void _Ready()
    {
        socket = new SocketIOClient.SocketIO("http://localhost:3000");
        socket.ConnectAsync();
        
        socket.On("game_update", response =>
        {
            var data = response.GetValue<GameData>();
            UpdateGameState(data);
        });
    }
}
```''',
                'category': 'networking',
                'tags': ['socketio', 'multiplayer', 'realtime'],
                'quality_score': 0.90,
                'topic': 'ë„¤íŠ¸ì›Œí‚¹',
                'timestamp': datetime.now().isoformat(),
                'context': {'project_type': 'multiplayer', 'network_lib': 'socketio'}
            },
            {
                'question': 'AI ëª¨ë¸ì„ Godot ê²Œì„ì— í†µí•©í•˜ëŠ” ìµœì í™” ë°©ë²•ì€?',
                'answer': '''AI ëª¨ë¸ í†µí•© ìµœì í™” ì „ëµ:

1. ëª¨ë¸ ê²½ëŸ‰í™”:
- ONNX í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì¶”ë¡  ì†ë„ í–¥ìƒ
- ì–‘ìí™”(Quantization) ì ìš©ìœ¼ë¡œ ëª¨ë¸ í¬ê¸° ê°ì†Œ

2. ë¹„ë™ê¸° ì²˜ë¦¬:
```csharp
public async Task<string> GetAIResponse(string input)
{
    return await Task.Run(() => 
    {
        // AI ëª¨ë¸ ì¶”ë¡ ì„ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
        return aiModel.Predict(input);
    });
}
```

3. ìºì‹± ì „ëµ:
- ìì£¼ ì‚¬ìš©ë˜ëŠ” ì‘ë‹µ ìºì‹±
- ìœ ì‚¬ ì…ë ¥ì— ëŒ€í•œ ê²°ê³¼ ì¬ì‚¬ìš©

4. ë°°ì¹˜ ì²˜ë¦¬:
- ì—¬ëŸ¬ ìš”ì²­ì„ ëª¨ì•„ì„œ í•œ ë²ˆì— ì²˜ë¦¬''',
                'category': 'ai_integration',
                'tags': ['ai', 'optimization', 'performance'],
                'quality_score': 0.88,
                'topic': 'AI ìµœì í™”',
                'timestamp': datetime.now().isoformat(),
                'context': {'optimization_target': 'inference_speed'}
            }
        ]


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_evolution_system = None

def get_evolution_system() -> SelfEvolutionSystem:
    """ìê°€ ì§„í™” ì‹œìŠ¤í…œ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _evolution_system
    if _evolution_system is None:
        _evolution_system = SelfEvolutionSystem()
    return _evolution_system


async def main():
    """í…ŒìŠ¤íŠ¸ ë° ë°ëª¨"""
    system = get_evolution_system()
    
    # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸
    test_question = "Godot 4ì—ì„œ ë©€í‹°í”Œë ˆì´ì–´ ê²Œì„ì„ ë§Œë“¤ ë•Œ RPC ë™ê¸°í™”ëŠ” ì–´ë–»ê²Œ í•˜ë‚˜ìš”?"
    test_context = {
        "user_id": "test_user_001",
        "project_type": "multiplayer_fps",
        "godot_version": "4.2",
        "language": "csharp"
    }
    
    print("ğŸ§¬ AutoCI ìê°€ ì§„í™” ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # ì§ˆë¬¸ ì²˜ë¦¬
    response, response_id = await system.process_user_question(test_question, test_context)
    
    print(f"ì§ˆë¬¸: {test_question}")
    print(f"ì‘ë‹µ ID: {response_id}")
    print(f"ì‘ë‹µ:\n{response}")
    print("=" * 60)
    
    # í”¼ë“œë°± ì‹œë®¬ë ˆì´ì…˜
    await system.receive_user_feedback(response_id, True, 5, "ë§¤ìš° ë„ì›€ì´ ë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    # ì§„í™” ìƒíƒœ í™•ì¸
    status = await system.get_evolution_status()
    print(f"ì§„í™” ìƒíƒœ: {status['evolution_stage']}")
    print(f"ì´ ì§ˆë¬¸ ìˆ˜: {status['metrics']['total_questions']}")
    print(f"í‰ê·  ì •í™•ë„: {status['metrics']['average_accuracy']:.2%}")
    print(f"ì§€ì‹ ë² ì´ìŠ¤ í¬ê¸°: {status['collective_knowledge_size']['total']}")


if __name__ == "__main__":
    asyncio.run(main())