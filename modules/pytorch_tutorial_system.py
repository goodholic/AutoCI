"""
PyTorch íŠœí† ë¦¬ì–¼ ë° ëŒ€í™”í˜• í•™ìŠµ ì‹œìŠ¤í…œ
AIê°€ PyTorchì˜ ê¸°ì´ˆë¶€í„° ê³ ê¸‰ê¹Œì§€ ì„¤ëª…í•˜ê³  ì½”ë“œ ì˜ˆì œë¥¼ ì œê³µ
"""

import json
import os
from typing import Dict, List, Optional, Tuple
from datetime import datetime
import asyncio
from pathlib import Path

class PyTorchTutorialSystem:
    """PyTorch ëŒ€í™”í˜• í•™ìŠµ ì‹œìŠ¤í…œ"""
    
    def __init__(self, ai_model=None):
        self.ai_model = ai_model
        self.knowledge_base_path = Path("continuous_learning/knowledge_base/pytorch_tutorials.json")
        self.conversation_history = []
        self.current_topic = None
        self.tutorial_progress = {}
        
        # PyTorch í•™ìŠµ ì£¼ì œë“¤
        self.topics = {
            "basics": {
                "title": "PyTorch ê¸°ì´ˆ",
                "subtopics": [
                    "í…ì„œ(Tensor) ì´í•´í•˜ê¸°",
                    "ìë™ ë¯¸ë¶„(Autograd)",
                    "ì‹ ê²½ë§ êµ¬ì¶• (nn.Module)",
                    "ë°ì´í„° ë¡œë”© (DataLoader)",
                    "ì˜µí‹°ë§ˆì´ì €ì™€ ì†ì‹¤ í•¨ìˆ˜"
                ]
            },
            "intermediate": {
                "title": "PyTorch ì¤‘ê¸‰",
                "subtopics": [
                    "CNN (Convolutional Neural Networks)",
                    "RNN/LSTM êµ¬í˜„",
                    "Transfer Learning",
                    "ëª¨ë¸ ì €ì¥ ë° ë¶ˆëŸ¬ì˜¤ê¸°",
                    "GPU í™œìš©í•˜ê¸°"
                ]
            },
            "advanced": {
                "title": "PyTorch ê³ ê¸‰",
                "subtopics": [
                    "Custom Datasetê³¼ DataLoader",
                    "Mixed Precision Training",
                    "Distributed Training",
                    "ëª¨ë¸ ìµœì í™” (Quantization, Pruning)",
                    "Production ë°°í¬"
                ]
            },
            "practical": {
                "title": "ì‹¤ì „ í”„ë¡œì íŠ¸",
                "subtopics": [
                    "ì´ë¯¸ì§€ ë¶„ë¥˜ í”„ë¡œì íŠ¸",
                    "ìì—°ì–´ ì²˜ë¦¬ (NLP) í”„ë¡œì íŠ¸",
                    "ê°•í™”í•™ìŠµ êµ¬í˜„",
                    "GAN êµ¬í˜„í•˜ê¸°",
                    "ì‹œê³„ì—´ ì˜ˆì¸¡"
                ]
            }
        }
        
        # ê¸°ë³¸ PyTorch ì§€ì‹ ë² ì´ìŠ¤
        self.pytorch_knowledge = {
            "í…ì„œ(Tensor) ì´í•´í•˜ê¸°": {
                "explanation": """
í…ì„œ(Tensor)ëŠ” PyTorchì˜ ê°€ì¥ ê¸°ë³¸ì ì¸ ìë£Œêµ¬ì¡°ì…ë‹ˆë‹¤.
NumPyì˜ ndarrayì™€ ë¹„ìŠ·í•˜ì§€ë§Œ, GPUì—ì„œ ì—°ì‚°ì´ ê°€ëŠ¥í•˜ê³  ìë™ ë¯¸ë¶„ì„ ì§€ì›í•©ë‹ˆë‹¤.

ì£¼ìš” íŠ¹ì§•:
1. ë‹¤ì°¨ì› ë°°ì—´ êµ¬ì¡°
2. GPU ê°€ì† ì§€ì›
3. ìë™ ë¯¸ë¶„ (requires_grad=True)
4. ë‹¤ì–‘í•œ ìˆ˜í•™ ì—°ì‚° ì§€ì›
                """,
                "code_examples": [
                    {
                        "title": "í…ì„œ ìƒì„±í•˜ê¸°",
                        "code": """
import torch

# 1. ì§ì ‘ ë°ì´í„°ë¡œ í…ì„œ ìƒì„±
data = [[1, 2], [3, 4]]
x_data = torch.tensor(data)

# 2. NumPy ë°°ì—´ì—ì„œ í…ì„œ ìƒì„±
import numpy as np
np_array = np.array(data)
x_np = torch.from_numpy(np_array)

# 3. ë‹¤ë¥¸ í…ì„œë¡œë¶€í„° ìƒì„±
x_ones = torch.ones_like(x_data)  # x_dataì™€ ê°™ì€ shape
x_rand = torch.rand_like(x_data, dtype=torch.float)

# 4. íŠ¹ì • í¬ê¸°ì˜ í…ì„œ ìƒì„±
shape = (2, 3)
rand_tensor = torch.rand(shape)
ones_tensor = torch.ones(shape)
zeros_tensor = torch.zeros(shape)
"""
                    },
                    {
                        "title": "í…ì„œ ì†ì„±ê³¼ ì—°ì‚°",
                        "code": """
# í…ì„œ ì†ì„±
tensor = torch.rand(3, 4)
print(f"Shape: {tensor.shape}")
print(f"Datatype: {tensor.dtype}")
print(f"Device: {tensor.device}")

# GPUë¡œ ì´ë™ (ê°€ëŠ¥í•œ ê²½ìš°)
if torch.cuda.is_available():
    tensor = tensor.to('cuda')

# ê¸°ë³¸ ì—°ì‚°
tensor1 = torch.tensor([[1, 2], [3, 4]])
tensor2 = torch.tensor([[5, 6], [7, 8]])

# ë§ì…ˆ
add_result = tensor1 + tensor2
# ë˜ëŠ”
add_result = torch.add(tensor1, tensor2)

# í–‰ë ¬ ê³±ì…ˆ
matmul_result = tensor1 @ tensor2
# ë˜ëŠ”
matmul_result = torch.matmul(tensor1, tensor2)

# ì›ì†Œë³„ ê³±ì…ˆ
mul_result = tensor1 * tensor2
"""
                    }
                ]
            },
            "ìë™ ë¯¸ë¶„(Autograd)": {
                "explanation": """
PyTorchì˜ AutogradëŠ” ìë™ ë¯¸ë¶„ì„ ìœ„í•œ ì—”ì§„ì…ë‹ˆë‹¤.
ì‹ ê²½ë§ í•™ìŠµì— í•„ìˆ˜ì ì¸ ì—­ì „íŒŒ(backpropagation)ë¥¼ ìë™ìœ¼ë¡œ ê³„ì‚°í•´ì¤ë‹ˆë‹¤.

í•µì‹¬ ê°œë…:
1. requires_grad=True: ë¯¸ë¶„ ì¶”ì  í™œì„±í™”
2. backward(): ì—­ì „íŒŒ ì‹¤í–‰
3. grad: ê³„ì‚°ëœ ê¸°ìš¸ê¸° ì €ì¥
4. no_grad(): ë¯¸ë¶„ ì¶”ì  ë¹„í™œì„±í™” (ì¶”ë¡  ì‹œ ì‚¬ìš©)
                """,
                "code_examples": [
                    {
                        "title": "ìë™ ë¯¸ë¶„ ê¸°ë³¸",
                        "code": """
import torch

# requires_grad=Trueë¡œ ë¯¸ë¶„ ì¶”ì  í™œì„±í™”
x = torch.ones(2, 2, requires_grad=True)
print(x)

# ì—°ì‚° ìˆ˜í–‰
y = x + 2
z = y * y * 3
out = z.mean()

print(f"y: {y}")
print(f"z: {z}")
print(f"out: {out}")

# ì—­ì „íŒŒ
out.backward()

# ê¸°ìš¸ê¸° í™•ì¸
print(f"x.grad: {x.grad}")
"""
                    },
                    {
                        "title": "ê°„ë‹¨í•œ ìµœì í™” ì˜ˆì œ",
                        "code": """
# ê°„ë‹¨í•œ ì„ í˜• íšŒê·€
import torch
import torch.nn as nn

# ë°ì´í„° ì¤€ë¹„
x = torch.tensor([[1.0], [2.0], [3.0], [4.0]])
y = torch.tensor([[2.0], [4.0], [6.0], [8.0]])

# ëª¨ë¸ ì •ì˜
model = nn.Linear(1, 1)

# ì†ì‹¤ í•¨ìˆ˜ì™€ ì˜µí‹°ë§ˆì´ì €
criterion = nn.MSELoss()
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# í•™ìŠµ ë£¨í”„
for epoch in range(100):
    # ìˆœì „íŒŒ
    predictions = model(x)
    loss = criterion(predictions, y)
    
    # ì—­ì „íŒŒ
    optimizer.zero_grad()  # ê¸°ìš¸ê¸° ì´ˆê¸°í™”
    loss.backward()        # ì—­ì „íŒŒ
    optimizer.step()       # íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸
    
    if epoch % 20 == 0:
        print(f'Epoch {epoch}, Loss: {loss.item():.4f}')

# í•™ìŠµëœ íŒŒë¼ë¯¸í„° í™•ì¸
print(f"Weight: {model.weight.item():.4f}")
print(f"Bias: {model.bias.item():.4f}")
"""
                    }
                ]
            }
        }
        
        self._load_knowledge_base()
    
    def _load_knowledge_base(self):
        """PyTorch ì§€ì‹ ë² ì´ìŠ¤ ë¡œë“œ"""
        if self.knowledge_base_path.exists():
            with open(self.knowledge_base_path, 'r', encoding='utf-8') as f:
                loaded_knowledge = json.load(f)
                self.pytorch_knowledge.update(loaded_knowledge)
    
    def _save_knowledge_base(self):
        """ì§€ì‹ ë² ì´ìŠ¤ ì €ì¥"""
        os.makedirs(self.knowledge_base_path.parent, exist_ok=True)
        with open(self.knowledge_base_path, 'w', encoding='utf-8') as f:
            json.dump(self.pytorch_knowledge, f, ensure_ascii=False, indent=2)
    
    async def start_tutorial_session(self):
        """ëŒ€í™”í˜• íŠœí† ë¦¬ì–¼ ì„¸ì…˜ ì‹œì‘"""
        print("\nğŸ”¥ PyTorch ëŒ€í™”í˜• í•™ìŠµ ì‹œìŠ¤í…œ")
        print("=" * 60)
        print("PyTorchì˜ ê¸°ì´ˆë¶€í„° ê³ ê¸‰ê¹Œì§€ ì°¨ê·¼ì°¨ê·¼ ë°°ì›Œë´…ì‹œë‹¤!")
        print("\nì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´:")
        print("  - 'ì£¼ì œ': í•™ìŠµ ì£¼ì œ ëª©ë¡ ë³´ê¸°")
        print("  - 'ì˜ˆì œ': í˜„ì¬ ì£¼ì œì˜ ì½”ë“œ ì˜ˆì œ ë³´ê¸°")
        print("  - 'ì‹¤í–‰': ì½”ë“œ ì˜ˆì œ ì‹¤í–‰í•˜ê¸°")
        print("  - 'ì§ˆë¬¸': í˜„ì¬ ì£¼ì œì— ëŒ€í•´ ì§ˆë¬¸í•˜ê¸°")
        print("  - 'ë‹¤ìŒ': ë‹¤ìŒ ì£¼ì œë¡œ ì´ë™")
        print("  - 'ì§„ë„': í•™ìŠµ ì§„í–‰ë¥  í™•ì¸")
        print("  - 'ì¢…ë£Œ': í•™ìŠµ ì¢…ë£Œ")
        print("=" * 60)
        
        await self._show_topics()
        
        while True:
            user_input = input("\nğŸ’­ ë¬´ì—‡ì„ ë°°ìš°ê³  ì‹¶ìœ¼ì‹ ê°€ìš”? > ").strip()
            
            if user_input.lower() in ['ì¢…ë£Œ', 'exit', 'quit']:
                print("\nğŸ‘‹ í•™ìŠµì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ë‹¤ìŒì— ë˜ ë§Œë‚˜ìš”!")
                break
            
            await self._process_user_input(user_input)
    
    async def _show_topics(self):
        """í•™ìŠµ ì£¼ì œ ëª©ë¡ í‘œì‹œ"""
        print("\nğŸ“š í•™ìŠµ ì£¼ì œ:")
        for key, topic in self.topics.items():
            print(f"\n[{key}] {topic['title']}")
            for i, subtopic in enumerate(topic['subtopics'], 1):
                progress = self.tutorial_progress.get(subtopic, 0)
                status = "âœ…" if progress >= 100 else f"ğŸ“Š {progress}%"
                print(f"  {i}. {subtopic} {status}")
    
    async def _process_user_input(self, user_input: str):
        """ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬"""
        input_lower = user_input.lower()
        
        if input_lower == 'ì£¼ì œ':
            await self._show_topics()
        
        elif input_lower == 'ì˜ˆì œ' and self.current_topic:
            await self._show_examples(self.current_topic)
        
        elif input_lower == 'ì‹¤í–‰' and self.current_topic:
            await self._run_example(self.current_topic)
        
        elif input_lower == 'ì§ˆë¬¸':
            await self._answer_question()
        
        elif input_lower == 'ë‹¤ìŒ':
            await self._next_topic()
        
        elif input_lower == 'ì§„ë„':
            await self._show_progress()
        
        else:
            # ì£¼ì œ ì„ íƒ ë˜ëŠ” ììœ  ì§ˆë¬¸
            await self._handle_topic_or_question(user_input)
    
    async def _show_examples(self, topic: str):
        """í˜„ì¬ ì£¼ì œì˜ ì˜ˆì œ í‘œì‹œ"""
        if topic in self.pytorch_knowledge:
            knowledge = self.pytorch_knowledge[topic]
            print(f"\nğŸ“– {topic} - ì„¤ëª…:")
            print(knowledge['explanation'])
            
            if 'code_examples' in knowledge:
                print("\nğŸ’» ì½”ë“œ ì˜ˆì œ:")
                for i, example in enumerate(knowledge['code_examples'], 1):
                    print(f"\n[ì˜ˆì œ {i}] {example['title']}")
                    print("-" * 40)
                    print(example['code'])
    
    async def _run_example(self, topic: str):
        """ì˜ˆì œ ì½”ë“œ ì‹¤í–‰"""
        if topic in self.pytorch_knowledge and 'code_examples' in self.pytorch_knowledge[topic]:
            examples = self.pytorch_knowledge[topic]['code_examples']
            
            print("\nğŸƒ ì–´ë–¤ ì˜ˆì œë¥¼ ì‹¤í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
            for i, example in enumerate(examples, 1):
                print(f"  {i}. {example['title']}")
            
            try:
                choice = int(input("\në²ˆí˜¸ ì„ íƒ: ")) - 1
                if 0 <= choice < len(examples):
                    example = examples[choice]
                    print(f"\nâ–¶ï¸ '{example['title']}' ì‹¤í–‰ ì¤‘...")
                    print("-" * 40)
                    
                    # ì‹¤ì œë¡œëŠ” ì—¬ê¸°ì„œ ì½”ë“œë¥¼ ì•ˆì „í•˜ê²Œ ì‹¤í–‰í•˜ëŠ” ë¡œì§ í•„ìš”
                    # exec() ì‚¬ìš©ì€ ë³´ì•ˆìƒ ìœ„í—˜í•˜ë¯€ë¡œ ì‹¤ì œ êµ¬í˜„ ì‹œ ì£¼ì˜
                    print("âš ï¸  ì½”ë“œ ì‹¤í–‰ ê²°ê³¼:")
                    print("(ì‹¤ì œ ì‹¤í–‰ì€ ë³´ì•ˆì„ ìœ„í•´ ì‹œë®¬ë ˆì´ì…˜ë©ë‹ˆë‹¤)")
                    print("\n[ì½”ë“œê°€ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤]")
                    
                    # ì§„ë„ ì—…ë°ì´íŠ¸
                    self.tutorial_progress[topic] = min(
                        self.tutorial_progress.get(topic, 0) + 25, 100
                    )
            except ValueError:
                print("âŒ ì˜¬ë°”ë¥¸ ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    async def _answer_question(self):
        """í˜„ì¬ ì£¼ì œì— ëŒ€í•œ ì§ˆë¬¸ ë‹µë³€"""
        if not self.current_topic:
            print("â“ ë¨¼ì € í•™ìŠµí•  ì£¼ì œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
            return
        
        question = input(f"\nğŸ¤” {self.current_topic}ì— ëŒ€í•´ ë¬´ì—‡ì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”? > ")
        
        # AI ëª¨ë¸ì´ ìˆë‹¤ë©´ í™œìš©, ì—†ë‹¤ë©´ ê¸°ë³¸ ë‹µë³€
        if self.ai_model:
            context = self.pytorch_knowledge.get(self.current_topic, {})
            response = await self._generate_ai_response(question, context)
            print(f"\nğŸ¤– ë‹µë³€: {response}")
        else:
            print(f"\nğŸ¤– {self.current_topic}ì— ëŒ€í•œ ì¼ë°˜ì ì¸ ë‹µë³€ì…ë‹ˆë‹¤.")
            print("ë” ìì„¸í•œ ë‹µë³€ì„ ì›í•˜ì‹œë©´ AI ëª¨ë¸ì„ ì—°ê²°í•´ì£¼ì„¸ìš”.")
    
    async def _generate_ai_response(self, question: str, context: Dict) -> str:
        """AIë¥¼ í™œìš©í•œ ë‹µë³€ ìƒì„±"""
        prompt = f"""
        ì£¼ì œ: {self.current_topic}
        ì§ˆë¬¸: {question}
        
        ê´€ë ¨ ì§€ì‹:
        {json.dumps(context, ensure_ascii=False, indent=2)}
        
        ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´ˆë³´ìë„ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
        ì½”ë“œ ì˜ˆì œê°€ í•„ìš”í•˜ë‹¤ë©´ ê°„ë‹¨í•œ ì˜ˆì œë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”.
        """
        
        # AI ëª¨ë¸ í˜¸ì¶œ (ì‹¤ì œ êµ¬í˜„ í•„ìš”)
        return "AI ë‹µë³€ì´ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤."
    
    async def _next_topic(self):
        """ë‹¤ìŒ ì£¼ì œë¡œ ì´ë™"""
        all_subtopics = []
        for topic in self.topics.values():
            all_subtopics.extend(topic['subtopics'])
        
        if self.current_topic in all_subtopics:
            current_index = all_subtopics.index(self.current_topic)
            if current_index < len(all_subtopics) - 1:
                self.current_topic = all_subtopics[current_index + 1]
                print(f"\nâ¡ï¸ ë‹¤ìŒ ì£¼ì œ: {self.current_topic}")
                await self._show_examples(self.current_topic)
            else:
                print("\nğŸ‰ ëª¨ë“  ì£¼ì œë¥¼ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤!")
    
    async def _show_progress(self):
        """í•™ìŠµ ì§„í–‰ë¥  í‘œì‹œ"""
        print("\nğŸ“Š í•™ìŠµ ì§„í–‰ë¥ :")
        total_topics = sum(len(topic['subtopics']) for topic in self.topics.values())
        completed = sum(1 for progress in self.tutorial_progress.values() if progress >= 100)
        
        print(f"ì „ì²´ ì§„í–‰ë¥ : {completed}/{total_topics} ({completed/total_topics*100:.1f}%)")
        print("\nì„¸ë¶€ ì§„í–‰ë¥ :")
        
        for key, topic in self.topics.items():
            topic_completed = sum(
                1 for subtopic in topic['subtopics'] 
                if self.tutorial_progress.get(subtopic, 0) >= 100
            )
            print(f"  {topic['title']}: {topic_completed}/{len(topic['subtopics'])}")
    
    async def _handle_topic_or_question(self, user_input: str):
        """ì£¼ì œ ì„ íƒ ë˜ëŠ” ììœ  ì§ˆë¬¸ ì²˜ë¦¬"""
        # ìˆ«ìë¡œ ì£¼ì œ ì„ íƒ
        try:
            topic_num = int(user_input)
            all_subtopics = []
            for topic in self.topics.values():
                all_subtopics.extend(topic['subtopics'])
            
            if 1 <= topic_num <= len(all_subtopics):
                self.current_topic = all_subtopics[topic_num - 1]
                print(f"\nâœ… '{self.current_topic}' ì£¼ì œë¥¼ ì„ íƒí–ˆìŠµë‹ˆë‹¤.")
                await self._show_examples(self.current_topic)
                return
        except ValueError:
            pass
        
        # í‚¤ì›Œë“œë¡œ ì£¼ì œ ê²€ìƒ‰
        for key, topic in self.topics.items():
            if key in user_input.lower() or topic['title'] in user_input:
                print(f"\nğŸ“š {topic['title']} ê´€ë ¨ ì£¼ì œ:")
                for i, subtopic in enumerate(topic['subtopics'], 1):
                    print(f"  {i}. {subtopic}")
                return
        
        # ììœ  ì§ˆë¬¸ìœ¼ë¡œ ì²˜ë¦¬
        print(f"\nğŸ¤” '{user_input}'ì— ëŒ€í•´ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.")
        if self.ai_model:
            response = await self._generate_ai_response(user_input, self.pytorch_knowledge)
            print(f"\nğŸ¤– ë‹µë³€: {response}")
        else:
            print("AI ëª¨ë¸ì´ ì—°ê²°ë˜ì§€ ì•Šì•„ ê¸°ë³¸ ë‹µë³€ë§Œ ì œê³µë©ë‹ˆë‹¤.")
            print("'ì£¼ì œ'ë¥¼ ì…ë ¥í•˜ì—¬ í•™ìŠµ ì£¼ì œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
    
    def add_custom_knowledge(self, topic: str, knowledge: Dict):
        """ì»¤ìŠ¤í…€ ì§€ì‹ ì¶”ê°€"""
        self.pytorch_knowledge[topic] = knowledge
        self._save_knowledge_base()
        print(f"âœ… '{topic}' ì§€ì‹ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")