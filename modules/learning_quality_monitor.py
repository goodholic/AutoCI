#!/usr/bin/env python3
"""
í•™ìŠµ í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ
ê³¼ì í•© ë°©ì§€, í•™ìŠµ ì§„í–‰ ì¶”ì , í’ˆì§ˆ í‰ê°€ë¥¼ ë‹´ë‹¹
"""

import os
import json
import time
import numpy as np
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from datetime import datetime, timedelta
from dataclasses import dataclass, asdict
import logging
try:
    import matplotlib
    matplotlib.use('Agg')  # ë¹„ëŒ€í™”í˜• ë°±ì—”ë“œ ì‚¬ìš©
    import matplotlib.pyplot as plt
    MATPLOTLIB_AVAILABLE = True
except ImportError:
    MATPLOTLIB_AVAILABLE = False
    import logging
    logging.getLogger(__name__).warning("Matplotlibì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í”Œë¡¯ ìƒì„±ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
from collections import deque

logger = logging.getLogger(__name__)

@dataclass
class LearningMetrics:
    """í•™ìŠµ ë©”íŠ¸ë¦­ ë°ì´í„°"""
    timestamp: str
    epoch: int
    iteration: int
    train_loss: float
    validation_loss: Optional[float] = None
    learning_rate: float = 0.0
    quality_score: float = 0.0
    overfitting_score: float = 0.0  # 0-1, ë†’ì„ìˆ˜ë¡ ê³¼ì í•©
    
    def to_dict(self) -> Dict:
        return asdict(self)

class LearningQualityMonitor:
    """í•™ìŠµ í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ ë° ê³¼ì í•© ë°©ì§€ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.project_root = Path(__file__).parent.parent
        self.monitor_dir = self.project_root / "continuous_learning" / "monitoring"
        self.monitor_dir.mkdir(parents=True, exist_ok=True)
        
        # ë©”íŠ¸ë¦­ ì €ì¥ ê²½ë¡œ
        self.metrics_file = self.monitor_dir / "learning_metrics.jsonl"
        self.plots_dir = self.monitor_dir / "plots"
        self.plots_dir.mkdir(exist_ok=True)
        
        # ê³¼ì í•© ê°ì§€ ì„¤ì •
        self.overfitting_threshold = 0.1  # validation_lossê°€ train_lossë³´ë‹¤ 10% ì´ìƒ ë†’ìœ¼ë©´ ê²½ê³ 
        self.early_stopping_patience = 5  # validation_lossê°€ 5ë²ˆ ì—°ì† ì¦ê°€í•˜ë©´ ì¤‘ë‹¨
        self.min_delta = 0.001  # ìµœì†Œ ê°œì„  í­
        
        # ë©”íŠ¸ë¦­ íˆìŠ¤í† ë¦¬
        self.train_loss_history = deque(maxlen=100)
        self.val_loss_history = deque(maxlen=100)
        self.quality_score_history = deque(maxlen=100)
        
        # ì¡°ê¸° ì¢…ë£Œ ê´€ë ¨
        self.best_val_loss = float('inf')
        self.patience_counter = 0
        self.should_stop = False
        
        # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •
        self.initial_learning_rate = 2e-5
        self.min_learning_rate = 1e-6
        self.lr_decay_factor = 0.95
        
        # í’ˆì§ˆ í‰ê°€ ê¸°ì¤€
        self.quality_criteria = {
            "coherence": 0.3,      # ì‘ë‹µì˜ ì¼ê´€ì„±
            "relevance": 0.3,      # ì§ˆë¬¸ê³¼ì˜ ê´€ë ¨ì„±
            "completeness": 0.2,   # ë‹µë³€ì˜ ì™„ì„±ë„
            "accuracy": 0.2        # ê¸°ìˆ ì  ì •í™•ì„±
        }
        
        # ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ìƒíƒœ
        self.monitoring_active = False
        self.start_time = None
        self.total_iterations = 0
        
    def start_monitoring(self, model_name: str, dataset_size: int):
        """ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        self.monitoring_active = True
        self.start_time = datetime.now()
        self.total_iterations = 0
        self.should_stop = False
        
        # ëª¨ë‹ˆí„°ë§ ì„¸ì…˜ ì •ë³´ ì €ì¥
        session_info = {
            "session_id": datetime.now().strftime("%Y%m%d_%H%M%S"),
            "model_name": model_name,
            "dataset_size": dataset_size,
            "start_time": self.start_time.isoformat(),
            "initial_learning_rate": self.initial_learning_rate,
            "overfitting_threshold": self.overfitting_threshold
        }
        
        session_file = self.monitor_dir / "current_session.json"
        with open(session_file, 'w', encoding='utf-8') as f:
            json.dump(session_info, f, indent=2)
        
        logger.info(f"í•™ìŠµ ëª¨ë‹ˆí„°ë§ ì‹œì‘: {model_name} (ë°ì´í„°ì…‹ í¬ê¸°: {dataset_size})")
    
    def update_metrics(self, epoch: int, iteration: int, 
                      train_loss: float, validation_loss: Optional[float] = None,
                      learning_rate: Optional[float] = None) -> LearningMetrics:
        """ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸ ë° ê³¼ì í•© ì²´í¬"""
        self.total_iterations += 1
        
        # í˜„ì¬ í•™ìŠµë¥  (ì œê³µë˜ì§€ ì•Šìœ¼ë©´ ê³„ì‚°)
        if learning_rate is None:
            learning_rate = self.calculate_learning_rate(epoch)
        
        # ê³¼ì í•© ì ìˆ˜ ê³„ì‚°
        overfitting_score = 0.0
        if validation_loss is not None:
            overfitting_score = self.calculate_overfitting_score(train_loss, validation_loss)
            
            # ì¡°ê¸° ì¢…ë£Œ ì²´í¬
            self.check_early_stopping(validation_loss)
        
        # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
        quality_score = self.estimate_quality_score(train_loss, validation_loss)
        
        # ë©”íŠ¸ë¦­ ìƒì„±
        metrics = LearningMetrics(
            timestamp=datetime.now().isoformat(),
            epoch=epoch,
            iteration=iteration,
            train_loss=train_loss,
            validation_loss=validation_loss,
            learning_rate=learning_rate,
            quality_score=quality_score,
            overfitting_score=overfitting_score
        )
        
        # íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
        self.train_loss_history.append(train_loss)
        if validation_loss is not None:
            self.val_loss_history.append(validation_loss)
        self.quality_score_history.append(quality_score)
        
        # ë©”íŠ¸ë¦­ ì €ì¥
        with open(self.metrics_file, 'a', encoding='utf-8') as f:
            f.write(json.dumps(metrics.to_dict()) + '\n')
        
        # ì£¼ê¸°ì ìœ¼ë¡œ í”Œë¡¯ ìƒì„± (100 iterationsë§ˆë‹¤)
        if self.total_iterations % 100 == 0:
            self.generate_plots()
        
        # ê²½ê³  ë° ê¶Œì¥ì‚¬í•­ ì¶œë ¥
        self.print_recommendations(metrics)
        
        return metrics
    
    def calculate_overfitting_score(self, train_loss: float, val_loss: float) -> float:
        """ê³¼ì í•© ì ìˆ˜ ê³„ì‚° (0-1)"""
        if train_loss == 0:
            return 0.0
        
        # validation lossê°€ train lossë³´ë‹¤ ì–¼ë§ˆë‚˜ ë†’ì€ì§€
        gap_ratio = (val_loss - train_loss) / train_loss
        
        # 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”
        overfitting_score = max(0.0, min(1.0, gap_ratio))
        
        return overfitting_score
    
    def check_early_stopping(self, val_loss: float) -> bool:
        """ì¡°ê¸° ì¢…ë£Œ ì²´í¬"""
        if val_loss < self.best_val_loss - self.min_delta:
            # ê°œì„ ë¨
            self.best_val_loss = val_loss
            self.patience_counter = 0
        else:
            # ê°œì„  ì•ˆë¨
            self.patience_counter += 1
            
            if self.patience_counter >= self.early_stopping_patience:
                self.should_stop = True
                logger.warning(f"ì¡°ê¸° ì¢…ë£Œ íŠ¸ë¦¬ê±°ë¨! Validation lossê°€ {self.patience_counter}ë²ˆ ì—°ì† ê°œì„ ë˜ì§€ ì•ŠìŒ")
                return True
        
        return False
    
    def calculate_learning_rate(self, epoch: int) -> float:
        """ì—í¬í¬ì— ë”°ë¥¸ í•™ìŠµë¥  ê³„ì‚° (ê°ì‡  ì ìš©)"""
        lr = self.initial_learning_rate * (self.lr_decay_factor ** epoch)
        return max(lr, self.min_learning_rate)
    
    def estimate_quality_score(self, train_loss: float, val_loss: Optional[float]) -> float:
        """í•™ìŠµ í’ˆì§ˆ ì ìˆ˜ ì¶”ì • (0-1)"""
        # ë‹¨ìˆœ íœ´ë¦¬ìŠ¤í‹±: lossê°€ ë‚®ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜
        base_score = 1.0 / (1.0 + train_loss)
        
        # validation lossê°€ ìˆìœ¼ë©´ ê³¼ì í•© í˜ë„í‹° ì ìš©
        if val_loss is not None:
            overfitting_penalty = max(0, (val_loss - train_loss) / (train_loss + 1e-8))
            base_score *= (1.0 - min(overfitting_penalty, 0.5))
        
        return min(1.0, base_score)
    
    def print_recommendations(self, metrics: LearningMetrics):
        """í•™ìŠµ ìƒíƒœì— ë”°ë¥¸ ê¶Œì¥ì‚¬í•­ ì¶œë ¥"""
        recommendations = []
        
        # ê³¼ì í•© ê²½ê³ 
        if metrics.overfitting_score > 0.3:
            recommendations.append("âš ï¸ ê³¼ì í•© ì§•í›„ ê°ì§€! ë‹¤ìŒì„ ê¶Œì¥í•©ë‹ˆë‹¤:")
            recommendations.append("  - í•™ìŠµë¥  ê°ì†Œ (í˜„ì¬: {:.2e})".format(metrics.learning_rate))
            recommendations.append("  - ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨ ì¦ê°€")
            recommendations.append("  - ë°ì´í„° ì¦ê°• ì ìš©")
            recommendations.append("  - ì •ê·œí™” ê°•í™”")
        
        # í•™ìŠµ ì •ì²´ ê²½ê³ 
        if len(self.train_loss_history) > 10:
            recent_losses = list(self.train_loss_history)[-10:]
            loss_variance = np.var(recent_losses)
            if loss_variance < 0.0001:
                recommendations.append("âš ï¸ í•™ìŠµì´ ì •ì²´ë˜ì—ˆìŠµë‹ˆë‹¤! ë‹¤ìŒì„ ì‹œë„í•˜ì„¸ìš”:")
                recommendations.append("  - í•™ìŠµë¥  ì¡°ì •")
                recommendations.append("  - ë‹¤ë¥¸ ì˜µí‹°ë§ˆì´ì € ì‹œë„")
                recommendations.append("  - ë°°ì¹˜ í¬ê¸° ë³€ê²½")
        
        # ì¡°ê¸° ì¢…ë£Œ ê²½ê³ 
        if self.should_stop:
            recommendations.append("ğŸ›‘ ì¡°ê¸° ì¢…ë£Œë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤! ë” ì´ìƒì˜ í•™ìŠµì€ ê³¼ì í•©ì„ ìœ ë°œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        # ê¶Œì¥ì‚¬í•­ ì¶œë ¥
        if recommendations:
            logger.warning("\n".join(recommendations))
    
    def generate_plots(self):
        """í•™ìŠµ ì§„í–‰ ìƒí™© í”Œë¡¯ ìƒì„±"""
        if not MATPLOTLIB_AVAILABLE:
            logger.warning("Matplotlibì´ ì—†ì–´ í”Œë¡¯ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return
            
        if len(self.train_loss_history) < 2:
            return
        
        plt.style.use('default')
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))
        
        # 1. Loss ê³¡ì„ 
        ax1 = axes[0, 0]
        iterations = range(len(self.train_loss_history))
        ax1.plot(iterations, self.train_loss_history, 'b-', label='Train Loss', alpha=0.7)
        if self.val_loss_history:
            val_iterations = range(len(self.val_loss_history))
            ax1.plot(val_iterations, self.val_loss_history, 'r-', label='Validation Loss', alpha=0.7)
        ax1.set_xlabel('Iterations')
        ax1.set_ylabel('Loss')
        ax1.set_title('Training Progress')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # 2. í’ˆì§ˆ ì ìˆ˜ ì¶”ì´
        ax2 = axes[0, 1]
        quality_iterations = range(len(self.quality_score_history))
        ax2.plot(quality_iterations, self.quality_score_history, 'g-', alpha=0.7)
        ax2.set_xlabel('Iterations')
        ax2.set_ylabel('Quality Score')
        ax2.set_title('Learning Quality')
        ax2.set_ylim(0, 1)
        ax2.grid(True, alpha=0.3)
        
        # 3. ê³¼ì í•© ë¶„ì„
        if self.val_loss_history and len(self.val_loss_history) > 0:
            ax3 = axes[1, 0]
            train_losses = list(self.train_loss_history)[:len(self.val_loss_history)]
            val_losses = list(self.val_loss_history)
            
            if train_losses and val_losses:
                overfitting_scores = [
                    self.calculate_overfitting_score(t, v) 
                    for t, v in zip(train_losses, val_losses)
                ]
                ax3.plot(range(len(overfitting_scores)), overfitting_scores, 'r-', alpha=0.7)
                ax3.axhline(y=0.3, color='r', linestyle='--', label='Warning Threshold')
                ax3.set_xlabel('Iterations')
                ax3.set_ylabel('Overfitting Score')
                ax3.set_title('Overfitting Detection')
                ax3.set_ylim(0, 1)
                ax3.legend()
                ax3.grid(True, alpha=0.3)
        
        # 4. í•™ìŠµ ì‹œê°„ ë° ì†ë„
        ax4 = axes[1, 1]
        if self.start_time:
            elapsed_time = (datetime.now() - self.start_time).total_seconds() / 3600  # hours
            speed = self.total_iterations / (elapsed_time + 1e-8)  # iterations per hour
            
            info_text = f"""í•™ìŠµ ì •ë³´:
ì´ ë°˜ë³µ: {self.total_iterations}
ê²½ê³¼ ì‹œê°„: {elapsed_time:.2f} ì‹œê°„
í•™ìŠµ ì†ë„: {speed:.1f} iterations/hour
í˜„ì¬ Train Loss: {self.train_loss_history[-1]:.4f}
"""
            if self.val_loss_history:
                info_text += f"í˜„ì¬ Val Loss: {self.val_loss_history[-1]:.4f}\n"
                info_text += f"ê³¼ì í•© ì ìˆ˜: {overfitting_scores[-1]:.3f}" if 'overfitting_scores' in locals() else ""
            
            ax4.text(0.1, 0.5, info_text, transform=ax4.transAxes, 
                    fontsize=12, verticalalignment='center')
            ax4.axis('off')
        
        # í”Œë¡¯ ì €ì¥
        plot_file = self.plots_dir / f"learning_progress_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
        plt.tight_layout()
        plt.savefig(plot_file, dpi=150, bbox_inches='tight')
        plt.close()
        
        # ìµœì‹  í”Œë¡¯ìœ¼ë¡œ ì‹¬ë³¼ë¦­ ë§í¬ ìƒì„± (Linux/WSL only)
        latest_plot = self.plots_dir / "latest_progress.png"
        if latest_plot.exists():
            latest_plot.unlink()
        try:
            latest_plot.symlink_to(plot_file.name)
        except:
            # Windowsì—ì„œëŠ” ë³µì‚¬
            import shutil
            shutil.copy(plot_file, latest_plot)
    
    def get_learning_summary(self) -> Dict[str, Any]:
        """í•™ìŠµ ìš”ì•½ ì •ë³´ ë°˜í™˜"""
        summary = {
            "total_iterations": self.total_iterations,
            "should_stop": self.should_stop,
            "current_train_loss": self.train_loss_history[-1] if self.train_loss_history else None,
            "current_val_loss": self.val_loss_history[-1] if self.val_loss_history else None,
            "best_val_loss": self.best_val_loss if self.best_val_loss < float('inf') else None,
            "average_quality_score": np.mean(self.quality_score_history) if self.quality_score_history else 0,
            "overfitting_detected": any(s > 0.3 for s in self.quality_score_history[-10:]) if len(self.quality_score_history) > 10 else False,
            "elapsed_time": str(datetime.now() - self.start_time) if self.start_time else "0:00:00"
        }
        
        return summary
    
    def export_report(self) -> Path:
        """í•™ìŠµ ë³´ê³ ì„œ ìƒì„±"""
        report_path = self.monitor_dir / f"learning_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        # ì „ì²´ ë©”íŠ¸ë¦­ ë¡œë“œ
        all_metrics = []
        if self.metrics_file.exists():
            with open(self.metrics_file, 'r', encoding='utf-8') as f:
                for line in f:
                    try:
                        all_metrics.append(json.loads(line.strip()))
                    except:
                        continue
        
        # ë³´ê³ ì„œ ìƒì„±
        report = {
            "summary": self.get_learning_summary(),
            "metrics_count": len(all_metrics),
            "final_metrics": all_metrics[-1] if all_metrics else None,
            "best_metrics": min(all_metrics, key=lambda x: x.get('validation_loss', float('inf'))) if all_metrics else None,
            "recommendations": self.generate_final_recommendations()
        }
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        logger.info(f"í•™ìŠµ ë³´ê³ ì„œ ìƒì„±: {report_path}")
        return report_path
    
    def generate_final_recommendations(self) -> List[str]:
        """ìµœì¢… ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        summary = self.get_learning_summary()
        
        if summary["overfitting_detected"]:
            recommendations.append("ê³¼ì í•©ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ í•™ìŠµ ì‹œ ë°ì´í„° ì¦ê°•ê³¼ ì •ê·œí™”ë¥¼ ê°•í™”í•˜ì„¸ìš”.")
        
        if summary["should_stop"]:
            recommendations.append("ì¡°ê¸° ì¢…ë£Œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì •ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        avg_quality = summary["average_quality_score"]
        if avg_quality < 0.5:
            recommendations.append(f"í‰ê·  í’ˆì§ˆ ì ìˆ˜ê°€ ë‚®ìŠµë‹ˆë‹¤ ({avg_quality:.2f}). ë°ì´í„°ì…‹ í’ˆì§ˆì„ ê°œì„ í•˜ì„¸ìš”.")
        elif avg_quality > 0.8:
            recommendations.append(f"ìš°ìˆ˜í•œ í•™ìŠµ í’ˆì§ˆì„ ë³´ì˜€ìŠµë‹ˆë‹¤ ({avg_quality:.2f}). í˜„ì¬ ì„¤ì •ì„ ìœ ì§€í•˜ì„¸ìš”.")
        
        return recommendations

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_quality_monitor = None

def get_quality_monitor() -> LearningQualityMonitor:
    """í’ˆì§ˆ ëª¨ë‹ˆí„° ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _quality_monitor
    if _quality_monitor is None:
        _quality_monitor = LearningQualityMonitor()
    return _quality_monitor