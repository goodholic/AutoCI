#!/usr/bin/env python3
"""
ì‹¤ì‹œê°„ í•™ìŠµ í†µí•©ê¸° - ê°œë°œ ê²½í—˜ì„ AI í•™ìŠµ ë°ì´í„°ë¡œ ì‹¤ì‹œê°„ ë³€í™˜
ê°œë°œ ì¤‘ ìˆ˜ì§‘ëœ ëª¨ë“  ì„±ê³µì ì¸ ì†”ë£¨ì…˜, íŒ¨í„´, ìµœì í™”ë¥¼ AIì˜ ì˜êµ¬ì ì¸ ì§€ì‹ìœ¼ë¡œ í†µí•©í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
1. ê°œë°œ ê²½í—˜ì„ AI í•™ìŠµìš© Q&A ìŒìœ¼ë¡œ ë³€í™˜
2. ì„±ê³µì ì¸ ì†”ë£¨ì…˜ì—ì„œ ìë™ìœ¼ë¡œ í•™ìŠµ ë°ì´í„° ìƒì„±
3. ì‹¤ì‹œê°„ìœ¼ë¡œ ì§€ì‹ ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸
4. í•™ìŠµ ì‹œìŠ¤í…œê³¼ ì™„ë²½í•œ í†µí•©
5. ê²Œì„ ê°œë°œ ê²½í—˜ì„ ì „ë¬¸ ë°ì´í„°ì…‹ìœ¼ë¡œ êµ¬ì„±
"""

import os
import sys
import json
import asyncio
import hashlib
import logging
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime
from dataclasses import dataclass, asdict
from collections import defaultdict
import re

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@dataclass
class LearningData:
    """í•™ìŠµ ë°ì´í„° êµ¬ì¡°"""
    id: str
    category: str
    topic: str
    question: str
    answer: str
    keywords: List[str]
    difficulty: int
    source: str  # 'development', 'community', 'ai_discovery'
    effectiveness: float
    metadata: Dict[str, Any]
    timestamp: str

@dataclass
class QAPair:
    """ì§ˆë¬¸-ë‹µë³€ ìŒ"""
    question_id: str
    question_text: str
    question_type: str
    answer_text: str
    quality_score: float
    source_experience: str
    generated_at: str

class RealtimeLearningIntegrator:
    """ì‹¤ì‹œê°„ í•™ìŠµ í†µí•©ê¸°"""
    
    def __init__(self):
        self.project_root = Path(__file__).parent.parent
        self.learning_base_path = self.project_root / "continuous_learning"
        self.integration_path = self.learning_base_path / "realtime_integration"
        self.integration_path.mkdir(parents=True, exist_ok=True)
        
        # í†µí•© ìƒíƒœ
        self.integration_stats = {
            'total_experiences_converted': 0,
            'qa_pairs_generated': 0,
            'knowledge_updates': 0,
            'training_datasets_created': 0,
            'last_integration': None
        }
        
        # ë³€í™˜ ê·œì¹™
        self.conversion_rules = self._load_conversion_rules()
        
        # ì¹´í…Œê³ ë¦¬ ë§¤í•‘ (ê°œë°œ ê²½í—˜ -> í•™ìŠµ ì£¼ì œ)
        self.category_mapping = {
            'error_solution': 'core_csharp_basics',
            'game_mechanic': 'core_godot_architecture',
            'code_pattern': 'core_csharp_advanced',
            'performance_opt': 'core_godot_ai_network',
            'resource_generation': 'core_godot_architecture',
            'community_solution': 'core_korean_concepts',
            'ai_discovery': 'core_nakama_ai',
            'networking': 'core_godot_networking',
            'nakama_integration': 'core_nakama_basics'
        }
        
        # í•™ìŠµ ì‹œìŠ¤í…œ ì—°ê²°
        self.continuous_learning_system = None
        self.experience_collector = None
        self.ai_model_controller = None
        
        # ì‹¤ì‹œê°„ í
        self.experience_queue = asyncio.Queue(maxsize=1000)
        self.processing_active = False
        
        # í†µí•© ë¡œê·¸
        self.integration_log = []
        
        # ê¸°ì¡´ í†µí•© ìƒíƒœ ë¡œë“œ
        self._load_integration_state()
    
    def _load_conversion_rules(self) -> Dict[str, Any]:
        """ê²½í—˜ íƒ€ì…ë³„ ë³€í™˜ ê·œì¹™ ë¡œë“œ"""
        return {
            'error_solution': {
                'question_templates': [
                    "C#ì—ì„œ {error_type} ì˜¤ë¥˜ê°€ ë°œìƒí•  ë•Œ ì–´ë–»ê²Œ í•´ê²°í•˜ë‚˜ìš”?",
                    "{error_description}ê°€ ë°œìƒí•˜ëŠ” ì´ìœ ì™€ í•´ê²° ë°©ë²•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
                    "Godotì—ì„œ {error_context} ê´€ë ¨ ì˜¤ë¥˜ë¥¼ í•´ê²°í•˜ëŠ” ë°©ë²•ì€?"
                ],
                'answer_format': "ì˜¤ë¥˜: {error_description}\n\ní•´ê²° ë°©ë²•:\n{solution_steps}\n\nì½”ë“œ ì˜ˆì œ:\n```csharp\n{code_example}\n```\n\nì„¤ëª…: {explanation}",
                'difficulty_calculator': lambda exp: min(5, 2 + exp.get('attempts', 1) // 3)
            },
            'game_mechanic': {
                'question_templates': [
                    "Godotì—ì„œ {mechanic_name} ê¸°ëŠ¥ì„ êµ¬í˜„í•˜ëŠ” ë°©ë²•ì€?",
                    "{mechanic_name}ì„ C#ìœ¼ë¡œ êµ¬í˜„í•˜ëŠ” ìµœì„ ì˜ ë°©ë²•ì„ ë³´ì—¬ì£¼ì„¸ìš”.",
                    "ê²Œì„ì—ì„œ {mechanic_description}ì„ ë§Œë“¤ë ¤ë©´ ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?"
                ],
                'answer_format': "êµ¬í˜„ ë°©ë²•:\n\n1. ê°œë… ì„¤ëª…:\n{description}\n\n2. ì½”ë“œ êµ¬í˜„:\n```csharp\n{code_snippet}\n```\n\n3. ì‚¬ìš© ì˜ˆì‹œ:\n{usage_example}\n\n4. ì„±ëŠ¥ ê³ ë ¤ì‚¬í•­:\n{performance_notes}",
                'difficulty_calculator': lambda exp: min(5, 3 + exp.get('complexity', 0) // 20)
            },
            'code_pattern': {
                'question_templates': [
                    "C#ì—ì„œ {pattern_name} íŒ¨í„´ì„ ì–´ë–»ê²Œ í™œìš©í•˜ë‚˜ìš”?",
                    "{use_case}ì— ì í•©í•œ ì½”ë“œ íŒ¨í„´ì„ ë³´ì—¬ì£¼ì„¸ìš”.",
                    "Godot í”„ë¡œì íŠ¸ì—ì„œ {pattern_name}ì„ ì‚¬ìš©í•˜ëŠ” ëª¨ë²” ì‚¬ë¡€ëŠ”?"
                ],
                'answer_format': "íŒ¨í„´ ì´ë¦„: {pattern_name}\n\nì‚¬ìš© ì‚¬ë¡€: {use_case}\n\nêµ¬í˜„:\n```csharp\n{code}\n```\n\nì¥ì :\n- íš¨ê³¼ì„±: {effectiveness}\n- ì ìš© íšŸìˆ˜: {applications}íšŒ\n\nì£¼ì˜ì‚¬í•­: {considerations}",
                'difficulty_calculator': lambda exp: 4  # íŒ¨í„´ì€ ë³´í†µ ê³ ê¸‰
            },
            'performance_opt': {
                'question_templates': [
                    "Godotì—ì„œ {optimization_type} ì„±ëŠ¥ì„ ìµœì í™”í•˜ëŠ” ë°©ë²•ì€?",
                    "{before_metrics}ì—ì„œ {after_metrics}ë¡œ ê°œì„ í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
                    "ê²Œì„ ì„±ëŠ¥ì„ {improvement}% í–¥ìƒì‹œí‚¤ëŠ” ìµœì í™” ê¸°ë²•ì€?"
                ],
                'answer_format': "ìµœì í™” ë°©ë²•: {method}\n\nì´ì „ ì„±ëŠ¥:\n{before_metrics}\n\nì´í›„ ì„±ëŠ¥:\n{after_metrics}\n\nê°œì„ ìœ¨: {improvement}%\n\nì½”ë“œ ë³€ê²½ì‚¬í•­:\n```csharp\n{code_changes}\n```\n\ní•µì‹¬ í¬ì¸íŠ¸: {key_points}",
                'difficulty_calculator': lambda exp: min(5, 3 + int(exp.get('improvement', 0) / 20))
            },
            'ai_discovery': {
                'question_templates': [
                    "{discovery_type}ì— ëŒ€í•œ í˜ì‹ ì ì¸ ì ‘ê·¼ ë°©ë²•ì€?",
                    "AIê°€ ë°œê²¬í•œ {description}ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
                    "{context}ì—ì„œ ì°½ì˜ì ì¸ í•´ê²°ì±…ì€ ë¬´ì—‡ì¸ê°€ìš”?"
                ],
                'answer_format': "AI ë°œê²¬: {discovery_type}\n\nì„¤ëª…:\n{description}\n\nêµ¬í˜„ ì½”ë“œ:\n```csharp\n{code}\n```\n\në§¥ë½: {context}\n\nì°½ì˜ì„± ì ìˆ˜: {creativity_score}/10\níš¨ê³¼ì„±: {effectiveness}",
                'difficulty_calculator': lambda exp: min(5, 4 + exp.get('creativity_score', 0) // 3)
            }
        }
    
    def _load_integration_state(self):
        """í†µí•© ìƒíƒœ ë¡œë“œ"""
        state_file = self.integration_path / "integration_state.json"
        if state_file.exists():
            try:
                with open(state_file, 'r', encoding='utf-8') as f:
                    self.integration_stats = json.load(f)
                logger.info(f"í†µí•© ìƒíƒœ ë¡œë“œ: {self.integration_stats['qa_pairs_generated']}ê°œ Q&A ìŒ ìƒì„±ë¨")
            except Exception as e:
                logger.error(f"í†µí•© ìƒíƒœ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def _save_integration_state(self):
        """í†µí•© ìƒíƒœ ì €ì¥"""
        state_file = self.integration_path / "integration_state.json"
        self.integration_stats['last_integration'] = datetime.now().isoformat()
        try:
            with open(state_file, 'w', encoding='utf-8') as f:
                json.dump(self.integration_stats, f, indent=2, ensure_ascii=False)
        except Exception as e:
            logger.error(f"í†µí•© ìƒíƒœ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    async def connect_systems(self, continuous_learning_system=None, experience_collector=None, ai_model_controller=None):
        """í•™ìŠµ ì‹œìŠ¤í…œë“¤ê³¼ ì—°ê²°"""
        if continuous_learning_system:
            self.continuous_learning_system = continuous_learning_system
            logger.info("âœ… ì—°ì† í•™ìŠµ ì‹œìŠ¤í…œê³¼ ì—°ê²°ë¨")
        
        if experience_collector:
            self.experience_collector = experience_collector
            logger.info("âœ… ê²½í—˜ ìˆ˜ì§‘ê¸°ì™€ ì—°ê²°ë¨")
            
            # ê¸°ì¡´ ê²½í—˜ ë°ì´í„° ë™ê¸°í™”
            await self._sync_existing_experiences()
        
        if ai_model_controller:
            self.ai_model_controller = ai_model_controller
            logger.info("âœ… AI ëª¨ë¸ ì»¨íŠ¸ë¡¤ëŸ¬ì™€ ì—°ê²°ë¨")
    
    async def _sync_existing_experiences(self):
        """ê¸°ì¡´ ìˆ˜ì§‘ëœ ê²½í—˜ ë™ê¸°í™”"""
        if not self.experience_collector:
            return
        
        logger.info("ê¸°ì¡´ ê²½í—˜ ë°ì´í„° ë™ê¸°í™” ì‹œì‘...")
        
        # ì˜¤ë¥˜ í•´ê²°ì±…
        for error_hash, solutions in self.experience_collector.error_solutions.items():
            for solution in solutions:
                if solution.get('success', False):
                    await self.convert_experience_to_learning_data('error_solution', solution)
        
        # ì„±ê³µì ì¸ ê²Œì„ ë©”ì¹´ë‹‰
        for mechanic in self.experience_collector.successful_mechanics:
            await self.convert_experience_to_learning_data('game_mechanic', mechanic)
        
        # ì½”ë“œ íŒ¨í„´
        for pattern_hash, pattern in self.experience_collector.code_patterns.items():
            if pattern.get('effectiveness', 0) > 0.7:
                await self.convert_experience_to_learning_data('code_pattern', pattern)
        
        # ì„±ëŠ¥ ìµœì í™”
        for optimization in self.experience_collector.performance_optimizations:
            if optimization.get('improvement', 0) > 10:  # 10% ì´ìƒ ê°œì„ 
                await self.convert_experience_to_learning_data('performance_opt', optimization)
        
        # AI ë°œê²¬
        for discovery in self.experience_collector.ai_discoveries:
            if discovery.get('effectiveness', 0) > 0.5:
                await self.convert_experience_to_learning_data('ai_discovery', discovery)
        
        logger.info(f"ë™ê¸°í™” ì™„ë£Œ: {self.integration_stats['total_experiences_converted']}ê°œ ê²½í—˜ ë³€í™˜ë¨")
    
    async def start_realtime_processing(self):
        """ì‹¤ì‹œê°„ ì²˜ë¦¬ ì‹œì‘"""
        self.processing_active = True
        logger.info("ğŸš€ ì‹¤ì‹œê°„ í•™ìŠµ í†µí•© ì‹œì‘")
        
        # ì²˜ë¦¬ íƒœìŠ¤í¬ ì‹œì‘
        asyncio.create_task(self._process_experience_queue())
        
        # ì£¼ê¸°ì  í†µí•© íƒœìŠ¤í¬
        asyncio.create_task(self._periodic_integration())
    
    async def stop_realtime_processing(self):
        """ì‹¤ì‹œê°„ ì²˜ë¦¬ ì¤‘ì§€"""
        self.processing_active = False
        
        # íì— ë‚¨ì€ ê²½í—˜ ì²˜ë¦¬
        while not self.experience_queue.empty():
            await asyncio.sleep(0.1)
        
        # ìµœì¢… í†µí•©
        await self._integrate_with_continuous_learning()
        
        # ìƒíƒœ ì €ì¥
        self._save_integration_state()
        
        logger.info("ğŸ›‘ ì‹¤ì‹œê°„ í•™ìŠµ í†µí•© ì¤‘ì§€")
    
    async def _process_experience_queue(self):
        """ê²½í—˜ í ì²˜ë¦¬"""
        while self.processing_active:
            try:
                # íì—ì„œ ê²½í—˜ ê°€ì ¸ì˜¤ê¸°
                experience_type, experience_data = await asyncio.wait_for(
                    self.experience_queue.get(), 
                    timeout=1.0
                )
                
                # í•™ìŠµ ë°ì´í„°ë¡œ ë³€í™˜
                learning_data = await self.convert_experience_to_learning_data(
                    experience_type, 
                    experience_data
                )
                
                if learning_data:
                    # Q&A ìŒ ìƒì„±
                    qa_pairs = await self.generate_qa_pairs(learning_data)
                    
                    # ì§€ì‹ ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸
                    await self.update_knowledge_base(learning_data)
                    
                    # í†µê³„ ì—…ë°ì´íŠ¸
                    self.integration_stats['total_experiences_converted'] += 1
                    self.integration_stats['qa_pairs_generated'] += len(qa_pairs)
                    
                    logger.info(f"âœ… ê²½í—˜ ë³€í™˜ ì™„ë£Œ: {experience_type} -> {len(qa_pairs)}ê°œ Q&A ìƒì„±")
                
            except asyncio.TimeoutError:
                continue
            except Exception as e:
                logger.error(f"ê²½í—˜ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
    
    async def convert_experience_to_learning_data(self, experience_type: str, experience_data: Dict[str, Any]) -> Optional[LearningData]:
        """ê°œë°œ ê²½í—˜ì„ í•™ìŠµ ë°ì´í„°ë¡œ ë³€í™˜"""
        try:
            # ë³€í™˜ ê·œì¹™ ê°€ì ¸ì˜¤ê¸°
            rules = self.conversion_rules.get(experience_type)
            if not rules:
                logger.warning(f"ë³€í™˜ ê·œì¹™ ì—†ìŒ: {experience_type}")
                return None
            
            # ì¹´í…Œê³ ë¦¬ ê²°ì •
            category = self.category_mapping.get(experience_type, 'core_csharp_basics')
            
            # í‚¤ì›Œë“œ ì¶”ì¶œ
            keywords = self._extract_keywords_from_experience(experience_type, experience_data)
            
            # ë‚œì´ë„ ê³„ì‚°
            difficulty = rules['difficulty_calculator'](experience_data)
            
            # í•™ìŠµ ë°ì´í„° ìƒì„±
            learning_data = LearningData(
                id=f"{experience_type}_{int(datetime.now().timestamp())}_{hashlib.md5(str(experience_data).encode()).hexdigest()[:8]}",
                category=category,
                topic=self._generate_topic_from_experience(experience_type, experience_data),
                question="",  # generate_qa_pairsì—ì„œ ìƒì„±
                answer="",    # generate_qa_pairsì—ì„œ ìƒì„±
                keywords=keywords,
                difficulty=difficulty,
                source='development',
                effectiveness=experience_data.get('effectiveness', 
                                                experience_data.get('success_rate', 
                                                                  experience_data.get('improvement', 50) / 100)),
                metadata=experience_data,
                timestamp=datetime.now().isoformat()
            )
            
            return learning_data
            
        except Exception as e:
            logger.error(f"ê²½í—˜ ë³€í™˜ ì˜¤ë¥˜: {e}")
            return None
    
    def _extract_keywords_from_experience(self, experience_type: str, experience_data: Dict[str, Any]) -> List[str]:
        """ê²½í—˜ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        keywords = []
        
        # íƒ€ì…ë³„ í‚¤ì›Œë“œ ì¶”ì¶œ
        if experience_type == 'error_solution':
            keywords.extend(['ì˜¤ë¥˜', 'í•´ê²°', experience_data.get('error', {}).get('type', 'ì˜¤ë¥˜')])
        elif experience_type == 'game_mechanic':
            keywords.extend(['ê²Œì„', 'ë©”ì¹´ë‹‰', experience_data.get('name', 'ê¸°ëŠ¥')])
        elif experience_type == 'code_pattern':
            keywords.extend(['íŒ¨í„´', 'ì½”ë“œ', experience_data.get('name', 'íŒ¨í„´')])
        elif experience_type == 'performance_opt':
            keywords.extend(['ì„±ëŠ¥', 'ìµœì í™”', experience_data.get('type', 'ìµœì í™”')])
        elif experience_type == 'ai_discovery':
            keywords.extend(['AI', 'ë°œê²¬', experience_data.get('discovery_type', 'AI')])
        
        # ì½”ë“œì—ì„œ ì¶”ê°€ í‚¤ì›Œë“œ ì¶”ì¶œ
        code = experience_data.get('code', experience_data.get('code_snippet', ''))
        if code:
            # C# í‚¤ì›Œë“œ ì°¾ê¸°
            csharp_keywords = re.findall(r'\b(class|public|private|void|int|string|bool|async|await)\b', code)
            keywords.extend(list(set(csharp_keywords)))
            
            # Godot í‚¤ì›Œë“œ ì°¾ê¸°
            godot_keywords = re.findall(r'\b(Node|GDScript|signal|export|ready|process)\b', code)
            keywords.extend(list(set(godot_keywords)))
        
        return list(set(keywords))[:10]  # ìµœëŒ€ 10ê°œ
    
    def _generate_topic_from_experience(self, experience_type: str, experience_data: Dict[str, Any]) -> str:
        """ê²½í—˜ì—ì„œ ì£¼ì œ ìƒì„±"""
        if experience_type == 'error_solution':
            return f"{experience_data.get('error', {}).get('type', 'ì˜¤ë¥˜')} í•´ê²°"
        elif experience_type == 'game_mechanic':
            return f"{experience_data.get('name', 'ê²Œì„ ê¸°ëŠ¥')} êµ¬í˜„"
        elif experience_type == 'code_pattern':
            return f"{experience_data.get('name', 'ì½”ë“œ íŒ¨í„´')} í™œìš©"
        elif experience_type == 'performance_opt':
            return f"{experience_data.get('type', 'ì„±ëŠ¥')} ìµœì í™”"
        elif experience_type == 'ai_discovery':
            return f"AI {experience_data.get('discovery_type', 'ë°œê²¬')}"
        else:
            return "ê°œë°œ ê²½í—˜"
    
    async def generate_qa_pairs(self, learning_data: LearningData) -> List[QAPair]:
        """í•™ìŠµ ë°ì´í„°ì—ì„œ Q&A ìŒ ìƒì„±"""
        qa_pairs = []
        
        # ê²½í—˜ íƒ€ì… ê²°ì •
        experience_type = learning_data.id.split('_')[0]
        rules = self.conversion_rules.get(experience_type, {})
        
        if not rules:
            return qa_pairs
        
        # ë‹¤ì–‘í•œ ì§ˆë¬¸ ìƒì„±
        question_templates = rules.get('question_templates', [])
        answer_format = rules.get('answer_format', '')
        
        for i, template in enumerate(question_templates[:3]):  # ìµœëŒ€ 3ê°œ ì§ˆë¬¸
            try:
                # ì§ˆë¬¸ ìƒì„±
                question_text = self._format_template(template, learning_data.metadata)
                
                # ë‹µë³€ ìƒì„±
                answer_text = self._format_template(answer_format, learning_data.metadata)
                
                # Q&A ìŒ ìƒì„±
                qa_pair = QAPair(
                    question_id=f"{learning_data.id}_q{i+1}",
                    question_text=question_text,
                    question_type=self._determine_question_type(experience_type),
                    answer_text=answer_text,
                    quality_score=learning_data.effectiveness,
                    source_experience=experience_type,
                    generated_at=datetime.now().isoformat()
                )
                
                qa_pairs.append(qa_pair)
                
                # í•™ìŠµ ì‹œìŠ¤í…œì— ì§ì ‘ ì¶”ê°€
                if self.continuous_learning_system:
                    await self._add_to_learning_system(qa_pair, learning_data)
                
            except Exception as e:
                logger.error(f"Q&A ìƒì„± ì˜¤ë¥˜: {e}")
        
        # Q&A ìŒ ì €ì¥
        await self._save_qa_pairs(qa_pairs)
        
        return qa_pairs
    
    def _format_template(self, template: str, data: Dict[str, Any]) -> str:
        """í…œí”Œë¦¿ í¬ë§·íŒ…"""
        # ë°ì´í„°ì—ì„œ ë³€ìˆ˜ ì¶”ì¶œ
        variables = {}
        
        # ê¸°ë³¸ ë³€ìˆ˜ë“¤
        variables.update({
            'error_type': data.get('error', {}).get('type', 'ì¼ë°˜ ì˜¤ë¥˜'),
            'error_description': data.get('error', {}).get('description', data.get('error', 'ì˜¤ë¥˜')),
            'error_context': data.get('error', {}).get('context', 'Godot'),
            'solution_steps': data.get('solution', {}).get('steps', data.get('solution', 'í•´ê²° ë°©ë²•')),
            'code_example': data.get('code', data.get('code_snippet', '// ì½”ë“œ ì˜ˆì œ')),
            'explanation': data.get('explanation', data.get('description', 'ì„¤ëª…')),
            'mechanic_name': data.get('name', 'ê²Œì„ ë©”ì¹´ë‹‰'),
            'mechanic_description': data.get('description', 'ê²Œì„ ê¸°ëŠ¥'),
            'pattern_name': data.get('name', 'ë””ìì¸ íŒ¨í„´'),
            'use_case': data.get('use_case', 'ì¼ë°˜ì ì¸ ì‚¬ìš©'),
            'code': data.get('code', '// íŒ¨í„´ ì½”ë“œ'),
            'effectiveness': f"{data.get('effectiveness', 1.0):.1f}",
            'applications': data.get('applications', 1),
            'considerations': data.get('considerations', 'ì£¼ì˜ì‚¬í•­ ì—†ìŒ'),
            'optimization_type': data.get('type', 'ì¼ë°˜'),
            'before_metrics': json.dumps(data.get('before_metrics', data.get('before', {})), ensure_ascii=False),
            'after_metrics': json.dumps(data.get('after_metrics', data.get('after', {})), ensure_ascii=False),
            'improvement': f"{data.get('improvement', 0):.1f}",
            'method': data.get('method', 'ìµœì í™” ë°©ë²•'),
            'code_changes': data.get('code_changes', '// ë³€ê²½ëœ ì½”ë“œ'),
            'key_points': data.get('key_points', 'í•µì‹¬ í¬ì¸íŠ¸'),
            'discovery_type': data.get('discovery_type', data.get('type', 'general')),
            'description': data.get('description', 'ì„¤ëª…'),
            'context': data.get('context', 'ì¼ë°˜ ë§¥ë½'),
            'creativity_score': data.get('creativity_score', 5),
            'usage_example': data.get('usage_example', '// ì‚¬ìš© ì˜ˆì‹œ'),
            'performance_notes': data.get('performance_notes', data.get('performance', 'ì„±ëŠ¥ ê³ ë ¤ì‚¬í•­'))
        })
        
        # í…œí”Œë¦¿ í¬ë§·íŒ…
        try:
            return template.format(**variables)
        except KeyError as e:
            logger.warning(f"í…œí”Œë¦¿ ë³€ìˆ˜ ëˆ„ë½: {e}")
            return template
    
    def _determine_question_type(self, experience_type: str) -> str:
        """ê²½í—˜ íƒ€ì…ì—ì„œ ì§ˆë¬¸ íƒ€ì… ê²°ì •"""
        type_mapping = {
            'error_solution': 'error',
            'game_mechanic': 'example',
            'code_pattern': 'example',
            'performance_opt': 'optimize',
            'ai_discovery': 'integrate'
        }
        return type_mapping.get(experience_type, 'explain')
    
    async def _add_to_learning_system(self, qa_pair: QAPair, learning_data: LearningData):
        """í•™ìŠµ ì‹œìŠ¤í…œì— Q&A ì¶”ê°€"""
        if not self.continuous_learning_system:
            return
        
        try:
            # ì§ˆë¬¸ í˜•ì‹ ë§ì¶”ê¸°
            question = {
                "id": qa_pair.question_id,
                "topic": learning_data.topic,
                "type": qa_pair.question_type,
                "language": "korean",
                "difficulty": learning_data.difficulty,
                "question": qa_pair.question_text,
                "keywords": learning_data.keywords
            }
            
            # ë‹µë³€ í˜•ì‹ ë§ì¶”ê¸°
            answer = {
                "model": "realtime_integration",
                "question_id": qa_pair.question_id,
                "answer": qa_pair.answer_text,
                "response_time": 0.1,
                "timestamp": qa_pair.generated_at
            }
            
            # ë¶„ì„ ê²°ê³¼
            analysis = {
                "success": True,
                "quality_score": qa_pair.quality_score,
                "extracted_knowledge": {
                    "source": qa_pair.source_experience,
                    "effectiveness": learning_data.effectiveness
                },
                "new_patterns": [],
                "improvements": []
            }
            
            # í•™ìŠµ ì‹œìŠ¤í…œì— ì €ì¥
            self.continuous_learning_system.save_qa_pair(question, answer, analysis)
            
            logger.debug(f"í•™ìŠµ ì‹œìŠ¤í…œì— Q&A ì¶”ê°€: {qa_pair.question_id}")
            
        except Exception as e:
            logger.error(f"í•™ìŠµ ì‹œìŠ¤í…œ ì¶”ê°€ ì˜¤ë¥˜: {e}")
    
    async def _save_qa_pairs(self, qa_pairs: List[QAPair]):
        """Q&A ìŒ ì €ì¥"""
        if not qa_pairs:
            return
        
        # ë‚ ì§œë³„ ë””ë ‰í† ë¦¬
        today = datetime.now().strftime("%Y%m%d")
        qa_dir = self.integration_path / "qa_pairs" / today
        qa_dir.mkdir(parents=True, exist_ok=True)
        
        # ë°°ì¹˜ íŒŒì¼ë¡œ ì €ì¥
        batch_id = f"batch_{int(datetime.now().timestamp())}"
        batch_file = qa_dir / f"{batch_id}.json"
        
        batch_data = {
            "batch_id": batch_id,
            "generated_at": datetime.now().isoformat(),
            "qa_pairs": [asdict(qa) for qa in qa_pairs],
            "count": len(qa_pairs)
        }
        
        try:
            with open(batch_file, 'w', encoding='utf-8') as f:
                json.dump(batch_data, f, indent=2, ensure_ascii=False)
            logger.debug(f"Q&A ë°°ì¹˜ ì €ì¥: {batch_file}")
        except Exception as e:
            logger.error(f"Q&A ì €ì¥ ì˜¤ë¥˜: {e}")
    
    async def update_knowledge_base(self, learning_data: LearningData):
        """ì§€ì‹ ë² ì´ìŠ¤ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸"""
        if not self.continuous_learning_system:
            return
        
        try:
            kb = self.continuous_learning_system.knowledge_base
            
            # ì¹´í…Œê³ ë¦¬ë³„ ì—…ë°ì´íŠ¸
            if learning_data.category.startswith('core_csharp'):
                # C# íŒ¨í„´ ì—…ë°ì´íŠ¸
                pattern_key = f"{learning_data.topic}_{learning_data.id}"
                kb["csharp_patterns"][pattern_key] = {
                    "topic": learning_data.topic,
                    "code": learning_data.metadata.get('code', ''),
                    "language": "korean",
                    "effectiveness": learning_data.effectiveness
                }
                
            elif learning_data.category.startswith('core_korean'):
                # í•œê¸€ ë²ˆì—­ ì—…ë°ì´íŠ¸
                for keyword in learning_data.keywords:
                    if re.match(r'[ê°€-í£]+', keyword):
                        kb["korean_translations"][keyword] = learning_data.metadata.get('description', '')
                
            elif learning_data.category.startswith('core_godot'):
                # Godot í†µí•© ì—…ë°ì´íŠ¸
                integration_key = f"{learning_data.topic}_{learning_data.id}"
                kb["godot_integrations"][integration_key] = {
                    "topic": learning_data.topic,
                    "implementation": learning_data.metadata,
                    "effectiveness": learning_data.effectiveness
                }
            
            # ê³µí†µ ì˜¤ë¥˜ íŒ¨í„´ ì—…ë°ì´íŠ¸
            if learning_data.source == 'error_solution':
                error_type = learning_data.metadata.get('error', {}).get('type', 'unknown')
                kb["common_errors"][error_type] = learning_data.metadata.get('solution', '')
            
            # ëª¨ë²” ì‚¬ë¡€ ì—…ë°ì´íŠ¸
            if learning_data.effectiveness > 0.8:
                practice_key = f"best_{learning_data.category}_{learning_data.id}"
                kb["best_practices"][practice_key] = {
                    "category": learning_data.category,
                    "practice": learning_data.topic,
                    "effectiveness": learning_data.effectiveness,
                    "source": learning_data.source
                }
            
            # ì§€ì‹ ë² ì´ìŠ¤ ì €ì¥
            self.continuous_learning_system._save_knowledge_base()
            
            self.integration_stats['knowledge_updates'] += 1
            logger.debug(f"ì§€ì‹ ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸: {learning_data.category}")
            
        except Exception as e:
            logger.error(f"ì§€ì‹ ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}")
    
    async def create_specialized_training_dataset(self, category: str = None) -> Dict[str, Any]:
        """íŠ¹í™”ëœ í•™ìŠµ ë°ì´í„°ì…‹ ìƒì„±"""
        dataset = {
            "name": f"game_dev_specialized_{category or 'all'}",
            "created_at": datetime.now().isoformat(),
            "category": category,
            "qa_pairs": [],
            "statistics": {}
        }
        
        # Q&A íŒŒì¼ë“¤ ìˆ˜ì§‘
        qa_files = list(self.integration_path.glob("qa_pairs/**/*.json"))
        
        total_pairs = 0
        category_counts = defaultdict(int)
        quality_scores = []
        
        for qa_file in qa_files:
            try:
                with open(qa_file, 'r', encoding='utf-8') as f:
                    batch_data = json.load(f)
                    
                    for qa_data in batch_data.get('qa_pairs', []):
                        # ì¹´í…Œê³ ë¦¬ í•„í„°ë§
                        if category and not qa_data.get('source_experience', '').startswith(category):
                            continue
                        
                        dataset['qa_pairs'].append(qa_data)
                        total_pairs += 1
                        category_counts[qa_data.get('source_experience', 'unknown')] += 1
                        quality_scores.append(qa_data.get('quality_score', 0))
                        
            except Exception as e:
                logger.error(f"ë°ì´í„°ì…‹ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
        
        # í†µê³„ ê³„ì‚°
        dataset['statistics'] = {
            "total_pairs": total_pairs,
            "category_distribution": dict(category_counts),
            "average_quality": sum(quality_scores) / len(quality_scores) if quality_scores else 0,
            "min_quality": min(quality_scores) if quality_scores else 0,
            "max_quality": max(quality_scores) if quality_scores else 0
        }
        
        # ë°ì´í„°ì…‹ ì €ì¥
        dataset_file = self.integration_path / "training_datasets" / f"{dataset['name']}_{int(datetime.now().timestamp())}.json"
        dataset_file.parent.mkdir(parents=True, exist_ok=True)
        
        try:
            with open(dataset_file, 'w', encoding='utf-8') as f:
                json.dump(dataset, f, indent=2, ensure_ascii=False)
            
            self.integration_stats['training_datasets_created'] += 1
            logger.info(f"íŠ¹í™” ë°ì´í„°ì…‹ ìƒì„±: {dataset_file.name} ({total_pairs}ê°œ Q&A)")
            
        except Exception as e:
            logger.error(f"ë°ì´í„°ì…‹ ì €ì¥ ì˜¤ë¥˜: {e}")
        
        return dataset
    
    async def _periodic_integration(self):
        """ì£¼ê¸°ì  í†µí•© ì‘ì—…"""
        while self.processing_active:
            await asyncio.sleep(300)  # 5ë¶„ë§ˆë‹¤
            
            try:
                # í•™ìŠµ ì‹œìŠ¤í…œê³¼ í†µí•©
                await self._integrate_with_continuous_learning()
                
                # íŠ¹í™” ë°ì´í„°ì…‹ ìƒì„±
                await self.create_specialized_training_dataset()
                
                # í†µí•© ìƒíƒœ ì €ì¥
                self._save_integration_state()
                
                # í†µí•© ë³´ê³ ì„œ ìƒì„±
                await self._generate_integration_report()
                
            except Exception as e:
                logger.error(f"ì£¼ê¸°ì  í†µí•© ì˜¤ë¥˜: {e}")
    
    async def _integrate_with_continuous_learning(self):
        """ì—°ì† í•™ìŠµ ì‹œìŠ¤í…œê³¼ ì™„ì „ í†µí•©"""
        if not self.continuous_learning_system:
            return
        
        logger.info("ì—°ì† í•™ìŠµ ì‹œìŠ¤í…œê³¼ í†µí•© ì‹œì‘...")
        
        # ìƒˆë¡œìš´ ì£¼ì œ ì¶”ê°€
        new_topics_added = 0
        
        # ìˆ˜ì§‘ëœ ê²½í—˜ì—ì„œ ìƒˆë¡œìš´ í•™ìŠµ ì£¼ì œ ìƒì„±
        if self.experience_collector:
            # ìì£¼ ë°œìƒí•˜ëŠ” ì˜¤ë¥˜ íŒ¨í„´ì„ ìƒˆ ì£¼ì œë¡œ
            for error_hash, solutions in self.experience_collector.error_solutions.items():
                if len(solutions) > 10:  # 10ë²ˆ ì´ìƒ ë°œìƒ
                    topic_id = f"frequent_error_{error_hash}"
                    if not any(t.id == topic_id for t in self.continuous_learning_system.learning_topics):
                        # ìƒˆ ì£¼ì œ ì¶”ê°€
                        from continuous_learning_system import LearningTopic
                        new_topic = LearningTopic(
                            id=topic_id,
                            category="ìì£¼ ë°œìƒí•˜ëŠ” ì˜¤ë¥˜",
                            topic=f"ì˜¤ë¥˜ íŒ¨í„´ {error_hash}",
                            difficulty=3,
                            korean_keywords=["ì˜¤ë¥˜", "í•´ê²°", "íŒ¨í„´"],
                            csharp_concepts=["error", "exception", "handling"],
                            godot_integration="Godot ì˜¤ë¥˜ ì²˜ë¦¬"
                        )
                        self.continuous_learning_system.learning_topics.append(new_topic)
                        new_topics_added += 1
        
        # í•™ìŠµ ì§„í–‰ ìƒíƒœ ì—…ë°ì´íŠ¸
        if hasattr(self.continuous_learning_system, 'progressive_manager') and self.continuous_learning_system.progressive_manager:
            # ì‹¤ì œ ê°œë°œ ê²½í—˜ ê¸°ë°˜ìœ¼ë¡œ ë‚œì´ë„ ì¡°ì •
            insights = self.experience_collector.get_learning_insights() if self.experience_collector else {}
            
            if insights.get('success_rate', 0) > 0.8:
                # ì„±ê³µë¥ ì´ ë†’ìœ¼ë©´ ë‚œì´ë„ ìƒìŠ¹
                current = self.continuous_learning_system.progressive_manager.progress['current_difficulty']
                if current < 5:
                    self.continuous_learning_system.progressive_manager.progress['current_difficulty'] = current + 1
                    logger.info(f"ë‚œì´ë„ ìƒìŠ¹: {current} -> {current + 1}")
        
        logger.info(f"í†µí•© ì™„ë£Œ: {new_topics_added}ê°œ ìƒˆ ì£¼ì œ ì¶”ê°€")
    
    async def _generate_integration_report(self):
        """í†µí•© ë³´ê³ ì„œ ìƒì„±"""
        report_dir = self.integration_path / "reports"
        report_dir.mkdir(exist_ok=True)
        
        report_file = report_dir / f"integration_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        
        # ê²½í—˜ ìˆ˜ì§‘ê¸° ì¸ì‚¬ì´íŠ¸
        experience_insights = self.experience_collector.get_learning_insights() if self.experience_collector else {}
        
        report = f"""# ì‹¤ì‹œê°„ í•™ìŠµ í†µí•© ë³´ê³ ì„œ

## ğŸ“Š í†µí•© í†µê³„
- ë³€í™˜ëœ ê²½í—˜: {self.integration_stats['total_experiences_converted']}
- ìƒì„±ëœ Q&A ìŒ: {self.integration_stats['qa_pairs_generated']}
- ì§€ì‹ ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸: {self.integration_stats['knowledge_updates']}
- ìƒì„±ëœ í•™ìŠµ ë°ì´í„°ì…‹: {self.integration_stats['training_datasets_created']}
- ë§ˆì§€ë§‰ í†µí•©: {self.integration_stats.get('last_integration', 'N/A')}

## ğŸ’¡ ê²½í—˜ ìˆ˜ì§‘ ì¸ì‚¬ì´íŠ¸
"""
        
        if experience_insights:
            report += f"""- ì´ ê²½í—˜: {experience_insights.get('total_experiences', 0)}
- ì„±ê³µë¥ : {experience_insights.get('success_rate', 0):.1%}
- AI ì°½ì˜ì„± ì ìˆ˜: {experience_insights.get('ai_creativity_score', 0):.1f}/10
- ì»¤ë®¤ë‹ˆí‹° ê¸°ì—¬: {experience_insights.get('community_contribution', 0)}

### ê°€ì¥ íš¨ê³¼ì ì¸ ì „ëµ
"""
            for strategy, score in experience_insights.get('most_effective_strategies', [])[:5]:
                report += f"- {strategy}: {score:.1f}ì \n"
            
            report += "\n### ì¼ë°˜ì ì¸ íŒ¨í„´\n"
            for pattern, freq in experience_insights.get('common_patterns', [])[:10]:
                report += f"- {pattern}: {freq}íšŒ\n"
        
        report += f"""
## ğŸ¯ í•™ìŠµ íš¨ê³¼
- ìƒˆë¡œìš´ ì˜¤ë¥˜ í•´ê²° íŒ¨í„´: {len(self.experience_collector.error_solutions) if self.experience_collector else 0}
- ì„±ê³µì ì¸ ê²Œì„ ë©”ì¹´ë‹‰: {len(self.experience_collector.successful_mechanics) if self.experience_collector else 0}
- ë°œê²¬ëœ ì½”ë“œ íŒ¨í„´: {len(self.experience_collector.code_patterns) if self.experience_collector else 0}

## ğŸ“ˆ í’ˆì§ˆ ì§€í‘œ
"""
        
        # Q&A í’ˆì§ˆ ë¶„ì„
        qa_files = list(self.integration_path.glob("qa_pairs/**/*.json"))
        quality_scores = []
        
        for qa_file in qa_files[-10:]:  # ìµœê·¼ 10ê°œ íŒŒì¼
            try:
                with open(qa_file, 'r', encoding='utf-8') as f:
                    batch_data = json.load(f)
                    for qa in batch_data.get('qa_pairs', []):
                        quality_scores.append(qa.get('quality_score', 0))
            except:
                pass
        
        if quality_scores:
            report += f"""- í‰ê·  Q&A í’ˆì§ˆ ì ìˆ˜: {sum(quality_scores)/len(quality_scores):.2f}
- ìµœê³  í’ˆì§ˆ ì ìˆ˜: {max(quality_scores):.2f}
- ìµœì € í’ˆì§ˆ ì ìˆ˜: {min(quality_scores):.2f}
"""
        
        report += f"""
## ğŸ”„ ë‹¤ìŒ ë‹¨ê³„
1. ë” ë§ì€ ê°œë°œ ê²½í—˜ ìˆ˜ì§‘
2. Q&A í’ˆì§ˆ ê°œì„ 
3. íŠ¹í™” ëª¨ë¸ í›ˆë ¨
4. ì‹¤ì‹œê°„ í”¼ë“œë°± ê°•í™”

---
ìƒì„± ì‹œê°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
        
        try:
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(report)
            logger.info(f"í†µí•© ë³´ê³ ì„œ ìƒì„±: {report_file}")
        except Exception as e:
            logger.error(f"ë³´ê³ ì„œ ìƒì„± ì˜¤ë¥˜: {e}")
    
    async def on_new_experience(self, experience_type: str, experience_data: Dict[str, Any]):
        """ìƒˆë¡œìš´ ê²½í—˜ ìˆ˜ì‹  (ì™¸ë¶€ ì—°ë™ìš©)"""
        if not self.processing_active:
            logger.warning("ì‹¤ì‹œê°„ ì²˜ë¦¬ê°€ ë¹„í™œì„±í™” ìƒíƒœì…ë‹ˆë‹¤")
            return
        
        try:
            # íì— ì¶”ê°€
            await self.experience_queue.put((experience_type, experience_data))
            logger.debug(f"ìƒˆ ê²½í—˜ íì— ì¶”ê°€: {experience_type}")
        except asyncio.QueueFull:
            logger.error("ê²½í—˜ íê°€ ê°€ë“ ì°¸")
    
    def get_integration_status(self) -> Dict[str, Any]:
        """í†µí•© ìƒíƒœ ë°˜í™˜"""
        return {
            "active": self.processing_active,
            "stats": self.integration_stats,
            "queue_size": self.experience_queue.qsize() if self.experience_queue else 0,
            "connected_systems": {
                "continuous_learning": self.continuous_learning_system is not None,
                "experience_collector": self.experience_collector is not None,
                "ai_controller": self.ai_model_controller is not None
            },
            "last_report": max(
                [f for f in (self.integration_path / "reports").glob("*.md")],
                key=lambda x: x.stat().st_mtime,
                default=None
            ) if (self.integration_path / "reports").exists() else None
        }

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_integrator_instance = None

def get_realtime_integrator():
    """ì‹¤ì‹œê°„ í†µí•©ê¸° ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _integrator_instance
    if _integrator_instance is None:
        _integrator_instance = RealtimeLearningIntegrator()
    return _integrator_instance

# ê°„í¸ ì‚¬ìš©ì„ ìœ„í•œ í•¨ìˆ˜ë“¤
async def start_integration(continuous_learning_system=None, experience_collector=None, ai_controller=None):
    """í†µí•© ì‹œì‘"""
    integrator = get_realtime_integrator()
    await integrator.connect_systems(continuous_learning_system, experience_collector, ai_controller)
    await integrator.start_realtime_processing()
    return integrator

async def stop_integration():
    """í†µí•© ì¤‘ì§€"""
    integrator = get_realtime_integrator()
    await integrator.stop_realtime_processing()

async def add_experience(experience_type: str, experience_data: Dict[str, Any]):
    """ê²½í—˜ ì¶”ê°€"""
    integrator = get_realtime_integrator()
    await integrator.on_new_experience(experience_type, experience_data)

def get_status():
    """ìƒíƒœ ì¡°íšŒ"""
    integrator = get_realtime_integrator()
    return integrator.get_integration_status()