#!/usr/bin/env python3
"""
24ì‹œê°„ ì—°ì† C# ì‹ ê²½ë§ í•™ìŠµ ì‹œìŠ¤í…œ
ì‹¤ì œë¡œ ì‹ ê²½ë§ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸í•˜ë©° í•™ìŠµí•˜ëŠ” ì‹œìŠ¤í…œ
"""

import os
import sys
import json
import time
import logging
import threading
import sqlite3
import asyncio
import aiohttp
import schedule
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
from collections import deque
import numpy as np

# PyTorch ì„í¬íŠ¸
try:
    import torch
    import torch.nn as nn
    import torch.optim as optim
    from torch.utils.data import DataLoader, Dataset
    import torch.nn.functional as F
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    print("âš ï¸ PyTorchê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì œí•œëœ ê¸°ëŠ¥ìœ¼ë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler('neural_continuous_learning.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class CSharpDataset(Dataset):
    """C# í•™ìŠµ ë°ì´í„°ì…‹"""
    
    def __init__(self, data_path: str, max_length: int = 512):
        self.data_path = Path(data_path)
        self.max_length = max_length
        self.data = []
        self.vocab = self._build_vocab()
        self._load_data()
        
    def _build_vocab(self) -> Dict[str, int]:
        """ì–´íœ˜ ì‚¬ì „ êµ¬ì¶•"""
        # C# í‚¤ì›Œë“œì™€ Unity ê´€ë ¨ ìš©ì–´
        keywords = [
            'public', 'private', 'protected', 'class', 'interface', 'namespace',
            'using', 'void', 'int', 'float', 'string', 'bool', 'var', 'const',
            'static', 'async', 'await', 'Task', 'return', 'if', 'else', 'for',
            'foreach', 'while', 'switch', 'case', 'break', 'continue', 'try',
            'catch', 'finally', 'throw', 'new', 'this', 'base', 'override',
            'virtual', 'abstract', 'sealed', 'partial', 'get', 'set', 'value',
            'GameObject', 'Transform', 'Vector3', 'Quaternion', 'Rigidbody',
            'Collider', 'MonoBehaviour', 'Start', 'Update', 'FixedUpdate',
            'OnCollisionEnter', 'OnTriggerEnter', 'Instantiate', 'Destroy'
        ]
        
        vocab = {'<PAD>': 0, '<UNK>': 1, '<START>': 2, '<END>': 3}
        for i, word in enumerate(keywords):
            vocab[word] = i + 4
            
        return vocab
        
    def _load_data(self):
        """ë°ì´í„° ë¡œë“œ"""
        # ì‹¤ì œ êµ¬í˜„ì‹œ ë°ì´í„°ë² ì´ìŠ¤ë‚˜ íŒŒì¼ì—ì„œ ë¡œë“œ
        self.data = []
        
    def __len__(self):
        return len(self.data)
        
    def __getitem__(self, idx):
        return self.data[idx]


class CSharpNeuralNetwork(nn.Module):
    """C# ì „ë¬¸ ì‹ ê²½ë§ ëª¨ë¸"""
    
    def __init__(self, vocab_size: int, hidden_size: int = 512, num_layers: int = 6):
        super().__init__()
        self.vocab_size = vocab_size
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        
        # ì„ë² ë”© ë ˆì´ì–´
        self.embedding = nn.Embedding(vocab_size, hidden_size)
        self.positional_encoding = self._create_positional_encoding()
        
        # íŠ¸ëœìŠ¤í¬ë¨¸ ë ˆì´ì–´
        self.transformer = nn.TransformerEncoder(
            nn.TransformerEncoderLayer(
                d_model=hidden_size,
                nhead=8,
                dim_feedforward=2048,
                dropout=0.1
            ),
            num_layers=num_layers
        )
        
        # ì¶œë ¥ ë ˆì´ì–´
        self.output_projection = nn.Linear(hidden_size, vocab_size)
        
    def _create_positional_encoding(self, max_len: int = 5000):
        """ìœ„ì¹˜ ì¸ì½”ë”© ìƒì„±"""
        pe = torch.zeros(max_len, self.hidden_size)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, self.hidden_size, 2).float() * 
                           (-np.log(10000.0) / self.hidden_size))
        
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        
        return nn.Parameter(pe.unsqueeze(0), requires_grad=False)
        
    def forward(self, x, mask=None):
        # ì„ë² ë”©
        seq_len = x.size(1)
        x = self.embedding(x) * np.sqrt(self.hidden_size)
        x = x + self.positional_encoding[:, :seq_len, :]
        
        # íŠ¸ëœìŠ¤í¬ë¨¸
        x = x.transpose(0, 1)  # (batch, seq, hidden) -> (seq, batch, hidden)
        x = self.transformer(x, mask=mask)
        x = x.transpose(0, 1)  # (seq, batch, hidden) -> (batch, seq, hidden)
        
        # ì¶œë ¥
        return self.output_projection(x)


class NeuralContinuousLearner:
    """24ì‹œê°„ ì—°ì† ì‹ ê²½ë§ í•™ìŠµ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.base_path = Path(__file__).parent
        self.data_path = self.base_path / "neural_learning_data"
        self.model_path = self.base_path / "neural_models"
        self.data_path.mkdir(exist_ok=True)
        self.model_path.mkdir(exist_ok=True)
        
        # í•™ìŠµ ì„¤ì •
        self.learning_config = {
            'batch_size': 32,
            'learning_rate': 0.0001,
            'max_epochs': 1000,
            'save_interval': 100,
            'eval_interval': 50,
            'gradient_accumulation_steps': 4,
            'warmup_steps': 1000,
            'max_grad_norm': 1.0
        }
        
        # ë°ì´í„° ì†ŒìŠ¤
        self.data_sources = {
            'github': 'https://api.github.com/search/code',
            'stackoverflow': 'https://api.stackexchange.com/2.3/search',
            'unity_docs': 'https://docs.unity3d.com/ScriptReference/',
            'ms_docs': 'https://docs.microsoft.com/en-us/dotnet/csharp/'
        }
        
        # í•™ìŠµ ìƒíƒœ
        self.learning_state = {
            'is_running': False,
            'total_steps': 0,
            'total_samples': 0,
            'current_loss': 0.0,
            'best_loss': float('inf'),
            'learning_history': deque(maxlen=1000),
            'last_checkpoint': None
        }
        
        # ì‹ ê²½ë§ ì´ˆê¸°í™”
        if TORCH_AVAILABLE:
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
            self.model = None
            self.optimizer = None
            self.scheduler = None
            self._init_neural_network()
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
        self._init_database()
        
        # ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •
        self._setup_scheduler()
        
    def _init_database(self):
        """í•™ìŠµ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        db_path = self.data_path / "neural_learning.db"
        self.conn = sqlite3.connect(str(db_path), check_same_thread=False)
        
        self.conn.execute('''
            CREATE TABLE IF NOT EXISTS learning_samples (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                source TEXT,
                code_snippet TEXT,
                description TEXT,
                quality_score REAL,
                learned_at TIMESTAMP,
                loss_value REAL,
                is_validated BOOLEAN DEFAULT 0
            )
        ''')
        
        self.conn.execute('''
            CREATE TABLE IF NOT EXISTS learning_progress (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TIMESTAMP,
                total_samples INTEGER,
                avg_loss REAL,
                learning_rate REAL,
                model_version TEXT,
                metrics TEXT
            )
        ''')
        
        self.conn.execute('''
            CREATE TABLE IF NOT EXISTS code_patterns (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                pattern_type TEXT,
                pattern_code TEXT,
                frequency INTEGER,
                quality_score REAL,
                last_seen TIMESTAMP
            )
        ''')
        
        self.conn.commit()
        
    def _init_neural_network(self):
        """ì‹ ê²½ë§ ì´ˆê¸°í™”"""
        if not TORCH_AVAILABLE:
            return
            
        logger.info(f"ğŸ§  ì‹ ê²½ë§ ì´ˆê¸°í™” (Device: {self.device})")
        
        # ëª¨ë¸ ìƒì„±
        vocab_size = 50000  # C# ì–´íœ˜ í¬ê¸°
        self.model = CSharpNeuralNetwork(
            vocab_size=vocab_size,
            hidden_size=512,
            num_layers=6
        ).to(self.device)
        
        # ì˜µí‹°ë§ˆì´ì €
        self.optimizer = optim.AdamW(
            self.model.parameters(),
            lr=self.learning_config['learning_rate'],
            betas=(0.9, 0.98),
            eps=1e-9
        )
        
        # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬
        self.scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(
            self.optimizer,
            T_0=1000,
            T_mult=2,
            eta_min=1e-6
        )
        
        # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
        self._load_checkpoint()
        
    def _setup_scheduler(self):
        """24ì‹œê°„ í•™ìŠµ ìŠ¤ì¼€ì¤„ ì„¤ì •"""
        # ë§¤ ì‹œê°„ë§ˆë‹¤ ì‹¤í–‰í•  ì‘ì—…ë“¤
        schedule.every().hour.do(self._hourly_learning)
        
        # ë§¤ 30ë¶„ë§ˆë‹¤ ë°ì´í„° ìˆ˜ì§‘
        schedule.every(30).minutes.do(self._collect_data)
        
        # ë§¤ 10ë¶„ë§ˆë‹¤ í•™ìŠµ
        schedule.every(10).minutes.do(self._train_batch)
        
        # ë§¤ 2ì‹œê°„ë§ˆë‹¤ í‰ê°€
        schedule.every(2).hours.do(self._evaluate_model)
        
        # ë§¤ì¼ ìì •ì— ëª¨ë¸ ë°±ì—…
        schedule.every().day.at("00:00").do(self._backup_model)
        
        # ë§¤ì¼ ìƒˆë²½ 3ì‹œì— ìµœì í™”
        schedule.every().day.at("03:00").do(self._optimize_model)
        
    async def _collect_data(self):
        """ë°ì´í„° ìˆ˜ì§‘ (ë¹„ë™ê¸°)"""
        logger.info("ğŸ“¥ C# ì½”ë“œ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
        
        collected = 0
        
        # GitHubì—ì„œ C# ì½”ë“œ ìˆ˜ì§‘
        try:
            async with aiohttp.ClientSession() as session:
                # Unity ê´€ë ¨ C# ì½”ë“œ ê²€ìƒ‰
                queries = [
                    'Unity MonoBehaviour language:csharp',
                    'Unity Coroutine async await',
                    'Unity GameObject Transform',
                    'Unity Physics Rigidbody',
                    'Unity UI Canvas',
                    'C# LINQ performance',
                    'C# async Task pattern',
                    'C# design patterns'
                ]
                
                for query in queries:
                    url = f"{self.data_sources['github']}?q={query}&per_page=10"
                    
                    try:
                        async with session.get(url) as response:
                            if response.status == 200:
                                data = await response.json()
                                
                                for item in data.get('items', []):
                                    # ì½”ë“œ í’ˆì§ˆ í‰ê°€
                                    quality = self._evaluate_code_quality(item)
                                    
                                    if quality > 0.7:  # ê³ í’ˆì§ˆ ì½”ë“œë§Œ ì €ì¥
                                        self._save_code_sample(
                                            source='github',
                                            code=item.get('content', ''),
                                            description=item.get('name', ''),
                                            quality=quality
                                        )
                                        collected += 1
                                        
                    except Exception as e:
                        logger.error(f"ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
                        
                    await asyncio.sleep(2)  # API ì œí•œ ê³ ë ¤
                    
        except Exception as e:
            logger.error(f"ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
            
        logger.info(f"âœ… {collected}ê°œ ì½”ë“œ ìƒ˜í”Œ ìˆ˜ì§‘ ì™„ë£Œ")
        
    def _evaluate_code_quality(self, code_item: Dict) -> float:
        """ì½”ë“œ í’ˆì§ˆ í‰ê°€"""
        quality_score = 0.5  # ê¸°ë³¸ ì ìˆ˜
        
        code = code_item.get('content', '')
        
        # í’ˆì§ˆ ì§€í‘œë“¤
        indicators = {
            'has_comments': '///' in code or '/*' in code,
            'uses_async': 'async' in code and 'await' in code,
            'has_error_handling': 'try' in code and 'catch' in code,
            'uses_linq': 'using System.Linq' in code,
            'proper_naming': not any(bad in code.lower() for bad in ['temp', 'test', 'foo', 'bar']),
            'has_unity_patterns': any(pattern in code for pattern in ['MonoBehaviour', 'Update', 'Start'])
        }
        
        # ì ìˆ˜ ê³„ì‚°
        for indicator, present in indicators.items():
            if present:
                quality_score += 0.1
                
        # ì½”ë“œ ê¸¸ì´ ê³ ë ¤
        lines = code.count('\n')
        if 10 < lines < 500:
            quality_score += 0.1
            
        return min(quality_score, 1.0)
        
    def _save_code_sample(self, source: str, code: str, description: str, quality: float):
        """ì½”ë“œ ìƒ˜í”Œ ì €ì¥"""
        self.conn.execute('''
            INSERT INTO learning_samples (source, code_snippet, description, quality_score, learned_at)
            VALUES (?, ?, ?, ?, ?)
        ''', (source, code, description, quality, datetime.now()))
        self.conn.commit()
        
    def _train_batch(self):
        """ë°°ì¹˜ í•™ìŠµ"""
        if not TORCH_AVAILABLE or not self.model:
            logger.warning("âš ï¸ ì‹ ê²½ë§ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return
            
        logger.info("ğŸ§  ì‹ ê²½ë§ ë°°ì¹˜ í•™ìŠµ ì‹œì‘...")
        
        # í•™ìŠµ ë°ì´í„° ë¡œë“œ
        samples = self.conn.execute('''
            SELECT code_snippet, description 
            FROM learning_samples 
            WHERE is_validated = 0 
            ORDER BY quality_score DESC 
            LIMIT ?
        ''', (self.learning_config['batch_size'],)).fetchall()
        
        if not samples:
            logger.info("í•™ìŠµí•  ìƒˆë¡œìš´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return
            
        # í•™ìŠµ ëª¨ë“œ
        self.model.train()
        total_loss = 0
        
        for code, description in samples:
            try:
                # ì½”ë“œë¥¼ í† í°í™” (ê°„ë‹¨í•œ ì˜ˆì‹œ)
                tokens = self._tokenize_code(code)
                
                if len(tokens) < 5:
                    continue
                    
                # í…ì„œ ë³€í™˜
                input_ids = torch.tensor([tokens[:-1]], device=self.device)
                target_ids = torch.tensor([tokens[1:]], device=self.device)
                
                # ìˆœì „íŒŒ
                outputs = self.model(input_ids)
                loss = F.cross_entropy(
                    outputs.reshape(-1, outputs.size(-1)),
                    target_ids.reshape(-1)
                )
                
                # ì—­ì „íŒŒ
                loss.backward()
                
                # ê·¸ë˜ë””ì–¸íŠ¸ ëˆ„ì 
                if self.learning_state['total_steps'] % self.learning_config['gradient_accumulation_steps'] == 0:
                    # ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘
                    nn.utils.clip_grad_norm_(
                        self.model.parameters(),
                        self.learning_config['max_grad_norm']
                    )
                    
                    # ì˜µí‹°ë§ˆì´ì € ìŠ¤í…
                    self.optimizer.step()
                    self.scheduler.step()
                    self.optimizer.zero_grad()
                    
                total_loss += loss.item()
                self.learning_state['total_steps'] += 1
                
            except Exception as e:
                logger.error(f"í•™ìŠµ ì¤‘ ì˜¤ë¥˜: {e}")
                continue
                
        # í•™ìŠµ ìƒíƒœ ì—…ë°ì´íŠ¸
        avg_loss = total_loss / len(samples) if samples else 0
        self.learning_state['current_loss'] = avg_loss
        self.learning_state['total_samples'] += len(samples)
        self.learning_state['learning_history'].append({
            'timestamp': datetime.now(),
            'loss': avg_loss,
            'samples': len(samples)
        })
        
        # ê²€ì¦ ì™„ë£Œ í‘œì‹œ
        sample_ids = [s[0] for s in samples]
        self.conn.execute(f'''
            UPDATE learning_samples 
            SET is_validated = 1, loss_value = ? 
            WHERE code_snippet IN ({','.join(['?']*len(sample_ids))})
        ''', [avg_loss] + sample_ids)
        self.conn.commit()
        
        logger.info(f"âœ… ë°°ì¹˜ í•™ìŠµ ì™„ë£Œ - Loss: {avg_loss:.4f}, Samples: {len(samples)}")
        
        # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        if self.learning_state['total_steps'] % self.learning_config['save_interval'] == 0:
            self._save_checkpoint()
            
    def _tokenize_code(self, code: str) -> List[int]:
        """ì½”ë“œ í† í°í™” (ê°„ë‹¨í•œ êµ¬í˜„)"""
        # ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ í† í¬ë‚˜ì´ì € í•„ìš”
        tokens = []
        words = code.split()
        
        for word in words[:100]:  # ìµœëŒ€ 100 í† í°
            if word in self.model.embedding.weight:
                tokens.append(self.model.embedding.weight[word])
            else:
                tokens.append(1)  # <UNK>
                
        return tokens
        
    def _hourly_learning(self):
        """ì‹œê°„ë³„ ì¢…í•© í•™ìŠµ"""
        logger.info("â° ì‹œê°„ë³„ ì¢…í•© í•™ìŠµ ì‹œì‘...")
        
        # ìˆ˜ì§‘ëœ íŒ¨í„´ ë¶„ì„
        patterns = self.conn.execute('''
            SELECT pattern_type, COUNT(*) as count 
            FROM code_patterns 
            GROUP BY pattern_type 
            ORDER BY count DESC 
            LIMIT 10
        ''').fetchall()
        
        logger.info("ğŸ“Š ì£¼ìš” í•™ìŠµ íŒ¨í„´:")
        for pattern_type, count in patterns:
            logger.info(f"  - {pattern_type}: {count}ê°œ")
            
        # í•™ìŠµ ì§„í–‰ ìƒí™© ì €ì¥
        metrics = {
            'patterns': dict(patterns),
            'total_steps': self.learning_state['total_steps'],
            'avg_loss': self.learning_state['current_loss']
        }
        
        self.conn.execute('''
            INSERT INTO learning_progress 
            (timestamp, total_samples, avg_loss, learning_rate, model_version, metrics)
            VALUES (?, ?, ?, ?, ?, ?)
        ''', (
            datetime.now(),
            self.learning_state['total_samples'],
            self.learning_state['current_loss'],
            self.scheduler.get_last_lr()[0] if self.scheduler else 0.0001,
            'v1.0',
            json.dumps(metrics)
        ))
        self.conn.commit()
        
    def _evaluate_model(self):
        """ëª¨ë¸ í‰ê°€"""
        if not TORCH_AVAILABLE or not self.model:
            return
            
        logger.info("ğŸ” ëª¨ë¸ í‰ê°€ ì‹œì‘...")
        
        self.model.eval()
        total_correct = 0
        total_samples = 0
        
        # í‰ê°€ ë°ì´í„° ë¡œë“œ
        eval_samples = self.conn.execute('''
            SELECT code_snippet, description 
            FROM learning_samples 
            WHERE quality_score > 0.8 
            ORDER BY RANDOM() 
            LIMIT 100
        ''').fetchall()
        
        with torch.no_grad():
            for code, description in eval_samples:
                try:
                    tokens = self._tokenize_code(code)
                    if len(tokens) < 5:
                        continue
                        
                    input_ids = torch.tensor([tokens[:-1]], device=self.device)
                    target_ids = tokens[1:]
                    
                    outputs = self.model(input_ids)
                    predictions = outputs.argmax(dim=-1).cpu().numpy()[0]
                    
                    # ì •í™•ë„ ê³„ì‚°
                    correct = sum(p == t for p, t in zip(predictions, target_ids))
                    total_correct += correct
                    total_samples += len(target_ids)
                    
                except Exception as e:
                    continue
                    
        accuracy = total_correct / total_samples if total_samples > 0 else 0
        logger.info(f"âœ… í‰ê°€ ì™„ë£Œ - ì •í™•ë„: {accuracy:.2%}")
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
        if self.learning_state['current_loss'] < self.learning_state['best_loss']:
            self.learning_state['best_loss'] = self.learning_state['current_loss']
            self._save_checkpoint(best=True)
            
    def _save_checkpoint(self, best=False):
        """ì²´í¬í¬ì¸íŠ¸ ì €ì¥"""
        if not TORCH_AVAILABLE or not self.model:
            return
            
        checkpoint = {
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'learning_state': self.learning_state,
            'timestamp': datetime.now().isoformat()
        }
        
        if best:
            path = self.model_path / "best_model.pt"
        else:
            path = self.model_path / f"checkpoint_{self.learning_state['total_steps']}.pt"
            
        torch.save(checkpoint, path)
        logger.info(f"ğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ì €ì¥: {path}")
        
        self.learning_state['last_checkpoint'] = str(path)
        
    def _load_checkpoint(self):
        """ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ"""
        if not TORCH_AVAILABLE:
            return
            
        best_model_path = self.model_path / "best_model.pt"
        
        if best_model_path.exists():
            try:
                checkpoint = torch.load(best_model_path, map_location=self.device)
                self.model.load_state_dict(checkpoint['model_state_dict'])
                self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
                self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
                self.learning_state.update(checkpoint['learning_state'])
                logger.info(f"âœ… ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì™„ë£Œ: {best_model_path}")
            except Exception as e:
                logger.error(f"ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                
    def _backup_model(self):
        """ì¼ì¼ ëª¨ë¸ ë°±ì—…"""
        logger.info("ğŸ’¾ ì¼ì¼ ëª¨ë¸ ë°±ì—… ì‹œì‘...")
        
        backup_path = self.model_path / f"backup_{datetime.now().strftime('%Y%m%d')}.pt"
        
        if self.learning_state['last_checkpoint']:
            import shutil
            shutil.copy(self.learning_state['last_checkpoint'], backup_path)
            logger.info(f"âœ… ë°±ì—… ì™„ë£Œ: {backup_path}")
            
    def _optimize_model(self):
        """ëª¨ë¸ ìµœì í™”"""
        logger.info("ğŸ”§ ëª¨ë¸ ìµœì í™” ì‹œì‘...")
        
        # ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬
        cutoff_date = datetime.now() - timedelta(days=7)
        self.conn.execute('''
            DELETE FROM learning_samples 
            WHERE learned_at < ? AND quality_score < 0.5
        ''', (cutoff_date,))
        
        # íŒ¨í„´ í†µê³„ ì—…ë°ì´íŠ¸
        self.conn.execute('''
            INSERT OR REPLACE INTO code_patterns (pattern_type, pattern_code, frequency, quality_score, last_seen)
            SELECT 
                'unity_pattern' as pattern_type,
                code_snippet as pattern_code,
                COUNT(*) as frequency,
                AVG(quality_score) as quality_score,
                MAX(learned_at) as last_seen
            FROM learning_samples
            WHERE code_snippet LIKE '%MonoBehaviour%'
            GROUP BY code_snippet
            HAVING COUNT(*) > 3
        ''')
        
        self.conn.commit()
        logger.info("âœ… ìµœì í™” ì™„ë£Œ")
        
    def start(self):
        """24ì‹œê°„ ì—°ì† í•™ìŠµ ì‹œì‘"""
        self.learning_state['is_running'] = True
        
        logger.info("ğŸš€ 24ì‹œê°„ C# ì‹ ê²½ë§ í•™ìŠµ ì‹œì‘!")
        logger.info(f"ğŸ–¥ï¸ Device: {self.device if TORCH_AVAILABLE else 'CPU only'}")
        logger.info(f"ğŸ“Š í˜„ì¬ í•™ìŠµ ìƒ˜í”Œ: {self.learning_state['total_samples']}")
        
        # ì´ˆê¸° ë°ì´í„° ìˆ˜ì§‘
        asyncio.run(self._collect_data())
        
        # í•™ìŠµ ë£¨í”„
        while self.learning_state['is_running']:
            try:
                schedule.run_pending()
                time.sleep(60)  # 1ë¶„ë§ˆë‹¤ ì²´í¬
                
                # ìƒíƒœ í‘œì‹œ
                if self.learning_state['total_steps'] % 100 == 0:
                    self._print_status()
                    
            except KeyboardInterrupt:
                logger.info("ğŸ›‘ ì‚¬ìš©ì ì¤‘ë‹¨...")
                break
            except Exception as e:
                logger.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
                time.sleep(300)  # 5ë¶„ í›„ ì¬ì‹œë„
                
    def stop(self):
        """í•™ìŠµ ì¤‘ì§€"""
        self.learning_state['is_running'] = False
        self._save_checkpoint()
        logger.info("ğŸ›‘ í•™ìŠµì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤")
        
    def _print_status(self):
        """í˜„ì¬ ìƒíƒœ ì¶œë ¥"""
        print("\n" + "="*60)
        print("ğŸ§  C# ì‹ ê²½ë§ í•™ìŠµ ìƒíƒœ")
        print("="*60)
        print(f"ì´ í•™ìŠµ ë‹¨ê³„: {self.learning_state['total_steps']:,}")
        print(f"ì´ í•™ìŠµ ìƒ˜í”Œ: {self.learning_state['total_samples']:,}")
        print(f"í˜„ì¬ Loss: {self.learning_state['current_loss']:.4f}")
        print(f"ìµœê³  Loss: {self.learning_state['best_loss']:.4f}")
        
        if self.scheduler:
            print(f"í•™ìŠµë¥ : {self.scheduler.get_last_lr()[0]:.6f}")
            
        # ìµœê·¼ í•™ìŠµ íŒ¨í„´
        recent_patterns = self.conn.execute('''
            SELECT pattern_type, frequency 
            FROM code_patterns 
            ORDER BY last_seen DESC 
            LIMIT 5
        ''').fetchall()
        
        if recent_patterns:
            print("\nìµœê·¼ í•™ìŠµ íŒ¨í„´:")
            for pattern, freq in recent_patterns:
                print(f"  - {pattern}: {freq}íšŒ")
                
        print("="*60 + "\n")
        
    def get_learning_stats(self) -> Dict[str, Any]:
        """í•™ìŠµ í†µê³„ ë°˜í™˜"""
        stats = {
            'is_running': self.learning_state['is_running'],
            'total_steps': self.learning_state['total_steps'],
            'total_samples': self.learning_state['total_samples'],
            'current_loss': self.learning_state['current_loss'],
            'best_loss': self.learning_state['best_loss'],
            'device': str(self.device) if TORCH_AVAILABLE else 'CPU',
            'model_parameters': sum(p.numel() for p in self.model.parameters()) if self.model else 0
        }
        
        # ìµœê·¼ í•™ìŠµ ê¸°ë¡
        recent_history = list(self.learning_state['learning_history'])[-10:]
        stats['recent_history'] = [
            {
                'time': h['timestamp'].strftime('%H:%M'),
                'loss': h['loss'],
                'samples': h['samples']
            }
            for h in recent_history
        ]
        
        return stats


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    learner = NeuralContinuousLearner()
    
    print("ğŸ§  24ì‹œê°„ C# ì‹ ê²½ë§ í•™ìŠµ ì‹œìŠ¤í…œ")
    print("="*60)
    print("ì´ ì‹œìŠ¤í…œì€ ì‹¤ì œë¡œ ì‹ ê²½ë§ì„ í•™ìŠµì‹œì¼œ C# ì½”ë”© ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.")
    print("GitHub, StackOverflow ë“±ì—ì„œ ê³ í’ˆì§ˆ C# ì½”ë“œë¥¼ ìˆ˜ì§‘í•˜ê³  í•™ìŠµí•©ë‹ˆë‹¤.")
    print("="*60)
    
    try:
        learner.start()
    except KeyboardInterrupt:
        print("\n\ní•™ìŠµì„ ì¤‘ì§€í•©ë‹ˆë‹¤...")
        learner.stop()
        
        
if __name__ == "__main__":
    main()