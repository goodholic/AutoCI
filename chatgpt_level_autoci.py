#!/usr/bin/env python3
"""
ChatGPT ìˆ˜ì¤€ì˜ AutoCI í†µí•© ì‹œìŠ¤í…œ
ëª¨ë“  ì»´í¬ë„ŒíŠ¸ë¥¼ í†µí•©í•˜ì—¬ ChatGPTì™€ ê°™ì€ ìˆ˜ì¤€ì˜ ëŒ€í™”í˜• AI êµ¬í˜„
"""

import os
import sys
import time
import json
import threading
import logging
from datetime import datetime
from typing import Dict, List, Optional, Tuple, Any

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

try:
    import torch
    import torch.nn as nn
    from transformers import AutoTokenizer, AutoModel
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False
    print("âš ï¸ Transformers ì—†ìŒ - ê¸°ë³¸ ëª¨ë“œë¡œ ì‹¤í–‰")

# ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸
try:
    from advanced_transformer_autoci import AdvancedAutoCI, KoreanTransformerModel, AdvancedMemorySystem, RealTimeLearningEngine
    from korean_dataset_collector import KoreanDatasetDatabase, ConversationDataCollector, ConversationQualityEvaluator
    from learning_progress_tracker import LearningProgressTracker
    ADVANCED_MODULES_AVAILABLE = True
except ImportError:
    ADVANCED_MODULES_AVAILABLE = False
    print("âš ï¸ ê³ ê¸‰ ëª¨ë“ˆ ì—†ìŒ - ê°„ì†Œí™” ëª¨ë“œë¡œ ì‹¤í–‰")

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ChatGPTLevelAutoCI:
    """ChatGPT ìˆ˜ì¤€ì˜ AutoCI ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.system_name = "ChatGPT-Level AutoCI"
        self.version = "2.0.0"
        self.capabilities = {
            "korean_conversation": True,
            "unity_expertise": True,
            "csharp_programming": True,
            "real_time_learning": True,
            "context_memory": True,
            "quality_evaluation": True,
            "continuous_improvement": True
        }
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.advanced_ai = None
        self.dataset_db = None
        self.progress_tracker = None
        self.conversation_history = []
        self.user_sessions = {}
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        self.metrics = {
            "total_conversations": 0,
            "user_satisfaction": 0.0,
            "learning_efficiency": 0.0,
            "response_accuracy": 0.0,
            "system_uptime": datetime.now(),
            "last_learning_update": None
        }
        
        # ì‹œìŠ¤í…œ ìƒíƒœ
        self.status = {
            "initialized": False,
            "learning_enabled": True,
            "components_healthy": False,
            "ready_for_conversation": False
        }
        
        self.initialize_system()
    
    def initialize_system(self):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        logger.info(f"ğŸš€ {self.system_name} v{self.version} ì´ˆê¸°í™” ì‹œì‘")
        
        try:
            # 1. ë°ì´í„°ì…‹ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            self._initialize_dataset_system()
            
            # 2. ê³ ê¸‰ AI ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            self._initialize_advanced_ai()
            
            # 3. ì§„í–‰ë¥  ì¶”ì  ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            self._initialize_progress_tracking()
            
            # 4. ì‹œìŠ¤í…œ ìƒíƒœ ì—…ë°ì´íŠ¸
            self.status["initialized"] = True
            self.status["components_healthy"] = self._check_component_health()
            self.status["ready_for_conversation"] = True
            
            logger.info("âœ… ChatGPT ìˆ˜ì¤€ì˜ AutoCI ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self._fallback_initialization()
    
    def _initialize_dataset_system(self):
        """ë°ì´í„°ì…‹ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            if ADVANCED_MODULES_AVAILABLE:
                self.dataset_db = KoreanDatasetDatabase()
                logger.info("âœ… í•œêµ­ì–´ ë°ì´í„°ì…‹ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            else:
                logger.warning("âš ï¸ ê³ ê¸‰ ë°ì´í„°ì…‹ ì‹œìŠ¤í…œ ì‚¬ìš© ë¶ˆê°€ - ê¸°ë³¸ ëª¨ë“œ")
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„°ì…‹ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def _initialize_advanced_ai(self):
        """ê³ ê¸‰ AI ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            if ADVANCED_MODULES_AVAILABLE and TRANSFORMERS_AVAILABLE:
                self.advanced_ai = AdvancedAutoCI()
                logger.info("âœ… ê³ ê¸‰ íŠ¸ëœìŠ¤í¬ë¨¸ AI ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            else:
                self._initialize_fallback_ai()
                logger.warning("âš ï¸ ê³ ê¸‰ AI ì‹œìŠ¤í…œ ì‚¬ìš© ë¶ˆê°€ - í´ë°± AI ì‚¬ìš©")
        except Exception as e:
            logger.error(f"âŒ ê³ ê¸‰ AI ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self._initialize_fallback_ai()
    
    def _initialize_fallback_ai(self):
        """í´ë°± AI ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        class FallbackAI:
            def __init__(self):
                self.responses = {
                    "greeting": ["ì•ˆë…•í•˜ì„¸ìš”! AutoCIì…ë‹ˆë‹¤.", "ë°˜ê°‘ìŠµë‹ˆë‹¤!", "ì•ˆë…•í•˜ì„¸ìš”! ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?"],
                    "unity": ["Unity ê°œë°œì„ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.", "Unity ê´€ë ¨ ì§ˆë¬¸ì´ì‹œêµ°ìš”!", "Unityì— ëŒ€í•´ ì„¤ëª…ë“œë¦¬ê² ìŠµë‹ˆë‹¤."],
                    "csharp": ["C# í”„ë¡œê·¸ë˜ë°ì„ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.", "C# ê´€ë ¨ ì§ˆë¬¸ì´ì‹œë„¤ìš”!", "C#ì— ëŒ€í•´ ì•Œë ¤ë“œë¦¬ê² ìŠµë‹ˆë‹¤."],
                    "default": ["ë„¤, ì´í•´í–ˆìŠµë‹ˆë‹¤.", "ë” êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì‹œë©´ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.", "ì¢‹ì€ ì§ˆë¬¸ì´ë„¤ìš”!"]
                }
                
            def chat(self, user_id: str, user_input: str) -> Tuple[str, str]:
                import random
                input_lower = user_input.lower()
                
                if any(word in input_lower for word in ["ì•ˆë…•", "hello", "hi"]):
                    response = random.choice(self.responses["greeting"])
                elif any(word in input_lower for word in ["unity", "ìœ ë‹ˆí‹°"]):
                    response = random.choice(self.responses["unity"])
                elif any(word in input_lower for word in ["c#", "csharp", "ì½”ë“œ"]):
                    response = random.choice(self.responses["csharp"])
                else:
                    response = random.choice(self.responses["default"])
                
                return response, f"fallback_conv_{int(time.time())}"
            
            def process_feedback(self, user_id: str, conversation_id: str, 
                               user_input: str, ai_response: str, feedback: str) -> bool:
                return True
            
            def save_model(self):
                pass
        
        self.advanced_ai = FallbackAI()
    
    def _initialize_progress_tracking(self):
        """ì§„í–‰ë¥  ì¶”ì  ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            if ADVANCED_MODULES_AVAILABLE:
                self.progress_tracker = LearningProgressTracker()
                logger.info("âœ… í•™ìŠµ ì§„í–‰ë¥  ì¶”ì  ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            else:
                logger.warning("âš ï¸ ì§„í–‰ë¥  ì¶”ì  ì‹œìŠ¤í…œ ì‚¬ìš© ë¶ˆê°€")
        except Exception as e:
            logger.error(f"âŒ ì§„í–‰ë¥  ì¶”ì  ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def _fallback_initialization(self):
        """í´ë°± ì´ˆê¸°í™”"""
        logger.warning("ğŸ”„ í´ë°± ëª¨ë“œë¡œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”")
        self._initialize_fallback_ai()
        self.status["initialized"] = True
        self.status["ready_for_conversation"] = True
        logger.info("âœ… í´ë°± ëª¨ë“œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _check_component_health(self) -> bool:
        """ì»´í¬ë„ŒíŠ¸ ìƒíƒœ í™•ì¸"""
        healthy = True
        
        if self.advanced_ai is None:
            healthy = False
            logger.warning("âš ï¸ AI ì‹œìŠ¤í…œ ë¹„ì •ìƒ")
        
        if ADVANCED_MODULES_AVAILABLE and self.dataset_db is None:
            healthy = False
            logger.warning("âš ï¸ ë°ì´í„°ì…‹ ì‹œìŠ¤í…œ ë¹„ì •ìƒ")
        
        return healthy
    
    def chat(self, user_input: str, user_id: str = "default_user") -> Dict[str, Any]:
        """ChatGPT ìˆ˜ì¤€ì˜ ëŒ€í™” ì¸í„°í˜ì´ìŠ¤"""
        
        if not self.status["ready_for_conversation"]:
            return {
                "response": "ì‹œìŠ¤í…œì´ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                "conversation_id": None,
                "confidence": 0.0,
                "learning_applied": False,
                "error": "system_not_ready"
            }
        
        try:
            start_time = time.time()
            
            # ì‚¬ìš©ì ì„¸ì…˜ ê´€ë¦¬
            if user_id not in self.user_sessions:
                self.user_sessions[user_id] = {
                    "conversations": [],
                    "preferences": {},
                    "satisfaction_scores": [],
                    "created_at": datetime.now().isoformat()
                }
            
            # AI ì‘ë‹µ ìƒì„±
            ai_response, conversation_id = self.advanced_ai.chat(user_id, user_input)
            
            # ì‘ë‹µ ì‹œê°„ ê³„ì‚°
            response_time = time.time() - start_time
            
            # ëŒ€í™” ê¸°ë¡ ì €ì¥
            conversation_record = {
                "conversation_id": conversation_id,
                "user_id": user_id,
                "user_input": user_input,
                "ai_response": ai_response,
                "timestamp": datetime.now().isoformat(),
                "response_time": response_time,
                "confidence": self._estimate_confidence(user_input, ai_response)
            }
            
            self.conversation_history.append(conversation_record)
            self.user_sessions[user_id]["conversations"].append(conversation_record)
            
            # ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            self.metrics["total_conversations"] += 1
            
            # ì‘ë‹µ í’ˆì§ˆ í‰ê°€ (ë°±ê·¸ë¼ìš´ë“œ)
            threading.Thread(
                target=self._evaluate_response_quality,
                args=(conversation_record,),
                daemon=True
            ).start()
            
            return {
                "response": ai_response,
                "conversation_id": conversation_id,
                "confidence": conversation_record["confidence"],
                "response_time": response_time,
                "learning_applied": True,
                "capabilities": list(self.capabilities.keys()),
                "system_status": "ready"
            }
            
        except Exception as e:
            logger.error(f"âŒ ëŒ€í™” ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return {
                "response": "ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                "conversation_id": None,
                "confidence": 0.0,
                "learning_applied": False,
                "error": str(e)
            }
    
    def _estimate_confidence(self, user_input: str, ai_response: str) -> float:
        """ì‘ë‹µ ì‹ ë¢°ë„ ì¶”ì •"""
        confidence = 0.5  # ê¸°ë³¸ê°’
        
        # ì‘ë‹µ ê¸¸ì´ ê¸°ë°˜
        if len(ai_response) > 50:
            confidence += 0.2
        
        # ê¸°ìˆ ì  í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€
        tech_keywords = ["unity", "c#", "gameobject", "script", "ì½”ë“œ", "ë©”ì„œë“œ"]
        if any(keyword in user_input.lower() for keyword in tech_keywords):
            if any(keyword in ai_response.lower() for keyword in tech_keywords):
                confidence += 0.2
        
        # êµ¬ì¡°í™”ëœ ë‹µë³€ (ì½”ë“œ ë¸”ë¡, ë‹¨ê³„ë³„ ì„¤ëª…)
        if any(marker in ai_response for marker in ["```", "1.", "2.", "3."]):
            confidence += 0.1
        
        return min(confidence, 1.0)
    
    def _evaluate_response_quality(self, conversation_record: Dict):
        """ì‘ë‹µ í’ˆì§ˆ í‰ê°€ (ë°±ê·¸ë¼ìš´ë“œ)"""
        try:
            if ADVANCED_MODULES_AVAILABLE and hasattr(self, 'quality_evaluator'):
                # í’ˆì§ˆ í‰ê°€ ìˆ˜í–‰
                pass
            
            # ê°„ë‹¨í•œ í’ˆì§ˆ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            confidence = conversation_record["confidence"]
            current_accuracy = self.metrics["response_accuracy"]
            self.metrics["response_accuracy"] = (current_accuracy + confidence) / 2
            
        except Exception as e:
            logger.error(f"í’ˆì§ˆ í‰ê°€ ì˜¤ë¥˜: {e}")
    
    def process_feedback(self, conversation_id: str, feedback: str, 
                        feedback_type: str = "general") -> Dict[str, Any]:
        """ì‚¬ìš©ì í”¼ë“œë°± ì²˜ë¦¬"""
        
        try:
            # ëŒ€í™” ê¸°ë¡ ì°¾ê¸°
            conversation_record = next(
                (conv for conv in self.conversation_history 
                 if conv["conversation_id"] == conversation_id),
                None
            )
            
            if not conversation_record:
                return {
                    "success": False,
                    "error": "conversation_not_found",
                    "message": "í•´ë‹¹ ëŒ€í™”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                }
            
            # í”¼ë“œë°± ë¶„ì„
            feedback_score = self._analyze_feedback(feedback)
            
            # ê³ ê¸‰ AI ì‹œìŠ¤í…œì— í”¼ë“œë°± ì „ë‹¬
            if hasattr(self.advanced_ai, 'process_feedback'):
                success = self.advanced_ai.process_feedback(
                    conversation_record["user_id"],
                    conversation_id,
                    conversation_record["user_input"],
                    conversation_record["ai_response"],
                    feedback
                )
            else:
                success = True
            
            # ì‚¬ìš©ì ë§Œì¡±ë„ ì—…ë°ì´íŠ¸
            user_id = conversation_record["user_id"]
            if user_id in self.user_sessions:
                self.user_sessions[user_id]["satisfaction_scores"].append(feedback_score)
                
                # ì „ì²´ ë§Œì¡±ë„ ì—…ë°ì´íŠ¸
                all_scores = [
                    score 
                    for session in self.user_sessions.values() 
                    for score in session["satisfaction_scores"]
                ]
                if all_scores:
                    self.metrics["user_satisfaction"] = sum(all_scores) / len(all_scores)
            
            # í•™ìŠµ ì§„í–‰ë¥  ê¸°ë¡
            if self.progress_tracker and feedback_score != 0:
                try:
                    self.progress_tracker.record_learning_step(
                        epoch=self.metrics["total_conversations"],
                        loss=max(0.1, 1.0 - abs(feedback_score)),
                        accuracy=max(0.1, (feedback_score + 1.0) / 2.0),
                        learning_rate=0.001,
                        batch_size=1,
                        data_points=1,
                        training_time=1.0
                    )
                except Exception as e:
                    logger.warning(f"ì§„í–‰ë¥  ê¸°ë¡ ì‹¤íŒ¨: {e}")
            
            self.metrics["last_learning_update"] = datetime.now().isoformat()
            
            return {
                "success": success,
                "feedback_score": feedback_score,
                "learning_applied": success,
                "message": "í”¼ë“œë°±ì´ í•™ìŠµì— ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤." if success else "í”¼ë“œë°± ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
            }
            
        except Exception as e:
            logger.error(f"âŒ í”¼ë“œë°± ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "error": str(e),
                "message": "í”¼ë“œë°± ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            }
    
    def _analyze_feedback(self, feedback: str) -> float:
        """í”¼ë“œë°± ë¶„ì„"""
        feedback_lower = feedback.lower()
        
        # ê¸ì •ì  íŒ¨í„´
        positive_patterns = [
            "ì¢‹", "ë§", "ì •í™•", "ë„ì›€", "ê³ ë§ˆ", "í›Œë¥­", "ì™„ë²½", "ìµœê³ ", "ê°ì‚¬"
        ]
        
        # ë¶€ì •ì  íŒ¨í„´
        negative_patterns = [
            "í‹€", "ì•„ë‹ˆ", "ì´ìƒ", "ë³„ë¡œ", "ë‹¤ì‹œ", "ì˜ëª»", "ë‚˜ì˜", "ì—‰í„°ë¦¬"
        ]
        
        positive_count = sum(1 for pattern in positive_patterns if pattern in feedback_lower)
        negative_count = sum(1 for pattern in negative_patterns if pattern in feedback_lower)
        
        if positive_count > negative_count:
            return min(1.0, positive_count * 0.3 + 0.4)
        elif negative_count > positive_count:
            return max(-1.0, -(negative_count * 0.3 + 0.4))
        else:
            return 0.0
    
    def get_system_status(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ"""
        uptime = datetime.now() - self.metrics["system_uptime"]
        
        return {
            "system_name": self.system_name,
            "version": self.version,
            "status": self.status,
            "capabilities": self.capabilities,
            "metrics": {
                **self.metrics,
                "uptime_hours": uptime.total_seconds() / 3600,
                "avg_conversations_per_hour": self.metrics["total_conversations"] / max(uptime.total_seconds() / 3600, 1)
            },
            "active_users": len(self.user_sessions),
            "components": {
                "advanced_ai": self.advanced_ai is not None,
                "dataset_db": self.dataset_db is not None,
                "progress_tracker": self.progress_tracker is not None,
                "transformers_available": TRANSFORMERS_AVAILABLE,
                "advanced_modules_available": ADVANCED_MODULES_AVAILABLE
            }
        }
    
    def generate_learning_report(self) -> Dict[str, Any]:
        """í•™ìŠµ ë³´ê³ ì„œ ìƒì„±"""
        try:
            report = {
                "generated_at": datetime.now().isoformat(),
                "system_performance": {
                    "total_conversations": self.metrics["total_conversations"],
                    "user_satisfaction": self.metrics["user_satisfaction"],
                    "response_accuracy": self.metrics["response_accuracy"],
                    "learning_efficiency": self.metrics["learning_efficiency"]
                },
                "user_analytics": {
                    "total_users": len(self.user_sessions),
                    "avg_conversations_per_user": (
                        sum(len(session["conversations"]) for session in self.user_sessions.values()) 
                        / max(len(self.user_sessions), 1)
                    ),
                    "user_retention": self._calculate_user_retention()
                },
                "conversation_insights": self._analyze_conversation_patterns(),
                "recommendations": self._generate_improvement_recommendations()
            }
            
            # ì§„í–‰ë¥  ì¶”ì ê¸°ì—ì„œ ì¶”ê°€ ì •ë³´
            if self.progress_tracker:
                try:
                    progress_report = self.progress_tracker.generate_progress_report()
                    report["learning_progress"] = progress_report
                except Exception as e:
                    logger.warning(f"ì§„í–‰ë¥  ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}")
            
            return report
            
        except Exception as e:
            logger.error(f"í•™ìŠµ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    def _calculate_user_retention(self) -> float:
        """ì‚¬ìš©ì ìœ ì§€ìœ¨ ê³„ì‚°"""
        if not self.user_sessions:
            return 0.0
        
        # ê°„ë‹¨í•œ ìœ ì§€ìœ¨: ëŒ€í™”ê°€ 2íšŒ ì´ìƒì¸ ì‚¬ìš©ì ë¹„ìœ¨
        retained_users = sum(
            1 for session in self.user_sessions.values() 
            if len(session["conversations"]) >= 2
        )
        
        return retained_users / len(self.user_sessions)
    
    def _analyze_conversation_patterns(self) -> Dict[str, Any]:
        """ëŒ€í™” íŒ¨í„´ ë¶„ì„"""
        if not self.conversation_history:
            return {}
        
        # ì£¼ì œë³„ ë¶„í¬
        topics = {}
        for conv in self.conversation_history:
            user_input = conv["user_input"].lower()
            
            if any(word in user_input for word in ["unity", "ìœ ë‹ˆí‹°"]):
                topics["unity"] = topics.get("unity", 0) + 1
            elif any(word in user_input for word in ["c#", "csharp"]):
                topics["csharp"] = topics.get("csharp", 0) + 1
            else:
                topics["general"] = topics.get("general", 0) + 1
        
        # ì‘ë‹µ ì‹œê°„ ë¶„ì„
        response_times = [conv["response_time"] for conv in self.conversation_history]
        avg_response_time = sum(response_times) / len(response_times) if response_times else 0
        
        # ì‹ ë¢°ë„ ë¶„ì„
        confidences = [conv["confidence"] for conv in self.conversation_history]
        avg_confidence = sum(confidences) / len(confidences) if confidences else 0
        
        return {
            "topic_distribution": topics,
            "avg_response_time": avg_response_time,
            "avg_confidence": avg_confidence,
            "total_conversations": len(self.conversation_history)
        }
    
    def _generate_improvement_recommendations(self) -> List[str]:
        """ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        # ì‘ë‹µ ì •í™•ë„ ê¸°ë°˜
        if self.metrics["response_accuracy"] < 0.7:
            recommendations.append("ì‘ë‹µ ì •í™•ë„ê°€ ë‚®ìŠµë‹ˆë‹¤. ë” ë§ì€ í•™ìŠµ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # ì‚¬ìš©ì ë§Œì¡±ë„ ê¸°ë°˜
        if self.metrics["user_satisfaction"] < 0.6:
            recommendations.append("ì‚¬ìš©ì ë§Œì¡±ë„ê°€ ë‚®ìŠµë‹ˆë‹¤. ì‘ë‹µ í’ˆì§ˆ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # ìœ ì§€ìœ¨ ê¸°ë°˜
        retention = self._calculate_user_retention()
        if retention < 0.5:
            recommendations.append("ì‚¬ìš©ì ìœ ì§€ìœ¨ì´ ë‚®ìŠµë‹ˆë‹¤. ë” ë§¤ë ¥ì ì¸ ëŒ€í™” ê²½í—˜ì„ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.")
        
        # ì»´í¬ë„ŒíŠ¸ ìƒíƒœ ê¸°ë°˜
        if not self.status["components_healthy"]:
            recommendations.append("ì¼ë¶€ ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        
        if not recommendations:
            recommendations.append("ì‹œìŠ¤í…œì´ ì˜ ì‘ë™í•˜ê³  ìˆìŠµë‹ˆë‹¤. í˜„ì¬ ì„±ëŠ¥ì„ ìœ ì§€í•˜ì„¸ìš”.")
        
        return recommendations
    
    def interactive_chat_interface(self):
        """ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤"""
        print(f"\nğŸ¤– {self.system_name} v{self.version}")
        print("=" * 60)
        print("ChatGPT ìˆ˜ì¤€ì˜ AutoCIì™€ ëŒ€í™”í•´ë³´ì„¸ìš”!")
        print("ëª…ë ¹ì–´: 'quit' (ì¢…ë£Œ), 'status' (ìƒíƒœ), 'report' (ë³´ê³ ì„œ)")
        print("=" * 60)
        
        user_id = f"user_{int(time.time())}"
        last_conversation_id = None
        
        while True:
            try:
                user_input = input("\nğŸ’¬ ë‹¹ì‹ : ").strip()
                
                if user_input.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
                    break
                
                elif user_input.lower() == 'status':
                    status = self.get_system_status()
                    print(f"\nğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ:")
                    print(f"  ë²„ì „: {status['version']}")
                    print(f"  ì´ ëŒ€í™”: {status['metrics']['total_conversations']}")
                    print(f"  ì‚¬ìš©ì ë§Œì¡±ë„: {status['metrics']['user_satisfaction']:.2f}")
                    print(f"  ì‘ë‹µ ì •í™•ë„: {status['metrics']['response_accuracy']:.2f}")
                    print(f"  ì—…íƒ€ì„: {status['metrics']['uptime_hours']:.1f}ì‹œê°„")
                    continue
                
                elif user_input.lower() == 'report':
                    print("\nğŸ“‹ í•™ìŠµ ë³´ê³ ì„œ ìƒì„± ì¤‘...")
                    report = self.generate_learning_report()
                    if "error" not in report:
                        print(f"ğŸ“ˆ ì´ ëŒ€í™”: {report['system_performance']['total_conversations']}")
                        print(f"ğŸ“Š ì‚¬ìš©ì ë§Œì¡±ë„: {report['system_performance']['user_satisfaction']:.2f}")
                        print(f"ğŸ¯ ê¶Œì¥ì‚¬í•­: {len(report['recommendations'])}ê°œ")
                        for i, rec in enumerate(report['recommendations'], 1):
                            print(f"  {i}. {rec}")
                    else:
                        print(f"âŒ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {report['error']}")
                    continue
                
                elif user_input.lower().startswith('feedback:') and last_conversation_id:
                    feedback = user_input[9:].strip()
                    result = self.process_feedback(last_conversation_id, feedback)
                    if result["success"]:
                        print(f"âœ… {result['message']}")
                    else:
                        print(f"âŒ {result['message']}")
                    continue
                
                # AIì™€ ëŒ€í™”
                result = self.chat(user_input, user_id)
                
                if "error" not in result:
                    print(f"\nğŸ¤– AutoCI: {result['response']}")
                    print(f"   (ì‹ ë¢°ë„: {result['confidence']:.2f}, "
                          f"ì‘ë‹µì‹œê°„: {result['response_time']:.2f}ì´ˆ)")
                    
                    last_conversation_id = result["conversation_id"]
                    
                    # ê°€ë” í”¼ë“œë°± ìš”ì²­
                    import random
                    if random.random() < 0.2:  # 20% í™•ë¥ 
                        print("\nğŸ’¡ ì´ ë‹µë³€ì´ ë„ì›€ì´ ë˜ì—ˆë‚˜ìš”? 'feedback: ì¢‹ì•„ìš”' ë˜ëŠ” 'feedback: ë³„ë¡œì˜ˆìš”'")
                else:
                    print(f"\nâŒ AutoCI: {result['response']}")
                
            except KeyboardInterrupt:
                break
            except Exception as e:
                print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        # ì‹œìŠ¤í…œ ì •ë¦¬
        if hasattr(self.advanced_ai, 'save_model'):
            self.advanced_ai.save_model()
        
        print(f"\nğŸ‘‹ {self.system_name}ë¥¼ ì´ìš©í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤!")
        print("í•™ìŠµ ë°ì´í„°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ ChatGPT ìˆ˜ì¤€ì˜ AutoCI ì‹œìŠ¤í…œ")
    print("=" * 60)
    
    try:
        # ChatGPT ìˆ˜ì¤€ AutoCI ì´ˆê¸°í™”
        autoci = ChatGPTLevelAutoCI()
        
        # ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤ ì‹œì‘
        autoci.interactive_chat_interface()
        
    except Exception as e:
        logger.error(f"ì‹œìŠ¤í…œ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    sys.exit(main())